{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image, ImageEnhance, ImageOps, ImageFilter\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (2200, 5828), Test data shape: (1000, 5828)\n"
     ]
    }
   ],
   "source": [
    "data = joblib.load(\"train.joblib\")\n",
    "test_data = joblib.load(open(\"data/eval1.joblib\", \"rb\"))\n",
    "print(f\"Training data shape: {data['data'].shape}, Test data shape: {test_data['data'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2200, 2, 62, 47)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshape_images = data['data'].reshape(-1, 2, 62, 47)\n",
    "labels = data['target']\n",
    "reshape_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2200, 62, 94)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images = np.concatenate((reshape_images[:, 0], reshape_images[:, 1]), axis=2)\n",
    "print(images.shape)\n",
    "plt.imshow(images[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1075aa9f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(Image.fromarray(images[0] * 255))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONVERT TO PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1075ab740>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def numpy_to_pil(images_array):\n",
    "    pil_images = []\n",
    "    for i in range(images_array.shape[0]):\n",
    "        img = Image.fromarray(images_array[i] * 255, mode='F')\n",
    "        pil_images.append(img)\n",
    "    return pil_images\n",
    "\n",
    "pil_images = numpy_to_pil(images)\n",
    "plt.imshow(pil_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10752dfa0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(pil_images[0].transpose(Image.FLIP_LEFT_RIGHT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(240.66669)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(pil_images[0].transpose(Image.FLIP_LEFT_RIGHT)).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BRIGHTNESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1216dfaa0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(ImageEnhance.Brightness(pil_images[0].convert('L')).enhance(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1217671d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(ImageEnhance.Brightness(pil_images[0].convert('L')).enhance(1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.uint8(255)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(ImageEnhance.Brightness(pil_images[0].convert('L')).enhance(1.5)).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONTRAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1217cacf0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(ImageEnhance.Contrast(pil_images[0].convert('L')).enhance(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x121850fe0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(pil_images[0].convert('L').filter(ImageFilter.FIND_EDGES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.uint8(255)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(pil_images[0].convert('L').filter(ImageFilter.FIND_EDGES)).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHARPNESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x107632660>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(ImageEnhance.Sharpness(pil_images[0].convert('L')).enhance(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x121923e90>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add random noise\n",
    "noise_factor = 0.05\n",
    "noise = np.random.randn(*images.shape) * noise_factor\n",
    "noisy_image = np.array(images + noise)\n",
    "plt.imshow(noisy_image[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x121998fe0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(pil_images[0].convert('L').filter(ImageFilter.GaussianBlur(1.2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x121a13ad0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(pil_images[0].convert('L').filter(ImageFilter.EDGE_ENHANCE_MORE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x121f2aa80>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAF1CAYAAABI2ohwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABf50lEQVR4nO3de3hU9b0v/vfcMpNJQkK45AIBAga5i4KiYIVWobXY1mO3rZdWu3d/u1qslfqcqtSeU+yxYO3ZHvau1m48VumxbNq9q62t1YK14oUqFEpFUFC5BSFEICSBJHNdvz+o0eTzXnYNkywCvl/Pk+fRD7PWrFm3fBne388KOI7jQERERMQnwRO9ASIiIvLhosGHiIiI+EqDDxEREfGVBh8iIiLiKw0+RERExFcafIiIiIivNPgQERERX2nwISIiIr7S4ENERER8pcGHiIiI+CrcWyv+0Y9+hB/84AfYt28fxo8fjyVLluAjH/nI310um81i7969KCkpQSAQ6K3NExERkR7kOA5aW1tRXV2NYPDvfLfh9IIVK1Y4kUjEeeCBB5wtW7Y4N910k1NUVOTs2rXr7y5bX1/vANCPfvSjH/3oRz8n4U99ff3f/V0fcJyef7DctGnTcNZZZ+H+++/vrI0dOxaXXnopFi9e/IHLNjc3o6ysDBMv/x8IRWKd9VCab2Yqbr8dSZbYWjpul81GXT56xpYCWW/fwgSyvJ4N2ZpTQN7f5W0cMojMxOybOVGyAUGXz5m2Kw2kyQa4bVOIrDdi3z9AanDZn06KbFOC1FJ2+SCpuWH7002A7T5Sy0ZsMUuOkZsg+5y5nE/FabJSu03hxgL+/inyPvyl5M1d6uSQVP7JXmDpQn5A2PXNtildSK75Qr5JmbjdWIfszwDZney8A/i+y4XXc4y9jp0LABBk20/ubZmo921i+4TdWzNF/ITIknueE2bHg31QukoE2T2DbCccl/sDuUbYS+kxckPub+Gjthbq4ItHjpBaG7m/kGPPjvuxul2e3V/CHbZY0MJXGmnq+gHSmQSe2/KvOHz4MEpLS/mGvPs+H/inxyGZTGL9+vW47bbbutTnzJmDNWvWmNcnEgkkEonO/29tbQUAhCIxhAreN/hwOfLZAnJAo7bmsAssxtfJLlDPgw+yLAAEyJ5mF2Iugw+n8BQcfITJNpGv7wIhMvggNTe9MfgAGXyAHCM3wYD3wQe7cp1Cb4OPYMxl8MF+ifXC4CMcIRdJhB8Qdn0HyDY5Xq95AA657r0OPoJBl8FHnum5fAYfAbfBB/tM7P6Uy+CDDXrJ8mwfAwDY4INcNzkNPkInx+AjlCE1l3WGkqTGBg9s8OFyLgbZvYCcD+GM3dHhMB98hF0+gJfIRI8HTg8cOIBMJoOKioou9YqKCjQ0NJjXL168GKWlpZ0/NTU1Pb1JIiIi0of0WuC0+8jHcRw6GlqwYAFuvvnmzv9vaWlBTU0NQmmny7cdg67bSd9n3pA/mton4gnyypPbvrT9Hm5gyH6vHHH7a5BHb6Xs+xx1+GlSHbLD5oGhorze36u1Cfs9d31qAH3tmIL9pja+wOU7+TwcyBw1tVz2B/tM1SF+Lg8NF3vfsG5WtPan9Vfa7MB/UcUrntb5iyP8K9bPFTeb2qjo9ab22KVL6PLLDk43tY+XbjK1ydHDpja4F87FjMP/+r2q3Z5PZ0UP5bVNCceeD9FAxPPyO8i1nCJfRY2O8G1qy9q/ft93eKypfbP8Lc/bxO5jVXmcywD/nPsz9nicG8vv3nii3XfYXp9XlWw1tf4h8u9g4Pt+VdsIU7um3wFTY/sYAK676mtd/j/jEo9genzwMXDgQIRCIfMtR2Njo/k2BACi0SiiUZfv/UREROSU0+P/7FJQUIApU6Zg1apVXeqrVq3C9On2bzEiIiLy4dIr/+xy880344tf/CKmTp2K8847D0uXLsXu3btx/fX261YRERH5cOmVwcfnP/95HDx4EN/97nexb98+TJgwAb/73e8wfPjw3ng7EREROYn0WuB03rx5mDdvXm+tXkRERE5SvTb4yJeDrnOtTy+xMxaAk2dmC5tFUk4mZLsllfNNhHs1KuLP+7hhswmasu2mdub7esC8a0rBYbrOdQnbGIK9T9alWUWbY1P/KbJ8LM+ZRhNIv4NELg1JPNqb4rNddreXm5rX2QmjIu+4vJvd90OetfvuF7POpkufXbzD1ObE7SyQJtJDIReNZKYSm5kSIr1YALf7UH6zbXKZ2cLU5nktP37UThA4u9Aej1z0xn2MzT8qCZJGGej5GW5+uqGs3tTuO3y6p9cBfN8PCPNZLN25nUvJfl3P0XTKpdEVoQfLiYiIiK80+BARERFfafAhIiIivtLgQ0RERHzVdwOnwQCc9z3EaRhpVZwLr4EygIcR3YJmXg0M2TBiW9Z7OIfZnLRBzKHkiJYGvQetmkm4szjAO9Dmu0+YI44N7vUn25/Le59rs6mUW1y0NNDzQbX1CRuIKyGPRo27PM2KR0a9OT22l9Y3tAwztTfSNmhWRc6xKVGvT6ADCh9fb2qj79pHX3tFSZOndboFtb3y2vZ8DwngAkBFLzzq4EjWPvK0OOjxZO4BDWnbMn9clB0n79uUb8t4hoXkmzJtpsbaxQP8OHk9dm5txweF7EVyKGsfzvZ6kl/JLFTNxAL2dX9o59t+YaH9ffPRWAt5pb2WX0va/QkAmVjX+3CGPOTPjb75EBEREV9p8CEiIiK+0uBDREREfKXBh4iIiPiqzwZOu/tK2Zsuf+ItrOQ1UAbwMCMLobaTzpeHSagIAIaS7nKleQ79KkJ2m0qD+XVVjJDYZW8ES914DcemHBueyjfg56dIwB67jGO7dLaSGpDf5x8TOUDr55W9ZWoXkCzhs+32fDjq8MDp3LgNTQbH1ZnaRwpX0+UBbx0xD5BA+cAcrnmvYgF+PJpJOJR1vC0M8P3ErjEWLu2Nz/mc3XRXRQF+f/NqT9oGystJ0DrfAHEuy7Ngr9drya3zJ1vnMPo7gAU+Aa/dWP+hxHacfS3Jz7E9aTuZgJ3PcRI4XdHMOxCj++I5NBrWNx8iIiLiKw0+RERExFcafIiIiIivNPgQERERX/XZwKkTOvbzrny74OWCdcLLkgc3s451R7O9M55jnUcjJKTGOgh2ODwklkvn0w8DFuL8oHp38aD3Lp+TCmyYkIWa3byessG98QXejmd9uh+tT47tIlV7jpUF7bn4T89/ia5z7kU/MbW9F5abWi6Pf2f76dVkiX2dS/rtrIJWU/MaUMwl3Mm6oXYE+Lnkdb3ezxDvWKj4WH0nqXo7Tm7dRFk3UoZdcyzUCwBtju0CzMKdrOspwI/9PnLs2CPpWedsAGjI2MDqJHJ7yOUezPYJ6z59bsztd5D3a6y7K0rX0fqzqRld/j+Y4h2ZGX3zISIiIr7S4ENERER8pcGHiIiI+EqDDxEREfGVBh8iIiLiqz472yUbAXpygstrSZt0Pi1ik8IAb60bJLtqWNjGxL3OjMgVa3vOsFlBbjOFWAvgVjKDp43MoAGAEJlNkG9bZDaT4W2SUq8IsWPnvb365qSdseE2W4SdD+x8GlvgfbYLw1pss+0EgCC8p8rNOhNDaD3r2PefQWbATI7afb+dzGoB+OyrI1P5Z/KK7adZhbnMA/F2jrJW5rvS/FoaS8rNWXvelIe9n6Ps/ZNkZocbNrsj3+uTWZuwx/hwhs/eOT9mP9MBMjOmPGjvtx0un317ys7eGhKy9zG3z87u2fsz9oBWkd+Wbo/tGNwLT3pg9yF2fYXy/E6Btdvfm+L3jHBbt32X9v77T998iIiIiK80+BARERFfafAhIiIivtLgQ0RERHzVZwOnTuDYT08ZELJhJRbgAXhrYK+ts49kbdtrAOgXtOFUFpxza7EdDdhDxYKYpbCBnxhZFgCKyTYBNm20K82DXqVB+15HSVviMhIeO0yCrQBwgAS9yslhyrfd/vBwfidXloRtWQt8t/bJ7DjvTtvjmXG5REdHjj/cWlfQQOs7U4OOe51u/nHnHFPLtvrzqAQWCgaAanLs2XFiLdtLgrzFN7s+x+cZQE6RgOVQ0uLbzd4MC4TntUnUhIjdzniUh9QBu0+Geby3RgJ8nQUB2y4/FPDeBp/9HqgIsVA0n6DAsBArC4cGc/j7f4I8JuMNEoA+x/tmUrTdfqyJvvbH0a7bnwl6/zz65kNERER8pcGHiIiI+EqDDxEREfGVBh8iIiLiqz4bOA1kj/30FLdOdAwLl7IwYXHAJnvy7SDY7tiwK8DDocNI+IwFGY84PAQbJh1B2ftkSAgVAIpIYJYF71IkBOsWnCsI2A6IETJGZp8zTd4H4KEuHrb1zq0bqlf7SFi41bH7blIB386VbTZoNiBk992UqD2X58R5cO/Lu0ea2ldK99LXevUvNb8xtY8/ekte6/SqPl1K64NChz0t/5GYDfhlXbrosvB4vlpJ4r4qh+XLSSA8F15Dkx3kdVFyLgPe99MeElwfRLsa83s7695cGODBVrZNkYDd92yb3O5jLMTqNsGB2Ufea3va/m6pDrFQdX6B7t3kvTckKulrM7FugdOQAqciIiLSR2nwISIiIr7S4ENERER8pcGHiIiI+EqDDxEREfFVn53t0tN2pGyCtyTIW2wfIrNsYgHbQrg0bMduLGUN8NkVTWTGQyTP1HwWZDtdWnx7dRr5nAAQIuntfNue5zIrqbuQy1ia7Wc2KydEEu4Any2TS3KdYSn5oTksz2es5NfO+8FhL+S1PFNFPmfsAG/X39OKgnyWl1dsFoTbUWczQ5rIvcDt6t5F2mRXkEdC5KLcZXaIV+wcZ4+PCJFHDeQy+2dbys7SOpSx96yhYe/XHLvfsmME8GPan9wz3WbT9QZ23bxBnkhRG/Hebt+rvWnyqIF2fndKR7se+4zL71RG33yIiIiIrzT4EBEREV9p8CEiIiK+0uBDREREfJVz4PS5557DD37wA6xfvx779u3DY489hksvvbTzzx3HwR133IGlS5eiqakJ06ZNw3333Yfx48fn9D5O6NhPT9mbIa1pwVrTAqPzCPHk0rZ7e9ru/oMZHrh0a4ndHQuJscAlAHSQFuWDSXt41m4eAA5kbFAsGrLBORbCrU/z3vklQVt3a2HsFWt5n0t7dhYcjJJAHWu3n2/bbdbSGfC+T1g7bBagBfIP0XqVKvYeSsvHuAgPf4MEJNm5PDCH8DPbd7mEpwfSXZ9fgLjDsQnFfAPh+T4+ghketp+zNoffTF4D5W73MYbdC3LZd21Z+5iMXN6fiQXY74D8jidzbsyejOfGXqev/XXso13+v1cDp0ePHsUZZ5yBe++9l/753XffjXvuuQf33nsv1q1bh8rKSsyePRutra25vpWIiIicgnL+5uPiiy/GxRdfTP/McRwsWbIEt99+Oy677DIAwLJly1BRUYHly5fjuuuuy29rRURE5KTXo5mPHTt2oKGhAXPmzOmsRaNRzJw5E2vWrKHLJBIJtLS0dPkRERGRU1ePDj4aGhoAABUVFV3qFRUVnX/W3eLFi1FaWtr5U1NT05ObJCIiIn1Mr3Q4DXTrFOk4jqm9a8GCBbj55ps7/7+lpQU1NTXIRgIIRI4vmMbChDNidpyVcvLr/JmvKVEWQPIWLM1Fb4TEAO+BPBbCHZtf9ooGBGMugUn2/rx7JR+LDyYhWr/kG7ZlITm3To+NZJ8mHdtls4jsu1zOsaND8uvcyQLM7HP21nnvl+Zsu6nl0q14V9reP0eG7b5Lkfsl4H3/sVD0IJfuquw4eQ1yunWPPkq2v3/I+w2G/b7IN6ybb7iUqQ6xjr0n7t4EwGa3c/iV3aODj8rKSgDHvgGpqqrqrDc2NppvQ94VjUYRjebXBlhEREROHj36zy61tbWorKzEqlWrOmvJZBKrV6/G9OnTe/KtRERE5CSV8zcfR44cwZtvvtn5/zt27MDGjRtRXl6OYcOGYf78+Vi0aBHq6upQV1eHRYsWIR6P46qrrurRDRcREZGTU86Djz//+c/46Effayzybl7j2muvxcMPP4xbbrkF7e3tmDdvXmeTsZUrV6KkpKTntlpEREROWjkPPmbNmgWHhNDeFQgEsHDhQixcuDCf7YIDwDnORojrkzZQd040v8ei90bHug8LFnAMuiSTvHYEzaX7pNdt8qvD54nm9jlZR04WQs1XNs+MXAc5diw06WfglO2nUnJ/yCW0mEu4lJlU4L3bMuO162u+oWiv3LpHR2jnT++2pWyQdWxB3wsr57uff3XULl8StKHmMlLjkyPyo2e7iIiIiK80+BARERFfafAhIiIivtLgQ0RERHylwYeIiIj4qlfaq/cEJ3js53jEAqx9dH4R+w/LzJaEY5PjGZfZTW3ktSwN3xdnkeS7TTtStqX09nSpqV1YyFuZnyzynbHBZOO8nbdXrI1+YeDEXp9sptDJLk6OM2tFzmao7SMt1wEglmdrfibf87E6fJzTKuHe8r0+bfdTivxdP5cZSWsT9n57TtT7Z7+0iB8TK4drqfuvhhyenKBvPkRERMRXGnyIiIiIrzT4EBEREV9p8CEiIiK+6rOB02wBcLwZspF5fqo9JCxVEbKtjvtikDJfNLzlkseK5xJM8gFrmQ70znGqjdhWxbWRkztcyrRlbcgtGsov4Bdp8v53HhZwDJK/M3lty++mOWtbSr+WtOd3EvxcKgrYxy+81D7K1JrSPJh6demfTY2dY0+02YDizNhhuk63duRe5ROyH0jul4D3a5EF3/MNlrrJp4292z4e2wu3xlzCpflg14LbPgo4H/z/H0TffIiIiIivNPgQERERX2nwISIiIr7S4ENERER81XcDpxHgePNF+Qat/s87F5ja9JI3Te2zxS2e17k+YQNpkwvs7ncLzu0mIdiSXugWyLh1KzyUteGxoeSMyiXQ1ZRpM7XiYNTUWHCtLwaA2XEDgKeOjja1SdF6Uzs3dmI/U2+cT7lg10PcYxLdLYDMwox70vZ18aB93bkFbsfDbtOEgu2m9pmtl9Kl/9w03NQ+MehVU/vha7NM7Zwhu+k6q6LNptaWtdv5ncHP0eUZr+dDvtdib4VLTxasc2q+v9e8CrnNMCCcwAf//wfRNx8iIiLiKw0+RERExFcafIiIiIivNPgQERERX2nwISIiIr7qs7NdnOCxnxOhJnbI1HKZ2cL8tmWyqd12wLZfbu7gieb+MdvytqTAJqIvGvCaqZWF7AwSAKgM2zT8mdGjplYVtm2eAaA8jxbIm5P28wDA68lKUzs7ttfUhrlsE8PaBf85YZdvSJfR5a8uOejpfR5uGWxqd/zxK/S14VY7GyBdbvfn2WN20OVvHfKkqU2J9nxP5wMZez4MDPEW4V4FkzYSn29rfDY7oM1lnRnH9oCOk5R+hNR2pPjsJdYKnV0Ltw23xw0Anm4db2oP7zzP1NKv9zO1Z5tPp+usrrb3sQPNdjvHFO6jy19Wss3U2Mw3t/tDPnpjtofbOcbqT7YNNLWiYMLUjmbtTDwAaM3abX3q4ARTe3nTaXT5km32V3PqvFZTWzz5MVO7tIifo17lsp+7/47O5Xe2vvkQERERX2nwISIiIr7S4ENERER8pcGHiIiI+KrPBk7h/O2nF7EgIgB8rOh1U0s4Nvh2KGMDSBuSNqgEAE/tHWtqDXv7m1q0xK4TAD5S+ZaphYNZUzurcKepDSJBKQBY3T7S1GIB0lLaJX+UTwvk8QW85fr4AhbszS/Qxtq7TyPB2v/bUUOXf7DZfs7ZRbbd/oiIHcs/9okf0nVOjtqg2i+OlJraqiYbUgOAH+3/mKmNir9jahtbhprat4c+Qdc5qcAe6NJeaOnMDvGBDL8WvYYZWUhul0uoOR6wAUMWGGXcAqdvkToLrM4q5O8zq3CTqd052NYw+QM37+/61v5JpuYWSN+SLDG1DGm9XRq0+9ktKHwiH4GQyzZNIyH31qy9vr+587N0nU0d9p7TcMBe34EU70c+7rP2d9CEErtNvz54pqllnL/SdeY7aYLqvksUOBUREZG+SoMPERER8ZUGHyIiIuIrDT5ERETEV302cBrMHPvpTSESngKAGAmkRQM20DYwZMduc+O2Mx8AzD3jl7Z4xt/ZwOPCQqA8GFobaSRV74EwFtiNB2yXzSxsMHZrih/c6pCts46arJvol/qxz8OxgOL8/jvpa1m3xZcTNjyWIe39WLDUzeeKbcfZzxW/6Hl55tmiN0xtY4cNoQLAb1sGmNpn+m00NbewsFehhE2S53upJ0i33ZRLu8UNyQpTq414C+PZM/mYUR4DqyfaoopXemGt9pp36ybKtGWTprY3Y5cf7eNflXel46ZWF7H3u3tq/4suPzqSXxdg72ww9aUOvu+v2fVRU/v8oLWm9tGYvRbiQd49WR1ORURE5KShwYeIiIj4SoMPERER8ZUGHyIiIuIrDT5ERETEV312tksgc+ynpxzI2Hbau9J8FshpEW993U9kq2AAWNpcbWq/a5xoasUR3l79ysEvmZrbbB2GtS3n7H6KBWzCHQB+cGCGqQ2MtJraV8peJUvz7WGzcl5N2lkoO1OD6PJvdtjZEbvby01t62E7A+e6PfZ1ABAosPMmbjv7KVP7SqltqQwAGxP2mLKZNbMKyfyMwgN0na8k95jaM0fHmNr4gl10ea86yu0ss3KXNH0juW4Hk9lPrNX/ZJeJRqeRWV7s8QlsnfnOanF7pMOSg1NM7dnGOlOrf4c8kmGTnZkBALHp9ji/dNZ/mJrbfYy1+2czshi32S470vb+sjdt27iXh+x5y855AGjM2GMyJ25nP7nZlrLn2P/cfqWpXV693tRiQf4+teF9psZm/b2ZStPl85lRdm6MH8/SKnt/uX33Z0ytYZBt6//l0ga6zkxB12s54/AZpIy++RARERFfafAhIiIivtLgQ0RERHylwYeIiIj4KqfA6eLFi/Hoo4/i9ddfR2FhIaZPn47vf//7OP300ztf4zgO7rjjDixduhRNTU2YNm0a7rvvPowfPz6nDQtkj/30lA2JMlMrcEm0lgZ78I3/Zm3CBpM2tI8wtdfbq+jyq/ecZmoTB9sw4hllNjT4+E4bQgWAH3ZcaGr/Ttqbx0I8VDWldLep3TrAtvNm3NoPX1/+gqnV0pCfDWR9a/8kus5fvWXrc2ptW+JVO083NQCo6X/Y1O4eadvlP108ztQexWS6zsbD9jO9nbRhwk+/wT/Tke/ZFuntA+3lHLzGhitfnPQoXeekAttyflKe4VImXWQD3W7tm+OkdbdXb6WO0HpJ0IbiBpN2+7kYveyrpsbuX1mecUe22gYxQ2F7LQ4deNjUPn31c3SdP1xjr+/pf7FByscn/YQuHwvYIOuPDw8xtc8UbzW1qjAP5o4mx3l0hN1vczke9v7Ejv2ifZ+gSw+M2teOL7OBUfY5Hzpsg8IAcM6fP2Zqhw/YfRLdw8/vxCAbRI002yDptmvvp8szYwvs8Xxk5BOm9lDLKM/rdLrdcnLoqp/bNx+rV6/GDTfcgJdeegmrVq1COp3GnDlzcPToe2nhu+++G/fccw/uvfderFu3DpWVlZg9ezZaW+2MBREREfnwyembj6ee6jpV56GHHsLgwYOxfv16XHDBBXAcB0uWLMHtt9+Oyy67DACwbNkyVFRUYPny5bjuuuvMOhOJBBLvm0LV0uLtAU8iIiJycsor89HcfGzOd3n5sV4GO3bsQENDA+bMmdP5mmg0ipkzZ2LNmjV0HYsXL0ZpaWnnT01NTT6bJCIiIn3ccQ8+HMfBzTffjPPPPx8TJkwAADQ0HGtEUlHRtSlTRUVF5591t2DBAjQ3N3f+1NfXH+8miYiIyEnguDucfu1rX8Mrr7yCF16wAcFAoGugy3EcU3tXNBpFlHRmzIaBQA/2Xx0Qsl3spkSPP8wGAOf99bOmdvRp2w0TADKk22L7GBsyKyuz2wkAR9vttv50OA+adXdj+Vpa/58NNpD2wtu1ptZB3hsA3jw00NTOL7KhrBkx72NcHi71ZuW9tjsqAET62XPvrAk7Te3xvTw81lbcZmo0nFm+3dRuJjUA2J22IbeBJIy3p4wfu09cfaOpFb5u93PkiUpTG//cPLrOz1xur+VFFa/Q13bXluUda1mQNJTw3gWRYWFC1nk07vI2rEOqV9Nus8FSAIgMsW+2+cYfeV7vT1vstfS/X59tas9O+JXndd58iT33vtlwpqm5hUM/Hbbn/XfesfeHew58xNSmFO2k67yipInWe9pFT33D1EoqeAB53dk/NTXW3Raw++lbA+39DgBKyb6rHGu7w6ZIZ12A76dvk+7VUxba8/HGm20YHgC+1M+Gz9n12ZjqR5enumfHvTUHB3Cc33zceOONePzxx/HHP/4RQ4e+l7qvrDx2o+v+LUdjY6P5NkREREQ+nHIafDiOg6997Wt49NFH8cwzz6C2tusouLa2FpWVlVi1alVnLZlMYvXq1Zg+fXrPbLGIiIic1HL6h40bbrgBy5cvx69//WuUlJR0fsNRWlqKwsJCBAIBzJ8/H4sWLUJdXR3q6uqwaNEixONxXHXVVb3yAUREROTkktPg4/77jzU0mTVrVpf6Qw89hC996UsAgFtuuQXt7e2YN29eZ5OxlStXoqTEPrlQREREPnxyGnw4zt9PkwQCASxcuBALFy483m0CAGQLgEB+edAuWLDH7RHNv2u1XSWbM7ajZsOuAXbhMbwb6NljbfjruqpnTW1lC+9GGg/yQJ8X29N8R25vtdv/yjn2kdtuLn3j46Z2OMse722Dtb2h6aP8fbIJe+yv6WcfN97vEz+jy1eG2GPEeVDMq2EuIb/uWEdIANg+m3SltPlE6qk2/qz5mvBhU9uTJl02yba7dShlhv+ONBy0LYBcvU0eod6QsV0yOxz7SHgAaHPs8XyRdBte22o7PTZewK/vlz/+r6Rqg63fP1hHl//ptnNMbXh5z4czJxfZrsS5mFNiH7f+7/tnmdrWEO/UDJ8Cp8Gj9vp0u7ftSdvfA1nYmtdrFgD+dNieO1nyuPkz+tmO1MfY/XTnYLvvn2m2Ifv/8+//QNf4pW96C0DfPODPpGp//wEAun+kHLLkeraLiIiI+EqDDxEREfGVBh8iIiLiKw0+RERExFcafIiIiIiverCBec/KRh0glkOv1vdJOTahnyEx3IYMbyMbCtjk/IUlm03thk/adtS5JKKZCws35rU849bC96HTfk6q3rd/av9dpjYuYmeRsHXuIe3FAT6TwquVH/khrf/4oG3/zFxaxLeJzWxJOHbWA2/J3Pd8Is5nebkm2ntYIJk2tVzOhwtsZ3uwv0fd8c7pdJ1/Itf3V/qvN7XPFNvnTN075GW6zozjbd/dOuANXj+P17343Hb7mASAP/5g9IB3TO3j8d/Q5QeSNvRPNE82td2t5ab2+UH8sQB+GTTG3ofWJ/iMwWeOnmFqLzfZNvL/Neppz+//4PBVpvZX8vYdjvd7xoGMffTGlxf+ytRW7D2bLv/P9XZmzI0VfzC1SQXe7wPpbtdiRrNdREREpK/S4ENERER8pcGHiIiI+EqDDxEREfFVnw2cZgoApwfbq8+IsXEWD959Iu41/JVfuLQ3sJbx5UEbwAWAqjzDsd8e+LqpNWdtOLMta5NW+QRL3YyK8HXGQ/b9X+ywocODpG03ACx9e6ap7TxkQ3bZrE1btbfQdCQiDTZoFuqwy3cM4e28y6tti/BHJj5samMLWLv7/GQcu++y4OHwSMCeD62n2aC32/nAzufJUd4evrvvDNri6XXH2HBlLkKBE/f3uO8M/S2tv1NlP9PISIupDQx5vxY/XfoXU/ty+RpTGxbmocVmci8IkckAxUF+3Xj1kcq3TG35oXPpa/+laoOpvUh+B6wgj6O4vPggXScLn5/j7bR1xQLAXy5tIDUeIOby289OtxEEmevhSt98iIiIiK80+BARERFfafAhIiIivtLgQ0RERHzVZwOnCDjHfo4DC7n1Bha8W5fg2xwL2K6OL7WPNLVXjw71/P41sUOmVhpqM7W6qA0lAUBN1nbMyzfolSD7ZEfajnEn5xm+ysU/97ddKXnA0e47AJhY+5+mVjs6v8BsI+lWeNjuOoyOeA9CZhx77DYn200t6BIOZeHUpozdJ8932M6ZoyI8eDeedEtsH2DPB/Y+AJDphVsUe6/+IfvZ2TFKOnzfvdxRbWqvkVpt1HYYBYCMY0OXWY9/N6wr4Nf3rEJyQuUZkj83xu6t3tf540OTTO2SkldMbXyekw0u7287rNanbGA0F789aDuhtmS30deGYPf97qR9/1HR/XT5EQW2Q+vLbaNMbWSBPZ8+W2xDxb0l2+3yzNpfc670zYeIiIj4SoMPERER8ZUGHyIiIuIrDT5ERETEVxp8iIiIiK/67mwXJ3DspxexNDvAZx3Uhr3NAjmY5bMTUt370Lo4Pc6T6x8vtq2ic5kJweU3s4XZmbYx9Q3tI0ytIrSVLp9vy3cm31butS5t2/MxmLRKHpznJC3W4pvNNskFmwXy6SI2M8X7+2TD9rpm7wMAcToLxttUCDYbDQCOknp/8jp2jNwMJTMMMkWHTc2tDXtz1s5KSpHtLCWz0fya3ZcLt9lL0aB9XECJy+Mf8nFO1LY3X310kMur7bFjj+OYMeJZz+//+FF7PmfI3/V3JAbT5Q+RRz2EyCy1Txc1kaW9nw+vJe1xGhCy7+N2LWQjXV/rZLzPUNU3HyIiIuIrDT5ERETEVxp8iIiIiK80+BARERFf9dnAaTAFBI8zR8VaSrPgnVuIJp/g39x4Rw6vPpLDa/MNl/qjLWv7prOgVX2G91ev6oNnpNd23H5KODa4Fw3YkB2TcnjAz2twkQU53YKUTNF+7wFD1vLdK7dtyjeAnO/7M6XB/ILBJ9LahD0XQy6/WmYXvWZq3s5aYFuKTxDwGrw/PbrP4zvlj4eyWW1vnu+UX9jY6yMV2DEGAHTPjucwR0TffIiIiIivNPgQERERX2nwISIiIr7S4ENERER81QfjfceEOgIIHWeH0zERHmbMB+tAeDKHxADgAOnw2py1HeqGhfnnPJCx+2RWoQ3zjYzYkNlGl85+a9FsameQhpYsXOnW0fKJNrtNPBDmn3wCo26vZedoLGAv8Vzeh2FBStYpEeCBtmSxXZ7tDwDYm06Y2rCwXWcu4c62bNLU4kFvXVP95DXonG+AOJf3DwbsPbkubO8ZGdKNEwDeTNkOrSknbWodjg3jDw3ld4xY19BjTuy9oK9h59g5bqdS98PsvcGpvvkQERERf2nwISIiIr7S4ENERER8pcGHiIiI+KrPBk4DaeB481JNJHi3NWVDk+yxyQAPcP36SI2pfb7EdsxzC/OxQF0zCb7l8hjvfA0k7zUwh31e5bFT5N603fe7kvzx1qGADY1GA966xrqFDgeHWtmrPa0TAN4hIdz+ZHF2jFvJMQb4vs9XiLQXzDdcyrDro4AcNzdp0rTUbTtTsPvvILm+c7luvIZL96Vt6NHrOQ8Ab6Xs8qMi3pdvJQHq/uR1vREsBYA1iXJTGxM5YGoZct65dR1NkSDp/ow99uUh+5nyDQVvbhtC6y8WNJia2++GvuZET4QIOB/8/x/k5NjDIiIicsrQ4ENERER8pcGHiIiI+EqDDxEREfFVToOP+++/H5MmTUK/fv3Qr18/nHfeeXjyySc7/9xxHCxcuBDV1dUoLCzErFmzsHnz5h7faBERETl55TTbZejQobjrrrtw2mmnAQCWLVuGz3zmM/jLX/6C8ePH4+6778Y999yDhx9+GKNHj8add96J2bNnY+vWrSgpKcltw9qBkPcAfRfvZGz6usNhaXrvbYlDJMb7atLWasK2ZTnA0/iDQ/nNRNhB0vSpHJLnzMMttu35RfHt9LVDPSb/z43Z/Vke2kJfW0aHw/nNDDnqsJQ8P/bMuo5hplYdetvUgmQsH8tzJkIuioO2dXVvOJK1Lc9zmcURO+Q9Eh8h/ZobMva2NTjP3cyupb0ZOy1ne5rflNjsiFz2CZMiu6k3WsNvT/NfAyPDh0wt389UErTvtSlp1/nMUTu78OZyfh/yanzcXrMAUBexM0byvef4Jet4v5Z65bECfrVX/9SnPoVPfvKTGD16NEaPHo3vfe97KC4uxksvvQTHcbBkyRLcfvvtuOyyyzBhwgQsW7YMbW1tWL58eS5vIyIiIqew4858ZDIZrFixAkePHsV5552HHTt2oKGhAXPmzOl8TTQaxcyZM7FmzRrX9SQSCbS0tHT5ERERkVNXzoOPTZs2obi4GNFoFNdffz0ee+wxjBs3Dg0Nxxq1VFRUdHl9RUVF558xixcvRmlpaedPTY39uk1EREROHTkPPk4//XRs3LgRL730Er761a/i2muvxZYt7/37faDbI5cdxzG191uwYAGam5s7f+rr63PdJBERETmJ5NxevaCgoDNwOnXqVKxbtw7/+q//iltvvRUA0NDQgKqqqs7XNzY2mm9D3i8ajSIajZp6IHPs53i8kRpoavWpAaZ2YaH3gc7EqA0rDQ/bdE1p0L+g0qCQPXz5tlquDDebWpvDB48/a7X7dHzBXlKz2+kWgmWhqHylHPv+Kce+j9u++0n9DFN7p+oVU5vff6fnbVqfsO/PgrEX+JMhzQlrNx8MsNAeb/Ucb7SffQ9pZQ4AtSTg+GKHDX2+lrQtwscWkD7uLoqC9hwfBPuZKkJuf1+znzND2qOnXYLOrL38QNJiPPQBf5E7XlOiPHT4cMtQU0s49p5ZHU6bWn+X8HMbbc1va5Hjvfn/DTsf3knzSQ/rEvY+VhK0j3TI5VrMN9x5JGvfP0PSnP1D3s9xr+cO2/a1CZcP71fglL634yCRSKC2thaVlZVYtWpV558lk0msXr0a06dPz/dtRERE5BSR0zcf3/rWt3DxxRejpqYGra2tWLFiBZ599lk89dRTCAQCmD9/PhYtWoS6ujrU1dVh0aJFiMfjuOqqq3pr+0VEROQkk9PgY//+/fjiF7+Iffv2obS0FJMmTcJTTz2F2bNnAwBuueUWtLe3Y968eWhqasK0adOwcuXKnHt8iIiIyKkrp8HHgw8++IF/HggEsHDhQixcuDCfbRIREZFTWM6BU784wWM/79rnEkirIl02P1ZoO/OtCaTy2p5JBX0v+cc6WtLApkvOKEXCX7Ec9tOQcJOplYfs8k1ZG0hryPBwZ4gklsbn2YTvE3HbkRPwHsytitveM20ZG5JmWOgQAE6LkJAdWNg2zw/fC3LpmMtkCmzUzGu3XAAoC9rj+U7WBu/GuizPzvsM6RQ5KGi3kwVo3YQCdvlQDjG7ELlwWTD1LdKdFQBKSIiWdVp282aHnSgQhD2fXyGX1+TYHrrOSQX2/aNR2xU66djgei5Y2LimjD/q44WOUlM7lGHno93PbkFpdj6zewE7R4De6VbMzh2GBVNnFfL7WCjR7bVJ74FoPVhOREREfKXBh4iIiPhKgw8RERHxlQYfIiIi4isNPkRERMRXfXa2SzoOOO+bUFAe8ja7AOBJ4Tnx/Ga7eMXa4gLe08tu7cVZa16Wns6SNLob1k6ctfiuDfNtHx1h7+Vt1kJ9mn/OSS6tnk+kOeWvmhpP89v95JZmD5GW9W2OPUejpDW823qbs7YdeC6zM9i52xup+1DSnjdNGdsOG+Dto4eSXRLJ2BkTAJ/Zwc57NmuOYW27AWBkxM4k8Dq7wA1rp82MIi3oe8Il/Taa2rkxb7PEmkkLfjdtWTv7qCFtZ6AABzyvk3E7l8+K2tmR72TYdWuvpYJeaHefi3yvefb7JuHY2YnRED+XI90m+5CJaK70zYeIiIj4SoMPERER8ZUGHyIiIuIrDT5ERETEV302cIoAurQFzze81RvWJmxAMOvw7ZxQwIOo3QVzGA+2OzYsdJi0Mi92WeUBEtI7m7Q6jgTya6fNjO17h9NVUdDu558cPN/ULu+/1tRqwjygOIwEHPONDUZIy3jWersqxEO9vREupUgWMeUxXAnwtuMsFJ1v+JthbbvdeA3zATxYm0twMB8bEzwl+KP9s03t3OHPeVonOxfdsLDvNf3yC5fmgrWcH+xx83NpV3+QhEP7u5yLLBTN5HuOsIkM8Vwe6dD9Uswhf6tvPkRERMRXGnyIiIiIrzT4EBEREV9p8CEiIiK+6rOB01AHEHpfBs2tA2I0YD8CC9EwLHAJAAM9hojOIG/TluXhreKg96CaV60kXPrX5EBTa8420eXjARvy63DseDSI/PYTfW+XY5QgXT6ZXALIjeQ4R0mHULfw1pCw3X+Xlm0wNRYuXddRTdd5KPKOqU2Oeu/i+xzJUobI5dyaLTG1howNvgHADL/ypiGbSjuY4Uk1FvxjgVF2Lbv1+vUa7GWB0ZBLR0t2PuYd5iN+ddRufSTAQ6wfjbV42qbDWX7e/6VhqC0O/zsb+AHvA/CQ/oiw3c+5BDnz9WKHPVNmxOz9YU/ahrfdzjF2d/LaRTdfrPM1ADSRwGvc43nrJtXtMGVyGFHomw8RERHxlQYfIiIi4isNPkRERMRXGnyIiIiIr/ps4DSQPfbzrr8meVhnVqH3R8h3d/xLHsNCZlsz9vHQAFActHWvXezcvJO1h29unHV1zK8L3q37J9N6acgGmAZGWk3tK6V7Pb8X26ebk/Z9TiOJrhc6eGLy+pdvMDXnbbtPKibup8t/r+5XpsbPO3uOxgv30XVuSJSZ2tLmQaY2JGIf9w0Ag0J2Pw8iz7PekLbv05i2IVQAmBq129obnYUPjbHB2uYsD9tuS9kg6eiIDSPGyLW0NcX/brU9Za/FSQW2xoJ3LIQKAAeydjvzCWS7aUjZR81PjNXT13oNDrrdQz9Tu8nUWCB8f8aedymXhrXr2sea2h8z9rr9StlfTY11gc3FfYdraH3JxgtN7T/P+3dTY/froEtn3lgg398u1mtJG2gfHbH7LkTC9ID387GZBFPdwvhOt19BLg18KX3zISIiIr7S4ENERER8pcGHiIiI+EqDDxEREfGVBh8iIiLiqz472wXO337+ZuFbn6Yve3bCr477LVqzPKmcdGwbXaaAtFpuy/IZF15ntri1xl3VbtPGf2ydbGqTKjZ6ep9csFktAPDE3vGmFgvbuHNzZrOp/UOJTbMDwKGsTei/lao0tZ812T7PLx8cQdf5sdO2mtqV0142teqwnUEC8NkVXkVckucDQnZ2xKsdNo3f6pIynx61s2D6h+xsm+fb7f58qH4GXefoUY+a2rm90HI9Qya2nB3lbcu9ztRiLdcjATbzCygL2hkrh8hlR9uju8wgybdtuldjyIwk1tb/mPzaeQ8tsOfYkkPjTG1XxwBTK3PZpmHRg6YWJ8fj5611pjYu9jZdZ33Kvv/9O2aaWuNhvj/OqNljark86sArNlPK7Xxirdx3pe3nBOyjH0ZG+Aw1rzPX2MyWh1sG09d2n2Dn8MlgfFnvLxURERHJnwYfIiIi4isNPkRERMRXGnyIiIiIr/ps4LS92kEw9l4gtKV+IH3d2OYvmtprM/6fp/d4gwSVAKAmfNjUXmwfZWqJrA3w/GOpDTceYwOnrI3tIy2j6dJ/Omzff2IJD2D1tI+X2DbLAPDn+DBT29Xc39RW7rchtdlFW+g6p0RtAGtKtNnUPlf8il24gtRykl877JRjW3S3ZXm7/SlRG+p6PWk/5zvpfnT5v5LXsjbZ1/Q7YGo/SvHg2evJKlM7N9ZIX5uPgmYb9H4xwf8eVBSwCTZ2jjCTCrynZQ9kbAC4KWNDk7vSPDh+WsR+JhaCzcUTbXZ5dm8aFs4vWOpmZvwNUxtbYFuc70v/xdRaHR4gHhW25/3zHfbX0FHHHuMzCnjwfWVLtak1t9t9d/2EF+jyN/V/k1Tz+3s5a4Xe6tjrbkTYnncAn8zw0UIbQmWTJjpcepwHyWfyOhGiOmyDrQCQjnd9/2zQpa8+3R4RERERH2nwISIiIr7S4ENERER8pcGHiIiI+KrPBk5HnbUb4aL3usz97vTf0ded9uyXTI0FxfqHbFCqMtRC1zk6YsNODZn9pnYwY4NeezM8YLizw4aNsrBd9HZ28GBtXZEN/t06wAbCeoNbwO/R01aZGgvJ/Wz/eaa26qgNoQLA5uRhU4sEbIDqUNru++X159B1/mHCf5F1egta5YKtsyqHMODVJbb749Jm3mnx5TYbQD4zagO3rFvhRdU8FD0uygLM9rxNOClT89o9EQBIThvTonadx9Zrzz0WDi0hnSJz2SbW4bSchOdKgnw7MyRQzrB9BwDbU7ZeQv5qmEuINpeOmswh0q35OdI0NgR7b50R8/73WhaUBlh3Wt7t9s7BNhDPau6O/+/gjeRcBIAUOR/OILu+mTe0Rn/asdeu89W0PUerQ7zNaDNsYLc0aNcZgg279gvy32vdM7Qkc+9K33yIiIiIrzT4EBEREV9p8CEiIiK+0uBDREREfJXX4GPx4sUIBAKYP39+Z81xHCxcuBDV1dUoLCzErFmzsHmzfaS6iIiIfDgd92yXdevWYenSpZg0aVKX+t1334177rkHDz/8MEaPHo0777wTs2fPxtatW1FSUuJ5/dcPWY14yd9PkJ81rN7U7ms6y9S+PfB1U9uWGkzXuY0E0i+Jv2NqcZIAbmNRfgDxAG9P293IAbwFcG2Ypdy9Jex3pGxbXgCIkQ7IuczOYObGbUp9zoinTe3BZtuaHQC+u3GuqWUzdowcCNqYeOAN3h79+tKZ9v2H8f18Ir3UYc+nStJOGwDOie0wNTazhfkfgzbQ+p867Myan7aUm9oB0vL9+jJ7fQF8dkWq2J54ucxMYfJdviFjz53yoJ3JMDDEr7niAJ+V1F1bls92Wddhr4cdCXt/GhFea2pu7dUTpM12HN5nu7AZK/cdrjG1EOy1OCPm/dEPbAZQxrGzOEKk5TiQ/7HPx+AQv+dEYGdcdpDPtC7BH/FRF7Ez30ZH7HuxmYhtLjNo/pSw94epUfu7gT0W4AuPXk/XGWnvdkw6+DFijuubjyNHjuDqq6/GAw88gP7933uWh+M4WLJkCW6//XZcdtllmDBhApYtW4a2tjYsX778eN5KRERETjHHNfi44YYbMHfuXFx00UVd6jt27EBDQwPmzJnTWYtGo5g5cybWrFlD15VIJNDS0tLlR0RERE5dOf+zy4oVK7BhwwasW7fO/FlDQwMAoKKioku9oqICu3btoutbvHgx7rjjjlw3Q0RERE5SOX3zUV9fj5tuugmPPPIIYjH3TnuBbv825ziOqb1rwYIFaG5u7vypr7cZDhERETl15PTNx/r169HY2IgpU6Z01jKZDJ577jnce++92Lr1WNvmhoYGVFVVdb6msbHRfBvyrmg0imjUhrWGhJtRHH7/2IiH6c4u22lqj7xp22xPjduA3sfjDXSdDzWPNbU2Z6+psfCWW/tiVt+dtmGfUWH+OUOB45+YVBvJL0SaL9YW+PoyHkgbMeXnpvZIo23P/vUq29r9nAtOXPAsVyta+5vadzfZsO2iM35Fl59Mrhmv3AJ65SEbktvQPuK438dN0OYgkXLpy7w/Y1tC59sY/xdHSk0t69jr6wLvncw9Y495AIBr+h0gVVaz1zK7jwDA3rS9l5yb5867ocz+5fC1pD1vQFquu+kgwdhdafuXVbfW8uxxGvc3nen5/b81kD9uIB/sOLNW7PVJHjjtyNrfF6Mj3iIJWRIABoABQbufWEid7U/H5bzpGJHo+t7tCf5CIqffaBdeeCE2bdqEjRs3dv5MnToVV199NTZu3IiRI0eisrISq1a994shmUxi9erVmD59ei5vJSIiIqeonL75KCkpwYQJE7rUioqKMGDAgM76/PnzsWjRItTV1aGurg6LFi1CPB7HVVdd1XNbLSIiIietHn+q7S233IL29nbMmzcPTU1NmDZtGlauXJlTjw8RERE5deU9+Hj22We7/H8gEMDChQuxcOHCfFctIiIip6Ae/+ajpxzIxNGeeX/KhYdoPln8qqn9P9jA6YWFNkQTCfBwZ0nQdun8eesYU2Phq1wMIaGkXIKl33lnvKndMci/Vvas2+FVJTa8lYLt7OfWGfATcRtY+sSIZ8krvYdLD5Cg1+r2KlPrcPg6UyRt9b/W2XDo4CdtCLT8OX6OtE2oNrWr7n7e1C4t4mFCZmWb3f45cd5Rk2GBvo1hG3I7O7bb1LaleCJtMsnFhtvt+cBCyQDQmrXXQyhgl7dH093kqA2P70yVeVqWhfEAIEhm87EwH+tiCwCnRew9Z6DLNdKdW4fTYT7d3ccWeA+XMmw/TfLeiJWGO3sjRJovdmd3C97nY0OSB3MPZex5Uhuxnbsv2fwFU+s38jBdZ3lR1+shfTSBPR62EdCD5URERMRnGnyIiIiIrzT4EBEREV9p8CEiIiK+6rOB03gwiXjw/WMjHgbsIGHA1v02WPMfrbbDKu8qCIwhgbT6lO1E9xZ5VP2oHLqJ5tO1FAD+47Upprbyro+YWrqQt7ZvqbW1BZf/0tTe7ODdaX/28rmm9uPB9v1Dz5SZWnulDQ0CQHT8YVNrbbT7dMgw+8jp1t9X0nWS5pUYdLGNRU0bsJMu/4unZ5ja6GVNphY8Yrdpzz8Mp+u8fd7PTO1zxc30tV4NDrFw6vF3QgWAMdF9ppYif2f51s7/Rpf/3em/M7WyN5Om1pa1NYCHGXeQ6y4X7NHkq47ac2dO3IaF3TqUslAzc27MrcWot3DpkawNprJHoLt5zi6O1xM2/AwA/7HnbFP7hyEbTG35bvu61g5+3t05/temxoKQNeSR8m7Oi9ouuLvStmtqvsHYXPywyV73I6P7TW1unByQPLHfVQBwSZG957Gw797ddvlPnbWRrnP30fIu/5+K8OuY0TcfIiIi4isNPkRERMRXGnyIiIiIrzT4EBEREV9p8CEiIiK+6rOzXUqDSRR7mO0yJWr78Eb62cTt5vahptZYtIuuc0bMJs9TUTsz5s3UiR27vfaRh03tnKIrTC399EC6fO2jdnbFnSNt2/A3P/oQXf7OT236O1v4N9O8vcwNm91Qy2YVTcrvfdz0v9jOZPjHK14xNa/tsHPBWtgDfDbAp3v+7TEybK+lLSn7Rlvf5jOicLotxbbYltL7MzwlXxu01/fQsE3os1kcF3ifBIKJMTuz5bWkbaXuNmOiP5k10Btmb7ra1EqjfMbEkaSdcTKi3yFT+8HQ39LlHw2daWqVYXvPGNffzuLYdJA3vJ9Y0Ghqs39xrakFyVMBYuMO03W2HbUH2iGT6YZV2M8OACUF9pEOr75iZ6vE9tuZSiGXyR1Fs+znfGnyf/EX52FP2t4by0L8xGczW9jsqcHP22HBv12yjq7zuj3ndfn/pMt1zOibDxEREfGVBh8iIiLiKw0+RERExFcafIiIiIiv+mzgNOMEkHF4W/C/J52ywaBn3h5taosG21bBbiIBu86iYNbU3Noss0Bavu3V2fLrp/zCvtB2YQcA/OOVthV6QaIXUot5ouHSHGQce5zWJWwibUIBSbkBmN9/m6lFAv7spxvKbBAScDvPvG0TC6kBwNCw3c8sRPvHQ+NMrV+JbXHtJr2vwdRKgvxaZ23X4ySESltKx3Jp0Z0xtV8csWHf4WHbbh4AUrDLb03a2+s5UR6cZ55tt9d34+uDTO3wYX4fCdkcJX4w76emVkWOOwA8NeaJv7OFx3y2+EVb5DlpAPa93rz6fk/v01u+td8m1d/aO9LUYgftPSP9ycN0nb0RLmXYNbs30+ryanvu/TlhA9T9dni/lrPdnl3R/f8/iL75EBEREV9p8CEiIiK+0uBDREREfKXBh4iIiPiqzwZO25wwgjmEV96vttp2I93bVGpqboHPP7TbcOmsmA0jDiNhn5VtPFA2saDJ1NyCXn55aNjznl73FukwCgAXPfUNW8za4GDZZnuaJezhAAC0j7D7uf8Gu/yRC2z3yQlD9tJ1vrJniKmt+8iPTK04yLtX5mNzkoe33k73M7U5cR54ZfLppmrjt8ewcOfahO2W+MKBUab2xVFrj3t7APfPsy1lg7W1JPw9IGTPUfZ5AB5YZYHyjqy9lo84/BgNJtt/jm0wmpNZhfZIvfX5H5uaW8j9gpevM7W5G79saivO+Ald/sY3P29qvx/Lu6GeDM75y+W0/tlhG01t8432/uAnFpJnv69YePzMAu/ddv/x2X8yteBl/gwL9M2HiIiI+EqDDxEREfGVBh8iIiLiKw0+RERExFcafIiIiIiv+uxslz+1n4ZY6L3NmxLd6XnZ64atNrUF+y7zvPzpkWZTa7Tdk+lslQEhnjzflbYJ5HjQzoQoJW3Y/ZQgaf5RLu3Nd3zqAU/rPHCJ3Sd70vzUmxy1UwS+OeVMU/tB5V88vTcA4DRW7PmZLcx4l+T5eJdW7t01Z/lsmR0p+/cGtu+YWMCllTk59itbptr3bhhoakNrvLcyz8XoiJ1FknLsxVgTPmxq28g+AoDJHmehfCz+pqk9315NX3tJkf380YD3Vur5cJsp9JOzlplaRcieT26PLyiN2tf+c/0MU3v2rTpTKynm520oaFuUJ56x59PRs+zyg8p52/B3DpaYWtUgew//+YSH6PJeH9/AZq6VBskvBvC257lgM1uaMnaG3660vY8NDXv/TmHsbbtM7YY/eZsFCQCRbp/fcdkfjL75EBEREV9p8CEiIiK+0uBDREREfKXBh4iIiPiqzwZOH9tzBsJF7yXDVuyywTcAeGnyf5na54pt2Oh/brfBv3vOHEnXeXP5dk/b2EjaGk+J8vDXix22Xe6vj9SY2jX9bGv4XGxMJEzNaxAR4CG5x4/ycObhjK2z7WeBuIG2m7WrnMKlHv3qqA2EPd8ymr72Y6VbTG1uvMPUWFg3DP5B3Vr7d+cWQB4etuEzr15P8XN0UNCuMxpM223qZ8/7/akyl3ez12Iu9pH20SzoXU6CbusSA+g6xxbYbWLnPQsirmrjQcKn220rd3aOuGGfM0SCwayNu5sp5LKPBLwHIX8x8g/eXljzoud1MmdmrjC1Jyc/aGosfJwb/tnZ4yN+eGCWqdUV7je1G8rq89wm757vsMHcj8fZ9cXvLZ/c+klTc6rsYx5yOW/zoW8+RERExFcafIiIiIivNPgQERERX2nwISIiIr7qs4HTjlQEoeR7IbC4x46QbkZesNPUhhbk15WxIWPDhAOCNlgKAEUBu/2xYH6fyS8fKzxE678+asOQT7TFTG1rh+0K+XaijK7zcMqGWEfF3zG1CtKF9hd7eSi5rp9d/oLS103tnwbw4NwbqUGmtpsEBEuD9nwoDfIulyysHCUh1NZsfh0U2fvsTA7nLy6wYeHaaKOpXTR0m6ntTpS7bIHtoMiw7pEA0OEUmFoVuWsNDNlzcW+qP13na8kmU/Pa9XR8dA+th2A7d6ZsCZEADyCzEG2+2Hu9lrSh4neyPFBeF/YW9n223Z63swr5fZD5y9krSDXfcKmVcfg2lQZtsPe6Ac+Z2qAQOaC9sJ1uzibXYpQEiH98eAhdPvG/qkztP574N/JK75+pPdP1/pbMsH3E6ZsPERER8ZUGHyIiIuIrDT5ERETEVxp8iIiIiK9yGnwsXLgQgUCgy09lZWXnnzuOg4ULF6K6uhqFhYWYNWsWNm/e3OMbLSIiIievnGe7jB8/Hk8//XTn/4dC7yWq7777btxzzz14+OGHMXr0aNx5552YPXs2tm7dipKSkpzepySaQPh9EyeenfArz8seydr2sPuP2FRwa4a3rj6StW10WfvlMtJ6Ou3STjsasLMWRkRYK3U+O8KriQV2edY+GABGkfbRTHHQzmBxMzJsZ8aMLLa1XTE+EyESsPv0cMamr2NB28764spX6Tonx3abWnW41b43mbEAAOfH7PkwMORt36UcPlslTmYisP1cmud3kx2O/Uy7k7ZNMwCEAva1Y6L7TK0sZGdMvNI+7Di27j0xcn0AQAlpmw7YGTBsZsfEWM+3vp4R4wfkOdKR+rWULU4q8P5cAdaun92HcjG2wM5sqczwVv39PZ7jg0J2RtWPD59GX8vOnaNZO9UoFLAzUwaFW+g6R4Tt7CV2PrVm+b6Lk0O6NTXY1KrDdtacG3bdr03YWTVu5xOzgVy30wP23vr9520bdQAYMMr+uvfarv+lDn595iPnW1s4HEZlZWXnz6BBx6YhOo6DJUuW4Pbbb8dll12GCRMmYNmyZWhra8Py5ct7fMNFRETk5JTz4OONN95AdXU1amtrccUVV2D79mMPYduxYwcaGhowZ86cztdGo1HMnDkTa9ascV1fIpFAS0tLlx8RERE5deU0+Jg2bRp++tOf4ve//z0eeOABNDQ0YPr06Th48CAaGhoAABUVFV2Wqaio6PwzZvHixSgtLe38qamxT3oVERGRU0dOg4+LL74Yn/3sZzFx4kRcdNFFeOKJJwAAy5Yt63xNoNtjoB3HMbX3W7BgAZqbmzt/6uv9e0SxiIiI+C+v9upFRUWYOHEi3njjDVx66aUAgIaGBlRVvdfGtbGx0Xwb8n7RaBTRqA0cFRUkEbG5Mk+2pGyo61BDqaktLzyHLj9ouP2nnzoSDq0J293nFghLkNa+rCUza9sNAAODdmfESS1EWnS/nuIBw1ERkpLLwYCQ3VbWqrkoYMOhHY5b+Cthaoczdp1rDk0ytWjIhlUBoCltQ1WlIdvOuy3LT7jikN1PlWHb3n1idK+pjS/goWa3Nts9LU4G/q0ZHiAeEbGBuuqQPR6DgrbN828OnXkcW/ee8qD3vwexNtnsvHcL8+1I2SDnW6TmNZANADXkWvjtkfGmdnrkTbo8u2/sTdt935y1n30yuX+6Yfuuf4i3V2fWJ+y1PLnAvv/4src9r3Mfuefl0m5+R8qGIctD9voaFXHbT7ZeHbL3+zaX9uwMu75neM/tYweZJFBGHt1xxbbPmdrQ3/Pz/vl77/f03uwcCZIAMAAUdJ90QSZhuMkrS59IJPDaa6+hqqoKtbW1qKysxKpVqzr/PJlMYvXq1Zg+fXo+byMiIiKnkJy++fjv//2/41Of+hSGDRuGxsZG3HnnnWhpacG1116LQCCA+fPnY9GiRairq0NdXR0WLVqEeDyOq666qre2X0RERE4yOQ0+9uzZgyuvvBIHDhzAoEGDcO655+Kll17C8OHHnpJ5yy23oL29HfPmzUNTUxOmTZuGlStX5tzjQ0RERE5dOQ0+Vqxgjz5+TyAQwMKFC7Fw4cJ8tklEREROYXkFTvuqc6I2vLXg/CdMbV1LLV3+mZZxpra30HZ6vD6HUNXAkA20tTk2DFhCgnMAsD9jg161JHDKzI17D5ayTo11YR6CnV1oQ0jrk9464dUnB9D6YRJ+e6lllKkFSTfOycW2kykAXBjfZmojwvZ9WkhnXCCXQB4Pl55IW1I2bFtCArSAW0DTBv+earMBve2t/Hh65baPWXfeNQn72mnRg6Y20KV7Y1HQXne/OlJnau9E7cy7c2M8KFxLwqnjYntMza3jLQucsnWyIOK2FA/5jY7Yz8+CuW62pWzn0vKgve4ayb0p4jLDMUU67m5N9TO1JQdtoHxgxHYlBoAv9PurqZUGvV+LTaTD61ESuhxKQrCNGbuPAO+dQ93sJ923Y6T789srbWfhuf/Dva+WF0ccG3QuIfdbAIh0C6I6Lq9j9GA5ERER8ZUGHyIiIuIrDT5ERETEVxp8iIiIiK/6bOD0aLIAYdeOdLn7SqntPjmJBMoA4IbNV5ra60W2S2sugdNyEg5NkaCW2+PrNyTt8rWRnn/McQg2aFXqEmxl4bVzot7Gs1Oiuzxv05f62Y6aufHWLTGXTo990R/abRjy5aP20eaTCnkw16s/to41tV37XQKnNrudE9ZlNB6w3Sc3JPqb2sQC+6h1AGBXDbs/bE7a63Njgp/frMvohYX2nV5L8k6RYz12c2YhVBYSB4BYwIZTh+XQOfT3R+zBq4gcNrUh5JH2bh2MI+RR9xvaR5haedgGOQeFeeB0f8a+18sJ+zkjJLAJAAOCdpvcgsXdNWT46wZ7bGD8WtKGXQHg7XSlqX3zT/9gasEz7PLfr9jo7c1d/CVhw7IVpIMvAIS77bss2Zdu9M2HiIiI+EqDDxEREfGVBh8iIiLiKw0+RERExFcafIiIiIiv+uxsl1Q2CCf73thobcK2Jwd4K3Wv3BLN1532gqn9779eZGr/XDTD1L5T9Xu6Ttaad3/Svn8o0E6XTzl2Jsa+dLOpDSYzNnJpqcxbbHuM4otvWNvxt1MjTO20WIOpDQ7xWQOAt4h+LGivxWyGt9PuDVXkWtpL2lyvSwymy8cCdvuHhm3ttIi9PR7K2NbTx3ibmfdGaiCtJxw7Y4TNoGEu4BPk8Msj1aY2rLjF0zoB4Mb+XmeksXuG91kPF8S2e34tZ/fT5CifncF5nJpCTCpw2fkeDQrxduQN6VJTK3/Ofs4/3HEPWdp7a/lfHrGt7ccV2HvG2AI+E7A41PV6SJDHiLjRNx8iIiLiKw0+RERExFcafIiIiIivNPgQERERX/XZwGk6G4Lzvta11SEe9NqTtnUW7swFa7X8n4NsIOyZP000tfGzecv16fE3TO3ttEtLamIQCQmu6bCBMtZC+NNFvIWv9H1urbNZy/h+IfviS4tY8M57wI4FvZtSNnxWWprfOdZIAqMAMDhkWz0zU6I2FD08/A597ZaUXWdz1ga9s44NA3bwfCB2p721Mp8c5Y8KeL59uKmNL7CvjQS8H7vP5hAulRPjvkNn03pb1p7PLfZJCSgNeg+X3rp/sql9tmydqbmFSxkTPidhdDf65kNERER8pcGHiIiI+EqDDxEREfGVBh8iIiLiqz4bOO1uf4Z32fzXBtt59KfDn+vx91819jemdl7ys6b2891T6PKby4eY2v8Z8gdTKw66dcyzQbOS4D5Te75tFFm27wVOD7gEDAd6DBieLFiQEeBBMda1tCPbny6fIudDY9p2KwTsOnMJd7ZlvXXZbD2aX6fHCHq+Q6rbuTQG9vP/8JC9bocWHDK1j8d5N842lyBqdyyECgATozao/hfSAflMchvMJYTKvNiRpXXe7dj61VH7mT5ayMO+Kce+FztObdmkqcWDJ3enZbafD5LwMwDUxOy5lxpoJxPk4sYBtnN3FemInYsgnA/8/w9eVkRERMRHGnyIiIiIrzT4EBEREV9p8CEiIiK+0uBDREREfNVnZ7s0txQimH4vQc/aJwPATZVPm1rKsenvzUmbFJ4c9Zbkd/PIuGWm9smX5tHX/uGtCab2dPlfTY23w+ZiAZssHhKxbeCfauOfM0NmGMwptDMB8k3Ts+R6a5anovdmbIvwWCBD1mlP3SDZHwAwPGzr+zM2eT4qzFsVhwLHP0bfm3b5nHQGkn2fDidCly8L2eXPLWQzMewsFK8tywHgtIht0X1+v22m9kTGnt+56O+Suu+NWQ/s819Q/LqpHcrYWRyhAJ+VkyGHeR9puV7lMtulOmTP8dXtg03t9YT97J8s2kXX6XXm2Miw22w4u62sjfyIsH3ERS5tv5mTfWYLs3j3XFO7aNBr9LX/X6k9H+9P2JmduWhz7Ll7kMzGy+X+kA998yEiIiK+0uBDREREfKXBh4iIiPhKgw8RERHxVZ8NnKbaIwjivbDdSx02kAUA58a8BZNu2/FpU7t/1M/pa2sjPBTW3Sjyun+f+gh97Zd//RVTu2X9Zaa2fYJtgQsA0+JvmloNOXo14cOmVp8uo+s8mLbb/4d2m5yLB22gDADqwt4CdSw8Vu0S3DuUse81MGTDa7mEYFnb8tas3aZtKRt2BYCioA2nxsn278/YsfxRl8Do3rRtm14dtmHhASEeQK4kgVN2PjIph19LbJ8OJcdzWNi2fg6EvLdVzsURJ2WLpBt4vgHFC2h3eLvvUw5vI59xbHBvXcIGRuuyB+jyu9LlphYK2A86K77T1Lak+HEfR9rIxwP2fBycQ4tt1h4+HmDt+vML8+frSNZey4eyvD15a9ae9+ML8gvMPkduJRcPftXUbiird1mDPc+Kd+QX/K8nj18YHrMbyvad22M/YsFu12fQewt4ffMhIiIivtLgQ0RERHylwYeIiIj4SoMPERER8VWfDZwWFCcQir8X6vvqpqvp674z7remxrqE/ub0x01t0YFz+DoHbfG6mcasQpKGA/Bvn37Y1G588lpT+9ErF9DlD42zXef+sf+fTG1QyL7/+AIeGAVsPePY5X91tIwu/dyRMaZ2demfXd6rq/0ZHugqCdpQVSxgt9OtIybzVsqGO99IVpL3IeFG8C6jWceO2/enbKDroyX8XCoLunWV7L5NPMDVQbr4erUnbcORgPeg9RSSJcwk8gvDufHabZF1Qk2BB2u9dt9MkLDr9hQ/R8rIX+M+XWSP8fqE91vu9Nh+UxscYgFgvvwe0l23le4n/pmGhux5z4K9LMTamGEhVOD1lD2eHVm7/ICQXT4EHmpmnapZQDLl8GuuNI/fgttS/HMu2PZFU/vWab/zvF42wSJ2ML9Qd31qgKm1Few0tXjQHo9m0gkVACLduk9nSDdqN/rmQ0RERHylwYeIiIj4SoMPERER8ZUGHyIiIuKrnKM2b7/9Nm699VY8+eSTaG9vx+jRo/Hggw9iypQpAADHcXDHHXdg6dKlaGpqwrRp03Dfffdh/PjxOb1Pv6IE3p8pnDhgH33dN567wtQuvfj/mhrr3vjfSje4vDvv5paPuXHbNa7+QhuW3ZO0nQ7dPHV0rKl9JP6GqbVmeZdM1hEz4diA48Qo3/du3Te725S0nR5f6xhCX5siQcrTojZ4d5A87nxEwTt0nTuTg0yNhUtZR0kAGBVp9LR8W3aUqU2L8kBaG+ky6tejrB9rnUTrN5dv97T8/owNn31q4it5bRN7VDsAlATs349Y2Lg3HsEeJUHKMpduv63kceVV5HUTCnhn362pZlNj4cztKXvexLt3mfybcvJXy4qQ3U/7MjaECgBZ0kr2AAmStma9ByFDZJ0jIodN7VDG3oOPgoeaNyft+VhNOu42uGQhEyQ8PpmEqh9usfexR/efRddZEW81tTmF7F7AP9MvD081tWQ/fu54NbLA3sdYuJSd96wGAMFu98yAyz2ULuv5lQCampowY8YMRCIRPPnkk9iyZQv+5V/+BWVlZZ2vufvuu3HPPffg3nvvxbp161BZWYnZs2ejtdUeDBEREfnwyembj+9///uoqanBQw891FkbMWJE5387joMlS5bg9ttvx2WXHXtuybJly1BRUYHly5fjuuuuM+tMJBJIJN7720RLS0uun0FEREROIjl98/H4449j6tSpuPzyyzF48GCceeaZeOCBBzr/fMeOHWhoaMCcOXM6a9FoFDNnzsSaNWvoOhcvXozS0tLOn5qamuP8KCIiInIyyGnwsX37dtx///2oq6vD73//e1x//fX4+te/jp/+9KcAgIaGBgBARUVFl+UqKio6/6y7BQsWoLm5ufOnvt7tKX8iIiJyKsjpn12y2SymTp2KRYsWAQDOPPNMbN68Gffffz+uueaaztcFuj1u3HEcU3tXNBpFlHSoExERkVNTToOPqqoqjBs3rktt7Nix+OUvfwkAqKw81rK6oaEBVVXvZb0bGxvNtyF/TyIVRij13ub9uYH/c0ywwEaYz1xnZ8CcU7XL1ApDPCU+OGLDsWfFd5oaa5Ht1g57bUetqf1kx3RTO/SabYELAMW77ZdUhe/YZPHP220th463YF27HZeBIwmJI0haOrOaS6dk6mny9myb3DqOO0Fvr82GXNLkpJwly6eK7AsfKZ1NV5nob3dAqsweqEARP5/CUV7vLs3aeZOZGQDw74Xn25eyQ5cl52KczwIZ/cY4U4vfaGdxfOpf7LUAuJyP7NixO5nL4WTnLcOum5DLkwroNZbD98rsthFMkWuJvI/r9c2OHdkmx+W3AL0e2PLs+nT77Hks7zaRgn1+9lq2PwEgSPY9XZ68LsMngSBVYj/UGUV1pua278Okm3lysN3+T7w+19Rqig7TdUbIyfNU2P4OKyVvHnWZURUPdp0ple6t9uozZszA1q1bu9S2bduG4cOHAwBqa2tRWVmJVatWdf55MpnE6tWrMX06v7mIiIjIh0tO33x84xvfwPTp07Fo0SJ87nOfw9q1a7F06VIsXboUwLF/bpk/fz4WLVqEuro61NXVYdGiRYjH47jqqqt65QOIiIjIySWnwcfZZ5+Nxx57DAsWLMB3v/td1NbWYsmSJbj66veeOHvLLbegvb0d8+bN62wytnLlSpSUlPT4xouIiMjJJ+cOp5dccgkuueQS1z8PBAJYuHAhFi5ceFwb5PztH5kzbW6Pge8qS56SnAnbZZNHbBe/UMjlceUR0r0yY/8tKxK0/zCYdvmHyfaEfS/2GbMdthMqAGQS9l/IMimS72C1XDIfZPNPdOaD/ds9zXy4/JswzXyQ12az3jMfpEEpMhH7wkyCrzPbYXdAtp1kPtg/NAPIZrxlPrJJ75mPLHmEvNfMRwYuXTJJBimTsKENt4yA58wHO8d7IfMBHzMfDrlu2HmXd+bD5brxnPlgb90HMx9sfx6re13e1jIu9zF23WfYpehyGQfIecbuGemj5Hedw69Fh2Q+EmF7zXeQmuNyH+p+f+o4cuz/HXbj6L6s4+VVPtqzZ496fYiIiJyk6uvrMXTo0A98TZ8bfGSzWezduxclJSVobW1FTU0N6uvr0a9fvxO9aeKipaVFx6mP0zE6Oeg49X06Ru4cx0Frayuqq6sRDH7wV385/7NLbwsGg50jpnd7g/Tr108H+SSg49T36RidHHSc+j4dI660tNTT63KaaisiIiKSLw0+RERExFd9evARjUbxne98R+3X+zgdp75Px+jkoOPU9+kY9Yw+FzgVERGRU1uf/uZDRERETj0afIiIiIivNPgQERERX2nwISIiIr7S4ENERER81acHHz/60Y9QW1uLWCyGKVOm4Pnnnz/Rm/ShtXjxYpx99tkoKSnB4MGDcemll2Lr1q1dXuM4DhYuXIjq6moUFhZi1qxZ2Lx58wnaYlm8eDECgQDmz5/fWdMx6hvefvttfOELX8CAAQMQj8cxefJkrF+/vvPPdZxOrHQ6jW9/+9uora1FYWEhRo4cie9+97vIZt974pyOUZ6cPmrFihVOJBJxHnjgAWfLli3OTTfd5BQVFTm7du060Zv2ofTxj3/ceeihh5xXX33V2bhxozN37lxn2LBhzpEjRzpfc9dddzklJSXOL3/5S2fTpk3O5z//eaeqqsppaWk5gVv+4bR27VpnxIgRzqRJk5ybbrqps65jdOIdOnTIGT58uPOlL33Jefnll50dO3Y4Tz/9tPPmm292vkbH6cS68847nQEDBji//e1vnR07djj/+Z//6RQXFztLlizpfI2OUX767ODjnHPOca6//voutTFjxji33XbbCdoieb/GxkYHgLN69WrHcRwnm806lZWVzl133dX5mo6ODqe0tNT58Y9/fKI280OptbXVqaurc1atWuXMnDmzc/ChY9Q33Hrrrc7555/v+uc6Tife3LlznX/6p3/qUrvsssucL3zhC47j6Bj1hD75zy7JZBLr16/HnDlzutTnzJmDNWvWnKCtkvdrbm4GAJSXlwMAduzYgYaGhi7HLBqNYubMmTpmPrvhhhswd+5cXHTRRV3qOkZ9w+OPP46pU6fi8ssvx+DBg3HmmWfigQce6PxzHacT7/zzz8cf/vAHbNu2DQDw17/+FS+88AI++clPAtAx6gl97qm2AHDgwAFkMhlUVFR0qVdUVKChoeEEbZW8y3Ec3HzzzTj//PMxYcIEAOg8LuyY7dq1y/dt/LBasWIFNmzYgHXr1pk/0zHqG7Zv3477778fN998M771rW9h7dq1+PrXv45oNIprrrlGx6kPuPXWW9Hc3IwxY8YgFAohk8nge9/7Hq688koAupZ6Qp8cfLwrEAh0+X/HcUxN/Pe1r30Nr7zyCl544QXzZzpmJ059fT1uuukmrFy5ErFYzPV1OkYnVjabxdSpU7Fo0SIAwJlnnonNmzfj/vvvxzXXXNP5Oh2nE+fnP/85HnnkESxfvhzjx4/Hxo0bMX/+fFRXV+Paa6/tfJ2O0fHrk//sMnDgQIRCIfMtR2Njoxlpir9uvPFGPP744/jjH/+IoUOHdtYrKysBQMfsBFq/fj0aGxsxZcoUhMNhhMNhrF69Gv/2b/+GcDjceRx0jE6sqqoqjBs3rktt7Nix2L17NwBdS33BN7/5Tdx222244oorMHHiRHzxi1/EN77xDSxevBiAjlFP6JODj4KCAkyZMgWrVq3qUl+1ahWmT59+grbqw81xHHzta1/Do48+imeeeQa1tbVd/ry2thaVlZVdjlkymcTq1at1zHxy4YUXYtOmTdi4cWPnz9SpU3H11Vdj48aNGDlypI5RHzBjxgwzTX3btm0YPnw4AF1LfUFbWxuCwa6/HkOhUOdUWx2jHnACw64f6N2ptg8++KCzZcsWZ/78+U5RUZGzc+fOE71pH0pf/epXndLSUufZZ5919u3b1/nT1tbW+Zq77rrLKS0tdR599FFn06ZNzpVXXqmpZyfY+2e7OI6OUV+wdu1aJxwOO9/73vecN954w/nZz37mxONx55FHHul8jY7TiXXttdc6Q4YM6Zxq++ijjzoDBw50brnlls7X6Bjlp88OPhzHce677z5n+PDhTkFBgXPWWWd1TusU/wGgPw899FDna7LZrPOd73zHqaysdKLRqHPBBRc4mzZtOnEbLWbwoWPUN/zmN79xJkyY4ESjUWfMmDHO0qVLu/y5jtOJ1dLS4tx0003OsGHDnFgs5owcOdK5/fbbnUQi0fkaHaP8BBzHcU7kNy8iIiLy4dInMx8iIiJy6tLgQ0RERHylwYeIiIj4SoMPERER8ZUGHyIiIuIrDT5ERETEVxp8iIiIiK80+BARERFfafAhIiIivtLgQ0RERHylwYeIiIj46v8HR8MDFrqJSmcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(pil_images[0].convert('L').filter(ImageFilter.CONTOUR()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM IMAGE AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint, seed\n",
    "seed(101)\n",
    "\n",
    "def image_augmentation(pil_images: list):\n",
    "    augmented_images = []\n",
    "    for image in pil_images:\n",
    "        if randint(1, 10) > 5:\n",
    "            image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "        if randint(1, 10) > 5:\n",
    "            image = ImageEnhance.Brightness(image.convert('L')).enhance(1.5)\n",
    "\n",
    "        if randint(1, 10) > 5:\n",
    "            image = ImageEnhance.Contrast(image.convert('L')).enhance(2)\n",
    "\n",
    "        if randint(1, 10) > 5:\n",
    "            image = image.convert('L').filter(ImageFilter.FIND_EDGES)\n",
    "\n",
    "        if randint(1, 10) > 5:\n",
    "            image = image.convert('L').filter(ImageFilter.GaussianBlur(0.75))\n",
    "\n",
    "        augmented_images.append(image)\n",
    "        \n",
    "    return augmented_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint, seed\n",
    "seed(101)\n",
    "\n",
    "def image_augmentation1(pil_images: list):\n",
    "    augmented_images = []\n",
    "    for image in pil_images:\n",
    "        if randint(1, 10) > 5:\n",
    "            image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "        if randint(1, 10) > 5:\n",
    "            image = ImageEnhance.Brightness(image.convert('L')).enhance(1.5)\n",
    "\n",
    "        if randint(1, 10) > 5:\n",
    "            image = ImageEnhance.Contrast(image.convert('L')).enhance(2)\n",
    "\n",
    "        if randint(1, 10) > 5:\n",
    "            image = image.convert('L').filter(ImageFilter.FIND_EDGES)\n",
    "\n",
    "        if randint(1, 10) > 5:\n",
    "            image = ImageEnhance.Sharpness(image.convert('L')).enhance(2)\n",
    "\n",
    "        augmented_images.append(image)\n",
    "        \n",
    "    return augmented_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_augmentation2(pil_images: list):\n",
    "    augmented_images = []  # Start with an empty list for augmented images\n",
    "    \n",
    "    for image in pil_images:\n",
    "        # Randomly decide how many augmentations to apply per image\n",
    "        augment_count = np.random.randint(2, 4)  # Apply between 2 to 4 augmentations to each image\n",
    "\n",
    "        # Apply augmentations based on the random selection\n",
    "        for _ in range(augment_count):\n",
    "            random_number = np.random.randint(1, 11)  # Randomly choose an augmentation type\n",
    "            \n",
    "            # 1. Horizontal flip with 50% chance\n",
    "            if random_number < 3:\n",
    "                image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            \n",
    "            # 2. Random brightness adjustment (20% chance)\n",
    "            elif random_number in range(3, 5):\n",
    "                image = ImageEnhance.Brightness(image.convert('L')).enhance(np.random.uniform(0.7, 1.5))\n",
    "\n",
    "            # 3. Random contrast adjustment (20% chance)\n",
    "            elif random_number in range(5, 7):\n",
    "                image = ImageEnhance.Contrast(image.convert('L')).enhance(np.random.uniform(0.5, 2))\n",
    "\n",
    "            # 4. Random sharpness adjustment (20% chance)\n",
    "            elif random_number in range(7, 9):\n",
    "                image = ImageEnhance.Sharpness(image.convert('L')).enhance(np.random.uniform(0.5, 2))\n",
    "\n",
    "            # 5. Random noise injection (10% chance)\n",
    "            elif random_number in range(9, 11):\n",
    "                image = image.convert('L').filter(ImageFilter.FIND_EDGES)\n",
    "\n",
    "            # Append the augmented image to the list\n",
    "            augmented_images.append(image)\n",
    "            \n",
    "    pil_images.extend(augmented_images)\n",
    "        \n",
    "    return pil_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_augmentation3(X, y):\n",
    "    augmented_images = []  # List to store augmented images\n",
    "    augmented_labels = []  # List to store corresponding labels\n",
    "    y = list(y)\n",
    "\n",
    "    for image, label in zip(X, y):\n",
    "        augment_count = np.random.randint(2, 4)  # Apply between 2 to 4 augmentations\n",
    "        original_image = image.copy()\n",
    "\n",
    "        for _ in range(augment_count):\n",
    "            random_number = np.random.randint(1, 13)  # Randomly choose an augmentation type\n",
    "            \n",
    "            if random_number < 3:\n",
    "                image = original_image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            elif random_number in range(3, 5):\n",
    "                image = ImageEnhance.Brightness(original_image.convert('L')).enhance(np.random.uniform(0.7, 1.5))\n",
    "            elif random_number in range(5, 7):\n",
    "                image = ImageEnhance.Contrast(original_image.convert('L')).enhance(np.random.uniform(0.5, 2))\n",
    "            elif random_number in range(7, 9):\n",
    "                image = ImageEnhance.Sharpness(original_image.convert('L')).enhance(np.random.uniform(0.5, 2))\n",
    "            elif random_number in range(9, 11):\n",
    "                image = original_image.convert('L').filter(ImageFilter.FIND_EDGES)\n",
    "            elif random_number in range(11, 13):\n",
    "                image = original_image.convert('L').filter(ImageFilter.GaussianBlur(np.random.uniform(0.7, 1)))\n",
    "\n",
    "            augmented_images.append(image)  # Convert PIL image back to numpy array\n",
    "            augmented_labels.append(label)\n",
    "        \n",
    "    X.extend(augmented_images)\n",
    "    y.extend(augmented_labels)\n",
    "    X = np.array(X) / 255\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1100"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(2200, size=1100).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_augmentation4(X, y, augmentation_ratio=0.5):\n",
    "    augmented_images = list(X)  # Start with original images\n",
    "    augmented_labels = list(y)  # Start with original labels\n",
    "\n",
    "    # Determine the number of images to augment based on augmentation_ratio\n",
    "    total_images = len(X)\n",
    "    num_augment = int(augmentation_ratio * total_images)\n",
    "\n",
    "    for i in range(8):  # 6 augmentation types\n",
    "        augment_indices = np.random.choice(total_images, size=num_augment, replace=False)\n",
    "        \n",
    "        for image_idx in augment_indices:\n",
    "            original_image = X[image_idx]\n",
    "            label = y[image_idx]\n",
    "            \n",
    "            # Apply specific augmentation logic\n",
    "            if i == 0:  # Horizontal flip\n",
    "                augmented_image = original_image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            elif i == 1:  # Brightness adjustment\n",
    "                augmented_image = ImageEnhance.Brightness(original_image.convert('L')).enhance(np.random.uniform(0.7, 1.5))\n",
    "            elif i == 2:  # Contrast adjustment\n",
    "                augmented_image = ImageEnhance.Contrast(original_image.convert('L')).enhance(np.random.uniform(0.5, 2))\n",
    "            elif i == 3:  # Sharpness adjustment\n",
    "                augmented_image = ImageEnhance.Sharpness(original_image.convert('L')).enhance(np.random.uniform(0.5, 2))\n",
    "            elif i == 4:  # Edge detection\n",
    "                augmented_image = original_image.convert('L').filter(ImageFilter.FIND_EDGES)\n",
    "            elif i == 5:  # Gaussian blur\n",
    "                augmented_image = original_image.convert('L').filter(ImageFilter.GaussianBlur(np.random.uniform(0.7, 1)))\n",
    "            elif i == 6:\n",
    "                augmented_image = original_image.convert('L').filter(ImageFilter.EDGE_ENHANCE_MORE)\n",
    "            elif i == 7:\n",
    "                augmented_image = original_image.convert('L').filter(ImageFilter.CONTOUR)\n",
    "                \n",
    "            \n",
    "\n",
    "            # Add augmented image and label to the dataset\n",
    "            augmented_images.append(augmented_image)\n",
    "            augmented_labels.append(label)\n",
    "    \n",
    "    # Normalize the images and convert labels to numpy arrays\n",
    "    X = np.array([np.array(img) / 255 for img in augmented_images])  # Normalize images\n",
    "    y = np.array(augmented_labels)\n",
    "    \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('reshape', FunctionTransformer(lambda x: x.reshape(-1, 2, 62, 47))),\n",
    "    ('concat', FunctionTransformer(lambda x: np.concatenate((x[:, 0], x[:, 1]), axis=2))),\n",
    "    ('convert_to_pil', FunctionTransformer(numpy_to_pil)),\n",
    "    ('image_augmentation', FunctionTransformer(image_augmentation2)),\n",
    "    ('normalize_array', FunctionTransformer(lambda x: np.array(x) / 255)),\n",
    "    ('flatten', FunctionTransformer(lambda x: x.reshape(x.shape[0], -1))),\n",
    "    ('pca', PCA(n_components=250))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_test(X):\n",
    "    X = X.reshape(-1, 2, 62, 47)\n",
    "    X = np.concatenate((X[:, 0], X[:, 1]), axis=2)\n",
    "    X = X.reshape(X.shape[0], -1)    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11000, 70) (11000,)\n",
      "(1000, 70) (1000,)\n"
     ]
    }
   ],
   "source": [
    "def numpy_to_pil(images_array):\n",
    "    pil_images = []\n",
    "    for i in range(images_array.shape[0]):\n",
    "        img = Image.fromarray(images_array[i] * 255, mode='F')\n",
    "        pil_images.append(img)\n",
    "    return pil_images\n",
    "\n",
    "def preprocessing(X, y, augmentation_ratio=0.5):\n",
    "    X = X.reshape(-1, 2, 62, 47)\n",
    "    X = np.concatenate((X[:, 0], X[:, 1]), axis=2)\n",
    "    X = numpy_to_pil(X)\n",
    "    X, y = image_augmentation4(X, y, augmentation_ratio)\n",
    "    X = X.reshape(X.shape[0], -1)    \n",
    "    return X, y\n",
    "\n",
    "def transform_test(X):\n",
    "    X = X.reshape(-1, 2, 62, 47)\n",
    "    X = np.concatenate((X[:, 0], X[:, 1]), axis=2)\n",
    "    X = X.reshape(X.shape[0], -1)    \n",
    "    return X\n",
    "\n",
    "\n",
    "X_train, y_train = preprocessing(data['data'], data['target'])\n",
    "X_test = transform_test(test_data['data'])\n",
    "y_test = test_data['target']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components=70, random_state=101)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.544\n",
      "0.625\n",
      "0.633\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "pred = knn.fit(X_train,y_train).predict(X_test)\n",
    "print(accuracy_score(y_test, pred))\n",
    "\n",
    "rf = RandomForestClassifier(random_state = 101)\n",
    "pred = rf.fit(X_train,y_train).predict(X_test)\n",
    "print(accuracy_score(y_test, pred))\n",
    "\n",
    "svc = SVC(probability = True, kernel='rbf', random_state=101)\n",
    "pred = svc.fit(X_train,y_train).predict(X_test)\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.673\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(128, 64), solver='adam', max_iter=1000, activation='relu', early_stopping=True, random_state=101)\n",
    "pred = mlp.fit(X_train,y_train).predict(X_test)\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "for i in range(2,8):\n",
    "    predictions = []\n",
    "    i = i / 10\n",
    "    X_train, y_train = preprocessing(data['data'], data['target'], i)\n",
    "    X_test = transform_test(test_data['data'])\n",
    "    y_test = test_data['target']\n",
    "\n",
    "    pca = PCA(n_components=300)\n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    X_test = pca.transform(X_test)\n",
    "    \n",
    "    svc = SVC(probability = True)\n",
    "    pred = svc.fit(X_train,y_train).predict(X_test)\n",
    "    predictions.append(accuracy_score(y_test, pred))\n",
    "    \n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(128, 64), solver='adam', max_iter=1000, activation='relu', early_stopping=True, random_state=101)\n",
    "    pred = mlp.fit(X_train,y_train).predict(X_test)\n",
    "    predictions.append(accuracy_score(y_test, pred))\n",
    "    \n",
    "    gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=0.01, max_depth=3, random_state=101)\n",
    "    pred = gbc.fit(X_train,y_train).predict(X_test)\n",
    "    predictions.append(accuracy_score(y_test, pred))\n",
    "    \n",
    "    cv = KFold(n_splits=3, shuffle=True, random_state=101)\n",
    "\n",
    "    estimators = [('mlp', mlp), ('svc',svc), ('gbc', gbc)]#, ('voting_soft', voting_clf_soft)]\n",
    "\n",
    "    stacking_clf = StackingClassifier(\n",
    "        estimators=estimators,\n",
    "        final_estimator=LogisticRegression(),\n",
    "        cv=cv,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    pred = stacking_clf.fit(X_train,y_train).predict(X_test)\n",
    "    predictions.append(accuracy_score(y_test, pred))\n",
    "    \n",
    "    result[i] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.2: [0.603, 0.605, 0.616, 0.615],\n",
       " 0.3: [0.623, 0.615, 0.618, 0.628],\n",
       " 0.4: [0.616, 0.618, 0.621, 0.63],\n",
       " 0.5: [0.616, 0.624, 0.631, 0.63],\n",
       " 0.6: [0.628, 0.621, 0.62, 0.633],\n",
       " 0.7: [0.612, 0.615, 0.617, 0.623]}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0-4\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.2: [0.623, 0.623, 0.617, 0.626],\n",
       " 0.3: [0.637, 0.614, 0.619, 0.626],\n",
       " 0.4: [0.627, 0.613, 0.649, 0.615],\n",
       " 0.5: [0.619, 0.635, 0.617, 0.639],\n",
       " 0.6: [0.63, 0.629, 0.611, 0.625],\n",
       " 0.7: [0.623, 0.621, 0.61, 0.634]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0-5\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.2: [0.633, 0.634, 0.624, 0.646],\n",
       " 0.3: [0.617, 0.622, 0.617, 0.63],\n",
       " 0.4: [0.631, 0.611, 0.63, 0.61],\n",
       " 0.5: [0.622, 0.612, 0.622, 0.614],\n",
       " 0.6: [0.645, 0.628, 0.636, 0.639],\n",
       " 0.7: [0.64, 0.621, 0.632, 0.623]}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0-6\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.2: [0.618, 0.592, 0.63, 0.609],\n",
       " 0.3: [0.614, 0.616, 0.632, 0.622],\n",
       " 0.4: [0.631, 0.614, 0.622, 0.619],\n",
       " 0.5: [0.612, 0.603, 0.631, 0.611],\n",
       " 0.6: [0.637, 0.631, 0.617, 0.638],\n",
       " 0.7: [0.631, 0.671, 0.631, 0.664]}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0-8\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 50\n",
      "At Iteration 50: [0.633, 0.646, 0.629, 0.645]\n",
      "i: 75\n",
      "At Iteration 75: [0.643, 0.674, 0.639, 0.675]\n",
      "i: 100\n",
      "At Iteration 100: [0.64, 0.668, 0.635, 0.675]\n",
      "i: 125\n",
      "At Iteration 125: [0.628, 0.627, 0.633, 0.633]\n",
      "i: 150\n",
      "At Iteration 150: [0.629, 0.659, 0.63, 0.658]\n",
      "i: 175\n",
      "At Iteration 175: [0.626, 0.661, 0.637, 0.66]\n",
      "i: 200\n",
      "At Iteration 200: [0.631, 0.648, 0.632, 0.649]\n",
      "i: 300\n",
      "At Iteration 300: [0.622, 0.639, 0.633, 0.643]\n"
     ]
    }
   ],
   "source": [
    "result = {}\n",
    "for i in [50, 75, 100, 125, 150, 175, 200, 300]:\n",
    "    print(f'i: {i}')\n",
    "    predictions = []\n",
    "    X_train, y_train = preprocessing(data['data'], data['target'], 0.7)\n",
    "    X_test = transform_test(test_data['data'])\n",
    "    y_test = test_data['target']\n",
    "\n",
    "    pca = PCA(n_components=i, random_state=101)\n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    X_test = pca.transform(X_test)\n",
    "    \n",
    "    svc = SVC(probability = True)\n",
    "    pred = svc.fit(X_train,y_train).predict(X_test)\n",
    "    predictions.append(accuracy_score(y_test, pred))\n",
    "    \n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(128, 64), solver='adam', max_iter=1000, activation='relu', early_stopping=True, random_state=101)\n",
    "    pred = mlp.fit(X_train,y_train).predict(X_test)\n",
    "    predictions.append(accuracy_score(y_test, pred))\n",
    "    \n",
    "    gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=0.01, max_depth=3, random_state=101)\n",
    "    pred = gbc.fit(X_train,y_train).predict(X_test)\n",
    "    predictions.append(accuracy_score(y_test, pred))\n",
    "    \n",
    "    estimators = [('mlp', mlp), ('svc',svc), ('gbc', gbc)]\n",
    "    cv = KFold(n_splits=3, shuffle=True, random_state=101)\n",
    "    \n",
    "    stacking_clf = StackingClassifier(\n",
    "        estimators=estimators,\n",
    "        final_estimator=LogisticRegression(),\n",
    "        cv=cv,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    pred = stacking_clf.fit(X_train,y_train).predict(X_test)\n",
    "    predictions.append(accuracy_score(y_test, pred))\n",
    "    \n",
    "    print(f'At Iteration {i}: {predictions}')\n",
    "    \n",
    "    result[i] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 65\n",
      "At Iteration 65: [0.635, 0.66, 0.627, 0.66]\n",
      "i: 70\n",
      "At Iteration 70: [0.651, 0.677, 0.628, 0.684]\n",
      "i: 75\n",
      "At Iteration 75: [0.641, 0.66, 0.631, 0.662]\n",
      "i: 80\n",
      "At Iteration 80: [0.645, 0.669, 0.623, 0.674]\n",
      "i: 85\n",
      "At Iteration 85: [0.644, 0.676, 0.637, 0.676]\n",
      "i: 90\n",
      "At Iteration 90: [0.638, 0.66, 0.63, 0.661]\n",
      "i: 95\n",
      "At Iteration 95: [0.625, 0.661, 0.622, 0.665]\n",
      "i: 100\n",
      "At Iteration 100: [0.641, 0.639, 0.641, 0.645]\n"
     ]
    }
   ],
   "source": [
    "result = {}\n",
    "for i in [65, 70, 75, 80, 85, 90, 95, 100]:\n",
    "    print(f'i: {i}')\n",
    "    predictions = []\n",
    "    X_train, y_train = preprocessing(data['data'], data['target'], 0.7)\n",
    "    X_test = transform_test(test_data['data'])\n",
    "    y_test = test_data['target']\n",
    "\n",
    "    pca = PCA(n_components=i, random_state=101)\n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    X_test = pca.transform(X_test)\n",
    "    \n",
    "    svc = SVC(probability = True)\n",
    "    pred = svc.fit(X_train,y_train).predict(X_test)\n",
    "    predictions.append(accuracy_score(y_test, pred))\n",
    "    \n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(128, 64), solver='adam', max_iter=1000, activation='relu', early_stopping=True, random_state=101)\n",
    "    pred = mlp.fit(X_train,y_train).predict(X_test)\n",
    "    predictions.append(accuracy_score(y_test, pred))\n",
    "    \n",
    "    gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=0.01, max_depth=3, random_state=101)\n",
    "    pred = gbc.fit(X_train,y_train).predict(X_test)\n",
    "    predictions.append(accuracy_score(y_test, pred))\n",
    "    \n",
    "    estimators = [('mlp', mlp), ('svc',svc), ('gbc', gbc)]\n",
    "    cv = KFold(n_splits=3, shuffle=True, random_state=101)\n",
    "    \n",
    "    stacking_clf = StackingClassifier(\n",
    "        estimators=estimators,\n",
    "        final_estimator=LogisticRegression(),\n",
    "        cv=cv,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    pred = stacking_clf.fit(X_train,y_train).predict(X_test)\n",
    "    predictions.append(accuracy_score(y_test, pred))\n",
    "    \n",
    "    print(f'At Iteration {i}: {predictions}')\n",
    "    \n",
    "    result[i] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{100: [0.63, 0.635, 0.639, 0.645],\n",
       " 300: [0.633, 0.63, 0.631, 0.634],\n",
       " 500: [0.631, 0.62, 0.638, 0.631],\n",
       " 700: [0.637, 0.632, 0.618, 0.635],\n",
       " 1000: [0.625, 0.62, 0.621, 0.622],\n",
       " 1500: [0.629, 0.618, 0.635, 0.627],\n",
       " 2500: [0.611, 0.595, 0.622, 0.611],\n",
       " 3000: [0.631, 0.626, 0.628, 0.632]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.632 total time= 2.0min\n",
      "[CV 2/3] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.672 total time= 2.1min\n",
      "[CV 3/3] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.655 total time= 2.3min\n",
      "0.626\n",
      "{'C': 0.1, 'gamma': 0.01, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1],\n",
    "    'gamma': [0.01],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=101)\n",
    "\n",
    "best_svc = GridSearchCV(\n",
    "    SVC(random_state=101, probability=True),\n",
    "    param_grid,\n",
    "    refit=True,\n",
    "    cv=cv,\n",
    "    verbose=3\n",
    ")\n",
    "\n",
    "best_svc.fit(X_train, y_train)\n",
    "pred = best_svc.best_estimator_.predict(X_test)\n",
    "print(accuracy_score(y_test, pred))\n",
    "print(best_svc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 5/5] END ..C=100.0, gamma=0.001, kernel=rbf;, score=0.850 total time= 3.7min\n",
      "[CV 2/5] END ..C=100.0, gamma=0.001, kernel=rbf;, score=0.854 total time= 3.7min\n",
      "[CV 1/5] END ..C=100.0, gamma=0.001, kernel=rbf;, score=0.876 total time= 3.9min\n",
      "[CV 3/5] END ..C=100.0, gamma=0.001, kernel=rbf;, score=0.870 total time= 3.9min\n",
      "[CV 4/5] END ..C=100.0, gamma=0.001, kernel=rbf;, score=0.861 total time= 3.9min\n",
      "[CV 1/5] END ...C=100.0, gamma=0.01, kernel=rbf;, score=0.818 total time= 2.8min\n",
      "[CV 2/5] END ...C=100.0, gamma=0.01, kernel=rbf;, score=0.806 total time= 2.9min\n",
      "[CV 3/5] END ...C=100.0, gamma=0.01, kernel=rbf;, score=0.798 total time= 2.8min\n",
      "[CV 3/5] END ...C=1.0, gamma=0.001, kernel=poly;, score=0.845 total time= 7.0min\n",
      "[CV 2/5] END ...C=1.0, gamma=0.001, kernel=poly;, score=0.836 total time= 7.0min\n",
      "[CV 1/5] END ...C=1.0, gamma=0.001, kernel=poly;, score=0.852 total time= 7.0min\n",
      "[CV 4/5] END ...C=100.0, gamma=0.01, kernel=rbf;, score=0.795 total time= 2.3min\n",
      "[CV 5/5] END ...C=100.0, gamma=0.01, kernel=rbf;, score=0.800 total time= 2.3min\n",
      "[CV 5/5] END ...C=1.0, gamma=0.001, kernel=poly;, score=0.821 total time= 5.6min\n",
      "[CV 4/5] END ...C=1.0, gamma=0.001, kernel=poly;, score=0.832 total time= 5.7min\n",
      "[CV 1/5] END ....C=10.0, gamma=0.1, kernel=poly;, score=0.841 total time= 7.9min\n",
      "[CV 3/5] END ....C=10.0, gamma=0.1, kernel=poly;, score=0.839 total time= 7.9min\n",
      "[CV 2/5] END ....C=10.0, gamma=0.1, kernel=poly;, score=0.829 total time= 8.0min\n",
      "[CV 4/5] END ....C=10.0, gamma=0.1, kernel=poly;, score=0.830 total time= 8.1min\n",
      "[CV 1/5] END ....C=1.0, gamma=0.001, kernel=rbf;, score=0.836 total time= 1.8min\n",
      "[CV 5/5] END ....C=10.0, gamma=0.1, kernel=poly;, score=0.828 total time= 7.9min\n",
      "[CV 2/5] END ....C=1.0, gamma=0.001, kernel=rbf;, score=0.834 total time= 1.8min\n",
      "[CV 1/5] END ....C=1.0, gamma=0.01, kernel=poly;, score=0.842 total time= 7.9min\n",
      "[CV 2/5] END ....C=1.0, gamma=0.01, kernel=poly;, score=0.829 total time= 7.9min\n",
      "[CV 3/5] END ....C=1.0, gamma=0.01, kernel=poly;, score=0.839 total time= 7.8min\n",
      "[CV 3/5] END ....C=1.0, gamma=0.001, kernel=rbf;, score=0.856 total time= 1.8min\n",
      "[CV 4/5] END ....C=1.0, gamma=0.001, kernel=rbf;, score=0.843 total time= 1.8min\n",
      "[CV 5/5] END ....C=1.0, gamma=0.001, kernel=rbf;, score=0.839 total time= 1.8min\n",
      "[CV 1/5] END ....C=100.0, gamma=0.1, kernel=rbf;, score=0.687 total time= 2.6min\n",
      "[CV 2/5] END ....C=100.0, gamma=0.1, kernel=rbf;, score=0.680 total time= 2.7min\n",
      "[CV 3/5] END ....C=100.0, gamma=0.1, kernel=rbf;, score=0.669 total time= 2.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ....C=100.0, gamma=0.1, kernel=rbf;, score=0.692 total time= 2.6min\n",
      "[CV 5/5] END ....C=100.0, gamma=0.1, kernel=rbf;, score=0.686 total time= 2.5min\n",
      "[CV 5/5] END ....C=1.0, gamma=0.01, kernel=poly;, score=0.828 total time= 7.9min\n",
      "[CV 4/5] END ....C=1.0, gamma=0.01, kernel=poly;, score=0.830 total time= 8.4min\n",
      "[CV 1/5] END ..C=10.0, gamma=0.001, kernel=poly;, score=0.840 total time= 8.1min\n",
      "[CV 2/5] END ..C=10.0, gamma=0.001, kernel=poly;, score=0.832 total time= 7.8min\n",
      "[CV 3/5] END ..C=10.0, gamma=0.001, kernel=poly;, score=0.842 total time= 7.7min\n",
      "[CV 4/5] END ..C=10.0, gamma=0.001, kernel=poly;, score=0.830 total time= 7.7min\n",
      "[CV 5/5] END ..C=10.0, gamma=0.001, kernel=poly;, score=0.829 total time= 7.4min\n",
      "[CV 1/5] END .....C=1.0, gamma=0.1, kernel=poly;, score=0.841 total time= 7.5min\n",
      "[CV 3/5] END .....C=1.0, gamma=0.1, kernel=poly;, score=0.839 total time= 7.3min\n",
      "[CV 2/5] END .....C=1.0, gamma=0.1, kernel=poly;, score=0.829 total time= 7.4min\n",
      "[CV 4/5] END .....C=1.0, gamma=0.1, kernel=poly;, score=0.830 total time= 7.1min\n",
      "[CV 5/5] END .....C=1.0, gamma=0.1, kernel=poly;, score=0.828 total time= 6.9min\n",
      "[CV 1/5] END ...C=10.0, gamma=0.01, kernel=poly;, score=0.842 total time= 7.0min\n",
      "[CV 2/5] END ...C=10.0, gamma=0.01, kernel=poly;, score=0.829 total time= 7.0min\n",
      "[CV 3/5] END ...C=10.0, gamma=0.01, kernel=poly;, score=0.839 total time= 6.7min\n",
      "[CV 4/5] END ...C=10.0, gamma=0.01, kernel=poly;, score=0.830 total time= 6.9min\n",
      "[CV 5/5] END ...C=10.0, gamma=0.01, kernel=poly;, score=0.828 total time= 5.8min\n",
      "0.646\n",
      "{'kernel': 'rbf', 'gamma': np.float64(0.001), 'C': np.float64(100.0)}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': np.logspace(0, 2, 3),\n",
    "    'gamma': np.logspace(-3, -1, 3),\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=101)\n",
    "\n",
    "best_svc = RandomizedSearchCV(\n",
    "    SVC(random_state=101, probability=True),\n",
    "    param_grid,\n",
    "    refit=True,\n",
    "    cv=cv,\n",
    "    verbose=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "best_svc.fit(X_train, y_train)\n",
    "pred = best_svc.best_estimator_.predict(X_test)\n",
    "print(accuracy_score(y_test, pred))\n",
    "print(best_svc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV 1/3] END .......C=0.01, gamma=1, kernel=rbf;, score=0.489 total time= 1.1min\n",
      "[CV 2/3] END .......C=0.01, gamma=1, kernel=rbf;, score=0.491 total time= 1.1min\n",
      "[CV 3/3] END .......C=0.01, gamma=1, kernel=rbf;, score=0.499 total time= 1.1min\n",
      "[CV 1/3] END .....C=0.01, gamma=0.1, kernel=rbf;, score=0.489 total time= 1.1min\n",
      "[CV 2/3] END .....C=0.01, gamma=0.1, kernel=rbf;, score=0.491 total time= 1.1min\n",
      "[CV 3/3] END .....C=0.01, gamma=0.1, kernel=rbf;, score=0.499 total time= 1.1min\n",
      "[CV 1/3] END ....C=0.01, gamma=0.01, kernel=rbf;, score=0.489 total time= 1.1min\n",
      "[CV 2/3] END ....C=0.01, gamma=0.01, kernel=rbf;, score=0.491 total time= 1.1min\n",
      "[CV 3/3] END ....C=0.01, gamma=0.01, kernel=rbf;, score=0.499 total time= 1.1min\n",
      "[CV 1/3] END ...C=0.01, gamma=0.001, kernel=rbf;, score=0.489 total time= 1.1min\n",
      "[CV 2/3] END ...C=0.01, gamma=0.001, kernel=rbf;, score=0.491 total time= 1.1min\n",
      "[CV 3/3] END ...C=0.01, gamma=0.001, kernel=rbf;, score=0.499 total time= 1.1min\n",
      "[CV 1/3] END ..C=0.01, gamma=0.0001, kernel=rbf;, score=0.489 total time= 1.1min\n",
      "[CV 2/3] END ..C=0.01, gamma=0.0001, kernel=rbf;, score=0.491 total time= 1.1min\n",
      "[CV 3/3] END ..C=0.01, gamma=0.0001, kernel=rbf;, score=0.499 total time= 1.1min\n",
      "[CV 1/3] END ........C=0.1, gamma=1, kernel=rbf;, score=0.489 total time= 1.1min\n",
      "[CV 2/3] END ........C=0.1, gamma=1, kernel=rbf;, score=0.491 total time= 1.1min\n",
      "[CV 3/3] END ........C=0.1, gamma=1, kernel=rbf;, score=0.499 total time= 1.1min\n",
      "[CV 1/3] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.489 total time= 1.1min\n",
      "[CV 2/3] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.491 total time= 1.1min\n",
      "[CV 3/3] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.499 total time= 1.1min\n",
      "[CV 1/3] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.661 total time= 1.1min\n",
      "[CV 2/3] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.665 total time= 1.1min\n",
      "[CV 3/3] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.650 total time= 1.1min\n",
      "[CV 1/3] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.547 total time= 1.1min\n",
      "[CV 2/3] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.545 total time= 1.1min\n",
      "[CV 3/3] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.562 total time= 1.1min\n",
      "[CV 1/3] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.489 total time= 1.1min\n",
      "[CV 2/3] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.491 total time= 1.1min\n",
      "[CV 3/3] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.506 total time= 1.1min\n",
      "[CV 1/3] END ..........C=1, gamma=1, kernel=rbf;, score=0.652 total time= 1.4min\n",
      "[CV 2/3] END ..........C=1, gamma=1, kernel=rbf;, score=0.659 total time= 1.4min\n",
      "[CV 3/3] END ..........C=1, gamma=1, kernel=rbf;, score=0.666 total time= 1.4min\n",
      "[CV 1/3] END ........C=1, gamma=0.1, kernel=rbf;, score=0.729 total time= 1.4min\n",
      "[CV 2/3] END ........C=1, gamma=0.1, kernel=rbf;, score=0.771 total time= 1.3min\n",
      "[CV 3/3] END ........C=1, gamma=0.1, kernel=rbf;, score=0.762 total time= 1.3min\n",
      "[CV 1/3] END .......C=1, gamma=0.01, kernel=rbf;, score=0.846 total time=  54.5s\n",
      "[CV 2/3] END .......C=1, gamma=0.01, kernel=rbf;, score=0.851 total time=  54.7s\n",
      "[CV 3/3] END .......C=1, gamma=0.01, kernel=rbf;, score=0.850 total time=  54.7s\n",
      "[CV 1/3] END ......C=1, gamma=0.001, kernel=rbf;, score=0.686 total time= 1.0min\n",
      "[CV 2/3] END ......C=1, gamma=0.001, kernel=rbf;, score=0.674 total time= 1.0min\n",
      "[CV 3/3] END ......C=1, gamma=0.001, kernel=rbf;, score=0.666 total time=  59.6s\n",
      "[CV 1/3] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.550 total time= 1.1min\n",
      "[CV 2/3] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.557 total time= 1.1min\n",
      "[CV 3/3] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.558 total time= 1.1min\n",
      "[CV 1/3] END .........C=10, gamma=1, kernel=rbf;, score=0.655 total time= 1.9min\n",
      "[CV 2/3] END .........C=10, gamma=1, kernel=rbf;, score=0.662 total time= 1.9min\n",
      "[CV 3/3] END .........C=10, gamma=1, kernel=rbf;, score=0.667 total time= 1.6min\n",
      "[CV 1/3] END .......C=10, gamma=0.1, kernel=rbf;, score=0.738 total time= 1.6min\n",
      "[CV 2/3] END .......C=10, gamma=0.1, kernel=rbf;, score=0.792 total time= 1.4min\n",
      "[CV 3/3] END .......C=10, gamma=0.1, kernel=rbf;, score=0.763 total time= 1.4min\n",
      "[CV 1/3] END ......C=10, gamma=0.01, kernel=rbf;, score=0.856 total time= 1.1min\n",
      "[CV 2/3] END ......C=10, gamma=0.01, kernel=rbf;, score=0.859 total time= 1.2min\n",
      "[CV 3/3] END ......C=10, gamma=0.01, kernel=rbf;, score=0.856 total time= 1.2min\n",
      "[CV 1/3] END .....C=10, gamma=0.001, kernel=rbf;, score=0.782 total time=  49.2s\n",
      "[CV 2/3] END .....C=10, gamma=0.001, kernel=rbf;, score=0.788 total time=  49.7s\n",
      "[CV 3/3] END .....C=10, gamma=0.001, kernel=rbf;, score=0.782 total time=  48.9s\n",
      "[CV 1/3] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.640 total time=  59.5s\n",
      "[CV 2/3] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.627 total time=  59.9s\n",
      "[CV 3/3] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.635 total time= 1.0min\n",
      "0.643\n",
      "{'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=101)\n",
    "\n",
    "best_svc = GridSearchCV(\n",
    "    SVC(random_state=101, probability=True),\n",
    "    param_grid,\n",
    "    refit=True,\n",
    "    cv=cv,\n",
    "    verbose=3\n",
    ")\n",
    "\n",
    "best_svc.fit(X_train, y_train)\n",
    "pred = best_svc.best_estimator_.predict(X_test)\n",
    "print(accuracy_score(y_test, pred))\n",
    "print(best_svc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV 1/3] END ........C=100, gamma=1, kernel=rbf;, score=0.744 total time= 5.1min\n",
      "[CV 2/3] END ........C=100, gamma=1, kernel=rbf;, score=0.710 total time= 4.6min\n",
      "[CV 3/3] END ........C=100, gamma=1, kernel=rbf;, score=0.649 total time= 2.6min\n",
      "[CV 1/3] END ......C=100, gamma=0.1, kernel=rbf;, score=0.803 total time=  40.5s\n",
      "[CV 2/3] END ......C=100, gamma=0.1, kernel=rbf;, score=0.841 total time=  38.1s\n",
      "[CV 3/3] END ......C=100, gamma=0.1, kernel=rbf;, score=0.715 total time=  37.1s\n",
      "[CV 1/3] END .....C=100, gamma=0.01, kernel=rbf;, score=0.865 total time=  32.4s\n",
      "[CV 2/3] END .....C=100, gamma=0.01, kernel=rbf;, score=0.898 total time=  33.6s\n",
      "[CV 3/3] END .....C=100, gamma=0.01, kernel=rbf;, score=0.812 total time=  43.0s\n",
      "[CV 1/3] END ....C=100, gamma=0.001, kernel=rbf;, score=0.858 total time=  25.4s\n",
      "[CV 2/3] END ....C=100, gamma=0.001, kernel=rbf;, score=0.899 total time=  30.9s\n",
      "[CV 3/3] END ....C=100, gamma=0.001, kernel=rbf;, score=0.815 total time=  26.3s\n",
      "[CV 1/3] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.674 total time=  33.0s\n",
      "[CV 2/3] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.709 total time=  34.2s\n",
      "[CV 3/3] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.660 total time=  33.5s\n",
      "[CV 1/3] END .......C=1000, gamma=1, kernel=rbf;, score=0.744 total time=  45.9s\n",
      "[CV 2/3] END .......C=1000, gamma=1, kernel=rbf;, score=0.710 total time=  43.6s\n",
      "[CV 3/3] END .......C=1000, gamma=1, kernel=rbf;, score=0.649 total time=  45.5s\n",
      "[CV 1/3] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.803 total time=  48.5s\n",
      "[CV 2/3] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.841 total time=  45.5s\n",
      "[CV 3/3] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.715 total time=  45.7s\n",
      "[CV 1/3] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.865 total time=  44.3s\n",
      "[CV 2/3] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.898 total time=  42.0s\n",
      "[CV 3/3] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.812 total time=  44.6s\n",
      "[CV 1/3] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.863 total time=  38.2s\n",
      "[CV 2/3] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.912 total time=  46.2s\n",
      "[CV 3/3] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.820 total time=  34.3s\n",
      "[CV 1/3] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.784 total time=  44.3s\n",
      "[CV 2/3] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.813 total time=  49.1s\n",
      "[CV 3/3] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.734 total time=  43.3s\n",
      "[CV 1/3] END .......C=5000, gamma=1, kernel=rbf;, score=0.744 total time=  52.6s\n",
      "[CV 2/3] END .......C=5000, gamma=1, kernel=rbf;, score=0.710 total time=  50.3s\n",
      "[CV 3/3] END .......C=5000, gamma=1, kernel=rbf;, score=0.649 total time=  46.9s\n",
      "[CV 1/3] END .....C=5000, gamma=0.1, kernel=rbf;, score=0.803 total time=  48.8s\n",
      "[CV 2/3] END .....C=5000, gamma=0.1, kernel=rbf;, score=0.841 total time=  44.5s\n",
      "[CV 3/3] END .....C=5000, gamma=0.1, kernel=rbf;, score=0.715 total time=  42.2s\n",
      "[CV 1/3] END ....C=5000, gamma=0.01, kernel=rbf;, score=0.865 total time=  48.0s\n",
      "[CV 2/3] END ....C=5000, gamma=0.01, kernel=rbf;, score=0.898 total time=  46.0s\n",
      "[CV 3/3] END ....C=5000, gamma=0.01, kernel=rbf;, score=0.812 total time=  47.5s\n",
      "[CV 1/3] END ...C=5000, gamma=0.001, kernel=rbf;, score=0.863 total time=  39.5s\n",
      "[CV 2/3] END ...C=5000, gamma=0.001, kernel=rbf;, score=0.912 total time=  46.3s\n",
      "[CV 3/3] END ...C=5000, gamma=0.001, kernel=rbf;, score=0.821 total time=  36.1s\n",
      "[CV 1/3] END ..C=5000, gamma=0.0001, kernel=rbf;, score=0.854 total time= 1.2min\n",
      "[CV 2/3] END ..C=5000, gamma=0.0001, kernel=rbf;, score=0.881 total time= 1.4min\n",
      "[CV 3/3] END ..C=5000, gamma=0.0001, kernel=rbf;, score=0.808 total time= 1.4min\n",
      "[CV 1/3] END ......C=10000, gamma=1, kernel=rbf;, score=0.744 total time= 1.3min\n",
      "[CV 2/3] END ......C=10000, gamma=1, kernel=rbf;, score=0.710 total time= 1.3min\n",
      "[CV 3/3] END ......C=10000, gamma=1, kernel=rbf;, score=0.649 total time=  58.2s\n",
      "[CV 1/3] END ....C=10000, gamma=0.1, kernel=rbf;, score=0.803 total time= 1.1min\n",
      "[CV 2/3] END ....C=10000, gamma=0.1, kernel=rbf;, score=0.841 total time= 1.1min\n",
      "[CV 3/3] END ....C=10000, gamma=0.1, kernel=rbf;, score=0.715 total time= 1.1min\n",
      "[CV 1/3] END ...C=10000, gamma=0.01, kernel=rbf;, score=0.865 total time=  47.8s\n",
      "[CV 2/3] END ...C=10000, gamma=0.01, kernel=rbf;, score=0.898 total time=  29.2s\n",
      "[CV 3/3] END ...C=10000, gamma=0.01, kernel=rbf;, score=0.812 total time=  31.9s\n",
      "[CV 1/3] END ..C=10000, gamma=0.001, kernel=rbf;, score=0.863 total time=  29.2s\n",
      "[CV 2/3] END ..C=10000, gamma=0.001, kernel=rbf;, score=0.912 total time=  48.2s\n",
      "[CV 3/3] END ..C=10000, gamma=0.001, kernel=rbf;, score=0.821 total time=  37.5s\n",
      "[CV 1/3] END .C=10000, gamma=0.0001, kernel=rbf;, score=0.863 total time= 1.4min\n",
      "[CV 2/3] END .C=10000, gamma=0.0001, kernel=rbf;, score=0.905 total time= 1.6min\n",
      "[CV 3/3] END .C=10000, gamma=0.0001, kernel=rbf;, score=0.816 total time= 1.4min\n",
      "0.628\n",
      "{'C': 5000, 'gamma': 0.001, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100, 1000],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=101)\n",
    "\n",
    "best_svc = GridSearchCV(\n",
    "    SVC(random_state=101, probability=True),\n",
    "    param_grid,\n",
    "    refit=True,\n",
    "    cv=3,\n",
    "    verbose=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "best_svc.fit(X_train, y_train)\n",
    "pred = best_svc.best_estimator_.predict(X_test)\n",
    "print(accuracy_score(y_test, pred))\n",
    "print(best_svc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 1 is smaller than n_iter=50. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 2/5] END C=10, gamma=0.0001, kernel=rbf;, score=(train=0.831, test=0.759) total time=  36.6s\n",
      "[CV 1/5] END C=10, gamma=0.0001, kernel=rbf;, score=(train=0.832, test=0.750) total time=  37.3s\n",
      "[CV 5/5] END C=10, gamma=0.0001, kernel=rbf;, score=(train=0.830, test=0.749) total time=  37.1s\n",
      "[CV 3/5] END C=10, gamma=0.0001, kernel=rbf;, score=(train=0.827, test=0.775) total time=  37.5s\n",
      "[CV 4/5] END C=10, gamma=0.0001, kernel=rbf;, score=(train=0.831, test=0.758) total time=  38.0s\n",
      "0.647\n",
      "{'kernel': 'rbf', 'gamma': 0.0001, 'C': 10}\n"
     ]
    }
   ],
   "source": [
    "param_distributions = {\n",
    "    'C': [10],\n",
    "    'gamma': [1e-4],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=101)\n",
    "\n",
    "best_svc2 = RandomizedSearchCV(\n",
    "    estimator=SVC(random_state=101, probability=True),\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50,\n",
    "    cv=cv,\n",
    "    verbose=3,\n",
    "    scoring='accuracy',\n",
    "    random_state=101,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "best_svc2.fit(X_train, y_train)\n",
    "pred = best_svc2.best_estimator_.predict(X_test)\n",
    "print(accuracy_score(y_test, pred))\n",
    "print(best_svc2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.672\n",
      "{'solver': 'adam', 'max_iter': 2000, 'hidden_layer_sizes': (75, 50), 'alpha': 1e-06, 'activation': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(75, 50), (75, 50, 25), (50, 25)],\n",
    "    'activation': ['relu', 'logistic'],\n",
    "    'alpha': [1e-6, 1e-4, 1e-2],\n",
    "    'max_iter': [1000, 1500, 2000],\n",
    "    'solver': ['adam']\n",
    "}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=101)\n",
    "\n",
    "best_mlp = RandomizedSearchCV(\n",
    "    MLPClassifier(random_state=101, early_stopping=True, validation_fraction=0.1),\n",
    "    param_distributions=param_grid,\n",
    "    refit=True,\n",
    "    cv=cv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "best_mlp.fit(X_train, y_train)\n",
    "pred = best_mlp.best_estimator_.predict(X_test)\n",
    "print(f\"{accuracy_score(y_test, pred)}\")\n",
    "print(f\"{best_mlp.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 9 is smaller than n_iter=10. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.668\n",
      "{'solver': 'adam', 'max_iter': 1000, 'hidden_layer_sizes': (75, 50), 'alpha': 0.01, 'activation': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(75, 50), (75, 50, 25), (50, 25)],\n",
    "    'activation': ['relu'],\n",
    "    'alpha': [1e-2],\n",
    "    'max_iter': [1000, 1500, 2000],\n",
    "    'solver': ['adam']\n",
    "}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=101)\n",
    "\n",
    "best_mlp = RandomizedSearchCV(\n",
    "    MLPClassifier(random_state=101, early_stopping=True, validation_fraction=0.1),\n",
    "    param_distributions=param_grid,\n",
    "    refit=True,\n",
    "    cv=cv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "best_mlp.fit(X_train, y_train)\n",
    "pred = best_mlp.best_estimator_.predict(X_test)\n",
    "print(f\"{accuracy_score(y_test, pred)}\")\n",
    "print(f\"{best_mlp.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 9 is smaller than n_iter=10. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.672\n",
      "{'solver': 'adam', 'max_iter': 1000, 'hidden_layer_sizes': (128, 84, 48), 'alpha': 1e-08, 'activation': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(75, 50), (75, 50, 25), (80, 50)],\n",
    "    'activation': ['relu'],\n",
    "    'alpha': [1e-8],\n",
    "    'max_iter': [1000, 1500, 2000],\n",
    "    'solver': ['adam']\n",
    "}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=101)\n",
    "\n",
    "best_mlp2 = RandomizedSearchCV(\n",
    "    MLPClassifier(random_state=101, early_stopping=True, validation_fraction=0.1),\n",
    "    param_distributions=param_grid,\n",
    "    refit=True,\n",
    "    cv=cv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "best_mlp2.fit(X_train, y_train)\n",
    "pred = best_mlp2.best_estimator_.predict(X_test)\n",
    "print(f\"{accuracy_score(y_test, pred)}\")\n",
    "print(f\"{best_mlp.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.681\n",
      "{'solver': 'adam', 'max_iter': 1000, 'hidden_layer_sizes': (128, 84, 48), 'alpha': 1e-08, 'activation': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(128, 84, 48)],\n",
    "    'activation': ['relu'],\n",
    "    'alpha': [1e-8],\n",
    "    'max_iter': [1000],\n",
    "    'solver': ['adam']\n",
    "}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=101)\n",
    "\n",
    "best_mlp = RandomizedSearchCV(\n",
    "    MLPClassifier(random_state=101, early_stopping=True, validation_fraction=0.1),\n",
    "    param_distributions=param_grid,\n",
    "    refit=True,\n",
    "    cv=cv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "best_mlp.fit(X_train, y_train)\n",
    "pred = best_mlp.best_estimator_.predict(X_test)\n",
    "print(f\"{accuracy_score(y_test, pred)}\")\n",
    "print(f\"{best_mlp.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 32 0.651\n",
      "63 34 0.641\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[133], line 22\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=101)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m best_mlp \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[1;32m     17\u001b[0m     MLPClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m101\u001b[39m, early_stopping\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, validation_fraction\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m),\n\u001b[1;32m     18\u001b[0m     param_distributions\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[1;32m     19\u001b[0m     refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     20\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     21\u001b[0m )\n\u001b[0;32m---> 22\u001b[0m \u001b[43mbest_mlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m pred \u001b[38;5;241m=\u001b[39m best_mlp\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     24\u001b[0m score \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, pred)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1015\u001b[0m     )\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1960\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1958\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1959\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1960\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1961\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1962\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1963\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/model_selection/_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    962\u001b[0m         )\n\u001b[1;32m    963\u001b[0m     )\n\u001b[0;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    988\u001b[0m     )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "best = 0\n",
    "best_node = []\n",
    "for i in range(63, 129):\n",
    "    for j in range(32, 85, 2):\n",
    "        param_grid = {\n",
    "            'hidden_layer_sizes': [(i, j)], # 68.1 (128, 84, 48),\n",
    "            'activation': ['relu'],\n",
    "            'alpha': [1e-8],\n",
    "            'max_iter': [1000],\n",
    "            'solver': ['adam']\n",
    "        }\n",
    "        # cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=101)\n",
    "\n",
    "        best_mlp = RandomizedSearchCV(\n",
    "            MLPClassifier(random_state=101, early_stopping=True, validation_fraction=0.1),\n",
    "            param_distributions=param_grid,\n",
    "            refit=True,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        best_mlp.fit(X_train, y_train)\n",
    "        pred = best_mlp.best_estimator_.predict(X_test)\n",
    "        score = accuracy_score(y_test, pred)\n",
    "        print(i, j, score)\n",
    "        if score > best:\n",
    "            best = score\n",
    "            best_node = [i, j]\n",
    "\n",
    "print(best, best_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=5, n_estimators=250, subsample=1.0;, score=0.608 total time= 1.9min\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=5, n_estimators=250, subsample=1.0;, score=0.620 total time= 1.9min\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=5, n_estimators=250, subsample=1.0;, score=0.628 total time= 1.9min\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=5, n_estimators=250, subsample=1.0;, score=0.609 total time= 1.9min\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=5, n_estimators=250, subsample=1.0;, score=0.617 total time= 1.9min\n",
      "[CV 1/5] END learning_rate=10, max_depth=3, n_estimators=750, subsample=0.8;, score=0.451 total time= 2.9min\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=7, n_estimators=500, subsample=1.0;, score=0.678 total time= 5.2min\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=7, n_estimators=500, subsample=1.0;, score=0.677 total time= 5.3min\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=7, n_estimators=500, subsample=1.0;, score=0.675 total time= 5.3min\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=7, n_estimators=500, subsample=1.0;, score=0.676 total time= 5.3min\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=7, n_estimators=500, subsample=1.0;, score=0.665 total time= 5.4min\n",
      "[CV 2/5] END learning_rate=10, max_depth=3, n_estimators=750, subsample=0.8;, score=0.511 total time= 3.2min\n",
      "[CV 3/5] END learning_rate=10, max_depth=3, n_estimators=750, subsample=0.8;, score=0.499 total time= 3.2min\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=250, subsample=1.0;, score=0.824 total time= 2.2min\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=250, subsample=1.0;, score=0.837 total time= 2.2min\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=250, subsample=1.0;, score=0.825 total time= 2.2min\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=250, subsample=1.0;, score=0.836 total time= 2.2min\n",
      "[CV 4/5] END learning_rate=10, max_depth=3, n_estimators=750, subsample=0.8;, score=0.528 total time= 3.3min\n",
      "[CV 5/5] END learning_rate=10, max_depth=3, n_estimators=750, subsample=0.8;, score=0.498 total time= 3.3min\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=250, subsample=1.0;, score=0.829 total time= 2.4min\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=3, n_estimators=750, subsample=0.8;, score=0.614 total time= 3.4min\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=3, n_estimators=750, subsample=0.8;, score=0.620 total time= 3.4min\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=3, n_estimators=750, subsample=0.8;, score=0.615 total time= 3.2min\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=750, subsample=1.0;, score=0.854 total time= 6.7min\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=750, subsample=1.0;, score=0.860 total time= 6.7min\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=750, subsample=1.0;, score=0.867 total time= 6.7min\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=750, subsample=1.0;, score=0.850 total time= 6.7min\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=750, subsample=1.0;, score=0.845 total time= 6.7min\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=3, n_estimators=750, subsample=0.8;, score=0.615 total time= 3.2min\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=3, n_estimators=750, subsample=0.8;, score=0.615 total time= 3.3min\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=5, n_estimators=250, subsample=0.8;, score=0.631 total time= 1.9min\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=5, n_estimators=250, subsample=0.8;, score=0.640 total time= 1.9min\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=5, n_estimators=250, subsample=0.8;, score=0.636 total time= 1.9min\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.8;, score=0.835 total time= 4.9min\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=5, n_estimators=250, subsample=0.8;, score=0.637 total time= 2.0min\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=5, n_estimators=250, subsample=0.8;, score=0.628 total time= 2.0min\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.8;, score=0.846 total time= 5.0min\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.8;, score=0.830 total time= 5.0min\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.8;, score=0.846 total time= 5.0min\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.8;, score=0.830 total time= 5.1min\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=250, subsample=1.0;, score=0.790 total time= 2.9min\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=250, subsample=1.0;, score=0.773 total time= 2.9min\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=250, subsample=1.0;, score=0.774 total time= 2.9min\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=500, subsample=1.0;, score=0.825 total time= 5.9min\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=500, subsample=1.0;, score=0.825 total time= 5.8min\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=500, subsample=1.0;, score=0.816 total time= 5.8min\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=500, subsample=1.0;, score=0.834 total time= 5.6min\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=500, subsample=1.0;, score=0.815 total time= 5.6min\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=250, subsample=1.0;, score=0.774 total time= 2.4min\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=250, subsample=1.0;, score=0.787 total time= 2.4min\n",
      "0.635\n",
      "{'subsample': 1.0, 'n_estimators': 750, 'max_depth': 5, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [1e-3, 1e-2, 1e-1, 1, 10],\n",
    "    'n_estimators': [100, 250, 500, 750],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 1.0],\n",
    "}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=101)\n",
    "\n",
    "best_gbc = RandomizedSearchCV(\n",
    "    estimator=GradientBoostingClassifier(random_state=101),\n",
    "    param_distributions=param_grid,\n",
    "    cv=cv,\n",
    "    verbose=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "best_gbc.fit(X_train, y_train)\n",
    "pred = best_gbc.best_estimator_.predict(X_test)\n",
    "print(accuracy_score(y_test, pred))\n",
    "print(best_gbc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.700, test=0.641) total time=   7.5s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.708, test=0.656) total time=   7.7s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.701, test=0.647) total time=   7.6s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.698, test=0.652) total time=   7.8s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.005, loss=deviance, max_depth=3, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.005, loss=deviance, max_depth=3, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.005, loss=deviance, max_depth=3, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.005, loss=deviance, max_depth=3, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=deviance, max_depth=3, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.688, test=0.645) total time=   8.0s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.852, test=0.730) total time=  21.6s\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.856, test=0.730) total time=  21.8s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.854, test=0.752) total time=  22.1s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=0.655, test=0.624) total time=   5.4s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.6;, score=(train=0.755, test=0.676) total time=  38.9s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.6;, score=(train=0.751, test=0.672) total time=  39.3s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.6;, score=(train=0.757, test=0.665) total time=  39.2s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=0.657, test=0.629) total time=   5.4s\n",
      "[CV 1/5] END learning_rate=0.005, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.005, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.005, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.005, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.005, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.005, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.005, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.005, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=0.661, test=0.613) total time=   5.4s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=0.657, test=0.617) total time=   5.1s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=0.662, test=0.626) total time=   5.3s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.6;, score=(train=0.751, test=0.677) total time=  38.9s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.6;, score=(train=0.764, test=0.688) total time=  39.4s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.858, test=0.738) total time=  22.8s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.845, test=0.736) total time=  22.5s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.742, test=0.663) total time=  23.4s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.751, test=0.665) total time=  24.1s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.749, test=0.667) total time=  24.8s\n",
      "[CV 1/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.748, test=0.659) total time=  25.1s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.743, test=0.680) total time=  24.4s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.7;, score=(train=0.820, test=0.725) total time=  29.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.7;, score=(train=0.831, test=0.724) total time=  28.2s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.7;, score=(train=0.830, test=0.714) total time=  28.3s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.836, test=0.747) total time=   9.1s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.7;, score=(train=0.835, test=0.732) total time=  27.5s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.7;, score=(train=0.817, test=0.711) total time=  26.8s\n",
      "[CV 2/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.842, test=0.730) total time=   9.1s\n",
      "[CV 3/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.841, test=0.725) total time=   9.4s\n",
      "[CV 4/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.849, test=0.734) total time=   9.4s\n",
      "[CV 5/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.837, test=0.734) total time=   9.8s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.8;, score=(train=0.944, test=0.815) total time=  39.6s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.8;, score=(train=0.945, test=0.795) total time=  40.1s\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.8;, score=(train=0.947, test=0.784) total time=  41.0s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.8;, score=(train=0.947, test=0.800) total time=  41.3s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.8;, score=(train=0.943, test=0.800) total time=  41.7s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.6;, score=(train=0.802, test=0.724) total time=  32.3s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.6;, score=(train=0.814, test=0.723) total time=  32.4s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.6;, score=(train=0.824, test=0.724) total time=  31.6s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.6;, score=(train=0.817, test=0.710) total time=  32.4s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.6;, score=(train=0.810, test=0.715) total time=  32.2s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=750, subsample=0.7;, score=(train=0.761, test=0.696) total time=  31.2s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=750, subsample=0.7;, score=(train=0.764, test=0.690) total time=  30.5s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=750, subsample=0.7;, score=(train=0.777, test=0.688) total time=  30.3s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=deviance, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=deviance, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=deviance, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=deviance, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=deviance, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=750, subsample=0.7;, score=(train=0.777, test=0.688) total time=  30.7s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=750, subsample=0.7;, score=(train=0.764, test=0.686) total time=  30.1s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=750, subsample=0.7;, score=(train=0.819, test=0.736) total time=  19.7s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=750, subsample=0.7;, score=(train=0.868, test=0.763) total time=  32.5s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=750, subsample=0.7;, score=(train=0.868, test=0.753) total time=  32.9s\n",
      "[CV 1/5] END learning_rate=0.005, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.005, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.005, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.005, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=750, subsample=0.7;, score=(train=0.872, test=0.741) total time=  33.5s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=750, subsample=0.7;, score=(train=0.881, test=0.757) total time=  33.0s\n",
      "[CV 1/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.9;, score=(train=0.816, test=0.722) total time=   5.3s\n",
      "[CV 2/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.9;, score=(train=0.819, test=0.702) total time=   4.9s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=750, subsample=0.7;, score=(train=0.858, test=0.749) total time=  33.5s\n",
      "[CV 3/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.9;, score=(train=0.822, test=0.700) total time=   5.4s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=750, subsample=0.7;, score=(train=0.821, test=0.722) total time=  19.4s\n",
      "[CV 4/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.9;, score=(train=0.829, test=0.712) total time=   5.1s\n",
      "[CV 5/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.9;, score=(train=0.808, test=0.695) total time=   5.0s\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=750, subsample=0.7;, score=(train=0.825, test=0.710) total time=  20.2s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=750, subsample=0.7;, score=(train=0.821, test=0.725) total time=  20.3s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=750, subsample=0.7;, score=(train=0.813, test=0.713) total time=  20.9s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250, subsample=0.9;, score=(train=0.659, test=0.601) total time=  18.9s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250, subsample=0.9;, score=(train=0.658, test=0.584) total time=  18.4s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250, subsample=0.9;, score=(train=0.654, test=0.585) total time=  18.7s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.7;, score=(train=0.758, test=0.693) total time=  41.4s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.7;, score=(train=0.749, test=0.691) total time=  41.8s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250, subsample=0.9;, score=(train=0.654, test=0.585) total time=  18.9s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.7;, score=(train=0.764, test=0.675) total time=  42.3s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.7;, score=(train=0.754, test=0.675) total time=  42.0s\n",
      "[CV 1/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=250, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=250, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=250, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=250, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=250, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.7;, score=(train=0.770, test=0.683) total time=  43.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250, subsample=0.9;, score=(train=0.647, test=0.589) total time=  18.4s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=0.619, test=0.596) total time=  33.7s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=0.748, test=0.658) total time=  28.2s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=0.744, test=0.659) total time=  28.6s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=0.619, test=0.590) total time=  32.8s\n",
      "[CV 2/5] END learning_rate=0.001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=0.612, test=0.584) total time=  33.5s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=0.752, test=0.653) total time=  28.5s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=0.622, test=0.599) total time=  33.1s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=0.618, test=0.596) total time=  32.8s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.519, test=0.511) total time=   8.5s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.520, test=0.515) total time=   8.6s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.521, test=0.512) total time=   8.6s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.514, test=0.507) total time=   8.6s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.516, test=0.513) total time=   8.9s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=0.756, test=0.660) total time=  29.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.533, test=0.524) total time=  11.3s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.524, test=0.515) total time=  11.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=0.743, test=0.665) total time=  29.6s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.536, test=0.526) total time=  11.4s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=deviance, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=deviance, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=deviance, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=deviance, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=deviance, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.526, test=0.522) total time=  11.3s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.639, test=0.596) total time=  14.8s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.502, test=0.503) total time=   2.5s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.502, test=0.503) total time=   2.3s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.646, test=0.593) total time=  14.9s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.503, test=0.502) total time=   2.3s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.502, test=0.503) total time=   2.4s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.503, test=0.502) total time=   2.5s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.8;, score=(train=0.754, test=0.670) total time=  36.8s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.8;, score=(train=0.742, test=0.682) total time=  37.4s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.640, test=0.596) total time=  15.2s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.8;, score=(train=0.747, test=0.672) total time=  37.5s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.651, test=0.595) total time=  15.2s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.637, test=0.591) total time=  15.2s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.529, test=0.519) total time=  12.5s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.8;, score=(train=0.759, test=0.681) total time=  40.5s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.8;, score=(train=0.746, test=0.682) total time=  40.9s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=0.739, test=0.661) total time=  25.6s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=750, subsample=1.0;, score=(train=0.880, test=0.773) total time=  49.9s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=750, subsample=1.0;, score=(train=0.885, test=0.751) total time=  51.0s\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=750, subsample=1.0;, score=(train=0.885, test=0.744) total time=  51.1s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=750, subsample=1.0;, score=(train=0.891, test=0.768) total time=  50.8s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=750, subsample=1.0;, score=(train=0.880, test=0.755) total time=  51.4s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=0.744, test=0.661) total time=  26.3s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=0.748, test=0.653) total time=  26.2s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=0.747, test=0.655) total time=  26.5s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=0.741, test=0.663) total time=  27.1s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.797, test=0.715) total time=  26.0s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.803, test=0.704) total time=  26.1s\n",
      "[CV 1/5] END learning_rate=0.005, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.872, test=0.765) total time=  17.1s\n",
      "[CV 1/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.805, test=0.701) total time=  26.3s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.815, test=0.714) total time=  25.9s\n",
      "[CV 2/5] END learning_rate=0.005, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.874, test=0.758) total time=  17.6s\n",
      "[CV 3/5] END learning_rate=0.005, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.881, test=0.744) total time=  17.6s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.794, test=0.703) total time=  26.2s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.884, test=0.760) total time=  17.9s\n",
      "[CV 5/5] END learning_rate=0.005, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.870, test=0.751) total time=  17.7s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.9;, score=(train=0.619, test=0.596) total time=  31.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.9;, score=(train=0.614, test=0.580) total time=  31.3s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.9;, score=(train=0.614, test=0.585) total time=  31.2s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.9;, score=(train=0.618, test=0.589) total time=  31.6s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.641, test=0.600) total time=   3.4s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.9;, score=(train=0.612, test=0.593) total time=  31.2s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.650, test=0.594) total time=   3.5s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.648, test=0.596) total time=   3.4s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.643, test=0.600) total time=   3.4s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.640, test=0.600) total time=   3.4s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=1.0;, score=(train=0.755, test=0.685) total time=  40.2s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=1.0;, score=(train=0.759, test=0.676) total time=  41.3s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=1.0;, score=(train=0.771, test=0.678) total time=  40.5s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=deviance, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=deviance, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=deviance, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=deviance, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=deviance, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.9;, score=(train=0.724, test=0.670) total time=  29.8s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.9;, score=(train=0.728, test=0.654) total time=  29.9s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=1.0;, score=(train=0.767, test=0.680) total time=  40.8s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.9;, score=(train=0.736, test=0.665) total time=  30.5s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=1.0;, score=(train=0.765, test=0.686) total time=  40.7s\n",
      "[CV 1/5] END learning_rate=0.005, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.005, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.005, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.005, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.9;, score=(train=0.736, test=0.665) total time=  30.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.9;, score=(train=0.726, test=0.657) total time=  29.6s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=0.744, test=0.684) total time=  32.6s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.868, test=0.754) total time=   5.8s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.8;, score=(train=0.750, test=0.690) total time=  20.7s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.8;, score=(train=0.749, test=0.685) total time=  20.7s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.871, test=0.745) total time=   5.9s\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.861, test=0.731) total time=   5.9s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.8;, score=(train=0.750, test=0.690) total time=  20.6s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=0.752, test=0.684) total time=  31.9s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=deviance, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=deviance, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=deviance, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=deviance, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=deviance, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=deviance, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=deviance, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=deviance, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=deviance, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=deviance, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, loss=deviance, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, loss=deviance, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=0.762, test=0.673) total time=  32.0s\n",
      "[CV 3/5] END learning_rate=0.01, loss=deviance, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, loss=deviance, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, loss=deviance, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=0.763, test=0.686) total time=  32.3s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=0.752, test=0.677) total time=  31.4s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.855, test=0.734) total time=   6.0s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.874, test=0.746) total time=   6.0s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=1000, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=1000, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=1000, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=1000, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=1000, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=0.839, test=0.746) total time=  14.4s\n",
      "[CV 2/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=0.840, test=0.725) total time=  14.6s\n",
      "[CV 3/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=0.845, test=0.728) total time=  14.5s\n",
      "[CV 4/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=0.850, test=0.729) total time=  14.2s\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.8;, score=(train=0.761, test=0.680) total time=  20.4s\n",
      "[CV 1/5] END learning_rate=0.01, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.725, test=0.678) total time=  13.2s\n",
      "[CV 5/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=0.835, test=0.716) total time=  14.8s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.8;, score=(train=0.753, test=0.672) total time=  20.3s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.8;, score=(train=0.610, test=0.585) total time=   2.8s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.8;, score=(train=0.614, test=0.580) total time=   2.9s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.8;, score=(train=0.608, test=0.579) total time=   2.7s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.8;, score=(train=0.618, test=0.593) total time=   2.7s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.8;, score=(train=0.608, test=0.586) total time=   2.8s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.729, test=0.676) total time=  13.5s\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.735, test=0.672) total time=  13.8s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.736, test=0.678) total time=  13.7s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.728, test=0.661) total time=  14.0s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.695, test=0.652) total time=  17.2s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.695, test=0.650) total time=  17.1s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.701, test=0.636) total time=  16.9s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.005, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.005, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.005, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.005, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.8;, score=(train=0.808, test=0.720) total time=  27.9s\n",
      "[CV 3/5] END learning_rate=0.005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.8;, score=(train=0.814, test=0.710) total time=  28.0s\n",
      "[CV 2/5] END learning_rate=0.005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.8;, score=(train=0.814, test=0.715) total time=  28.1s\n",
      "[CV 4/5] END learning_rate=0.005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.8;, score=(train=0.817, test=0.716) total time=  27.8s\n",
      "[CV 5/5] END learning_rate=0.005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.8;, score=(train=0.803, test=0.709) total time=  27.8s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.704, test=0.660) total time=  16.9s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.702, test=0.650) total time=  16.6s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=0.818, test=0.726) total time=  53.5s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=0.824, test=0.725) total time=  53.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=0.828, test=0.719) total time=  52.6s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=0.834, test=0.727) total time=  53.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=0.816, test=0.716) total time=  52.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "305 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "76 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of GradientBoostingClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "203 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "14 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of GradientBoostingClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.64827273        nan        nan 0.67545455        nan        nan\n",
      " 0.73727273 0.62181818        nan        nan 0.66672727        nan\n",
      " 0.72118182        nan 0.799             nan 0.73372727 0.71918182\n",
      " 0.68954545        nan        nan        nan        nan 0.75263636\n",
      "        nan 0.72136364        nan 0.70627273 0.68345455 0.58863636\n",
      " 0.59290909        nan        nan 0.65909091        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.51163636\n",
      " 0.67763636 0.52118182 0.59436364        nan        nan        nan\n",
      " 0.50254545 0.75818182        nan 0.65854545 0.70754545 0.75563636\n",
      "        nan 0.58881818        nan 0.68118182 0.59827273        nan\n",
      " 0.66227273        nan        nan        nan        nan        nan\n",
      "        nan 0.68081818        nan 0.68318182 0.74218182        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.72881818        nan        nan 0.67309091\n",
      "        nan        nan        nan        nan 0.58463636 0.71409091\n",
      "        nan 0.64963636        nan        nan        nan        nan\n",
      "        nan        nan 0.72245455        nan]\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the train scores are non-finite: [0.69925           nan        nan 0.75559091        nan        nan\n",
      " 0.85288636 0.65836364        nan        nan 0.74629545        nan\n",
      " 0.82645455        nan 0.94520455        nan 0.84086364 0.81343182\n",
      " 0.76854545        nan        nan        nan        nan 0.86913636\n",
      "        nan 0.81988636        nan 0.81877273 0.75893182 0.65415909\n",
      " 0.618             nan        nan 0.74875           nan        nan\n",
      "        nan        nan        nan        nan        nan 0.51793182\n",
      " 0.74959091 0.5295     0.64247727        nan        nan        nan\n",
      " 0.50254545 0.88445455        nan 0.74368182 0.80286364 0.87629545\n",
      "        nan 0.61531818        nan 0.76322727 0.64438636        nan\n",
      " 0.72984091        nan        nan        nan        nan        nan\n",
      "        nan 0.75454545        nan 0.75265909 0.86575           nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.84168182        nan        nan 0.73038636\n",
      "        nan        nan        nan        nan 0.61152273 0.81136364\n",
      "        nan 0.69959091        nan        nan        nan        nan\n",
      "        nan        nan 0.82420455        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier Accuracy: 0.657\n",
      "Best Parameters: {'subsample': 0.8, 'n_estimators': 750, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 6, 'loss': 'exponential', 'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=101)\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [1e-4, 5e-4, 1e-3, 5e-3, 1e-2],\n",
    "    'n_estimators': [100, 250, 500, 750, 1000],\n",
    "    'max_depth': [3, 4, 5, 6, 7],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'loss': ['deviance', 'exponential']\n",
    "}\n",
    "# Initialize the GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier(random_state=101)\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "best_gbc = RandomizedSearchCV(\n",
    "    estimator=gbc,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=100,  # Number of parameter settings sampled\n",
    "    cv=cv,\n",
    "    scoring='accuracy',\n",
    "    verbose=3,\n",
    "    random_state=101,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True  # To analyze training vs. validation scores\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "best_gbc.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "pred_gbc = best_gbc.best_estimator_.predict(X_test)\n",
    "print(\"Gradient Boosting Classifier Accuracy:\", accuracy_score(y_test, pred_gbc))\n",
    "print(\"Best Parameters:\", best_gbc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.730, test=0.657) total time=  19.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.727, test=0.668) total time=  19.1s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.725, test=0.667) total time=  19.4s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.725, test=0.677) total time=  19.4s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.005, loss=deviance, max_depth=3, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.005, loss=deviance, max_depth=3, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.005, loss=deviance, max_depth=3, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=deviance, max_depth=3, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.005, loss=deviance, max_depth=3, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.733, test=0.690) total time=  19.5s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.871, test=0.757) total time=  50.4s\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.863, test=0.741) total time=  50.3s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.864, test=0.748) total time=  51.3s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=0.693, test=0.640) total time=  10.3s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.6;, score=(train=0.805, test=0.701) total time= 1.5min\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.6;, score=(train=0.805, test=0.725) total time= 1.5min\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.6;, score=(train=0.806, test=0.713) total time= 1.5min\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=0.690, test=0.644) total time=  10.3s\n",
      "[CV 1/5] END learning_rate=0.005, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.005, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.005, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.005, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.005, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.005, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.005, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.005, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=0.695, test=0.636) total time=  10.1s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=0.697, test=0.648) total time=  10.1s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=0.698, test=0.669) total time=  10.4s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.6;, score=(train=0.808, test=0.713) total time= 1.4min\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.6;, score=(train=0.820, test=0.745) total time= 1.4min\n",
      "[CV 1/5] END learning_rate=0.0005, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.865, test=0.750) total time=  42.3s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.869, test=0.768) total time=  42.6s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.835, test=0.728) total time=  48.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.838, test=0.728) total time=  49.1s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.832, test=0.751) total time=  49.6s\n",
      "[CV 1/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.840, test=0.736) total time=  49.5s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.855, test=0.762) total time=  49.4s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.7;, score=(train=0.836, test=0.730) total time=  57.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.7;, score=(train=0.838, test=0.727) total time=  57.6s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.7;, score=(train=0.839, test=0.741) total time=  58.0s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.848, test=0.737) total time=  18.5s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.7;, score=(train=0.832, test=0.735) total time=  54.9s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.7;, score=(train=0.843, test=0.750) total time=  54.1s\n",
      "[CV 2/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.847, test=0.754) total time=  21.4s\n",
      "[CV 3/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.850, test=0.738) total time=  23.7s\n",
      "[CV 4/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.844, test=0.735) total time=  23.3s\n",
      "[CV 5/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.857, test=0.758) total time=  21.1s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.8;, score=(train=0.950, test=0.800) total time= 1.4min\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.8;, score=(train=0.952, test=0.815) total time= 1.4min\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.8;, score=(train=0.951, test=0.811) total time= 1.4min\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.8;, score=(train=0.949, test=0.806) total time= 1.4min\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.8;, score=(train=0.952, test=0.810) total time= 1.4min\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.6;, score=(train=0.830, test=0.730) total time= 1.0min\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.6;, score=(train=0.826, test=0.737) total time= 1.0min\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.6;, score=(train=0.826, test=0.721) total time= 1.0min\n",
      "[CV 1/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.6;, score=(train=0.824, test=0.731) total time= 1.0min\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.6;, score=(train=0.840, test=0.753) total time= 1.0min\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=750, subsample=0.7;, score=(train=0.786, test=0.698) total time=  59.3s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=750, subsample=0.7;, score=(train=0.783, test=0.713) total time=  58.3s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=750, subsample=0.7;, score=(train=0.784, test=0.701) total time=  58.5s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=deviance, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=deviance, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=deviance, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=deviance, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=deviance, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=750, subsample=0.7;, score=(train=0.784, test=0.703) total time=  57.9s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=750, subsample=0.7;, score=(train=0.797, test=0.730) total time=  59.1s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=750, subsample=0.7;, score=(train=0.832, test=0.726) total time=  38.4s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=750, subsample=0.7;, score=(train=0.876, test=0.755) total time= 1.1min\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=750, subsample=0.7;, score=(train=0.880, test=0.765) total time= 1.1min\n",
      "[CV 1/5] END learning_rate=0.005, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.005, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.005, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.005, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=750, subsample=0.7;, score=(train=0.878, test=0.758) total time= 1.1min\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=750, subsample=0.7;, score=(train=0.878, test=0.761) total time= 1.1min\n",
      "[CV 1/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.9;, score=(train=0.822, test=0.712) total time=   8.4s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=750, subsample=0.7;, score=(train=0.892, test=0.779) total time= 1.0min\n",
      "[CV 2/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.9;, score=(train=0.822, test=0.722) total time=   8.7s\n",
      "[CV 3/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.9;, score=(train=0.829, test=0.710) total time=   8.6s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=750, subsample=0.7;, score=(train=0.827, test=0.735) total time=  36.7s\n",
      "[CV 4/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.9;, score=(train=0.822, test=0.713) total time=   9.2s\n",
      "[CV 5/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.9;, score=(train=0.831, test=0.745) total time=   9.3s\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=750, subsample=0.7;, score=(train=0.825, test=0.728) total time=  36.3s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=750, subsample=0.7;, score=(train=0.825, test=0.726) total time=  36.8s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=750, subsample=0.7;, score=(train=0.833, test=0.735) total time=  36.8s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250, subsample=0.9;, score=(train=0.827, test=0.718) total time=  35.9s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250, subsample=0.9;, score=(train=0.819, test=0.730) total time=  35.9s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250, subsample=0.9;, score=(train=0.828, test=0.722) total time=  35.6s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.7;, score=(train=0.776, test=0.707) total time= 1.3min\n",
      "[CV 1/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.7;, score=(train=0.778, test=0.693) total time= 1.3min\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250, subsample=0.9;, score=(train=0.828, test=0.730) total time=  33.3s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.7;, score=(train=0.779, test=0.693) total time= 1.3min\n",
      "[CV 4/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.7;, score=(train=0.779, test=0.700) total time= 1.3min\n",
      "[CV 1/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=250, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=250, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=250, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=250, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=250, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.7;, score=(train=0.789, test=0.721) total time= 1.3min\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250, subsample=0.9;, score=(train=0.840, test=0.745) total time=  32.9s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=0.670, test=0.625) total time=  57.8s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=0.852, test=0.735) total time=  48.4s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=0.846, test=0.752) total time=  48.5s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=0.666, test=0.645) total time=  57.4s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=0.669, test=0.615) total time=  57.8s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=0.849, test=0.733) total time=  49.6s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=0.672, test=0.635) total time=  57.5s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=0.677, test=0.650) total time=  57.9s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.696, test=0.633) total time=  15.5s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.684, test=0.634) total time=  14.7s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.696, test=0.630) total time=  14.5s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.692, test=0.632) total time=  14.4s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.693, test=0.654) total time=  14.3s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=0.847, test=0.741) total time=  48.8s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.691, test=0.627) total time=  17.3s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=0.858, test=0.761) total time=  48.2s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.683, test=0.629) total time=  17.4s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.688, test=0.639) total time=  17.5s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.8;, score=(train=0.775, test=0.687) total time=  57.8s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.694, test=0.632) total time=  17.6s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.767, test=0.694) total time=  22.8s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.692, test=0.647) total time=  17.4s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=deviance, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=deviance, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=deviance, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=deviance, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=deviance, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.8;, score=(train=0.768, test=0.701) total time=  57.5s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.8;, score=(train=0.773, test=0.685) total time=  57.1s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.575, test=0.560) total time=   3.5s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.573, test=0.545) total time=   3.6s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.8;, score=(train=0.774, test=0.698) total time=  58.5s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.8;, score=(train=0.783, test=0.719) total time=  58.1s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.566, test=0.552) total time=   3.9s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.574, test=0.555) total time=   3.9s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.574, test=0.562) total time=   4.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.764, test=0.678) total time=  23.1s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.777, test=0.706) total time=  23.3s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.759, test=0.698) total time=  22.9s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.765, test=0.693) total time=  19.7s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=0.846, test=0.736) total time=  32.2s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=0.849, test=0.752) total time=  30.7s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=0.853, test=0.737) total time=  30.4s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=0.845, test=0.740) total time=  31.2s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=750, subsample=1.0;, score=(train=0.903, test=0.773) total time= 1.1min\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=750, subsample=1.0;, score=(train=0.899, test=0.766) total time= 1.1min\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=750, subsample=1.0;, score=(train=0.894, test=0.760) total time= 1.0min\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=750, subsample=1.0;, score=(train=0.898, test=0.776) total time= 1.0min\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=0.859, test=0.770) total time=  31.2s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.825, test=0.731) total time=  30.5s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.825, test=0.735) total time=  30.4s\n",
      "[CV 1/5] END learning_rate=0.005, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.884, test=0.768) total time=  19.6s\n",
      "[CV 2/5] END learning_rate=0.005, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.890, test=0.774) total time=  19.4s\n",
      "[CV 1/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.825, test=0.720) total time=  28.9s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.826, test=0.727) total time=  29.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.836, test=0.750) total time=  29.0s\n",
      "[CV 3/5] END learning_rate=0.005, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.888, test=0.765) total time=  19.2s\n",
      "[CV 4/5] END learning_rate=0.005, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.890, test=0.770) total time=  19.4s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.005, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.896, test=0.782) total time=  19.1s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.9;, score=(train=0.684, test=0.631) total time=  30.3s\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=750, subsample=1.0;, score=(train=0.897, test=0.769) total time=  55.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.9;, score=(train=0.678, test=0.647) total time=  29.8s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.9;, score=(train=0.683, test=0.627) total time=  29.3s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.9;, score=(train=0.682, test=0.633) total time=  29.1s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.9;, score=(train=0.691, test=0.666) total time=  29.1s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.757, test=0.680) total time=   3.0s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.751, test=0.686) total time=   3.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.761, test=0.675) total time=   3.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.757, test=0.687) total time=   2.9s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.770, test=0.695) total time=   2.9s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=1.0;, score=(train=0.781, test=0.685) total time=  37.4s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=1.0;, score=(train=0.779, test=0.705) total time=  36.3s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=1.0;, score=(train=0.778, test=0.686) total time=  35.9s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=deviance, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=deviance, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=deviance, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=deviance, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=deviance, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.9;, score=(train=0.745, test=0.669) total time=  26.9s\n",
      "[CV 5/5] END learning_rate=0.01, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=1.0;, score=(train=0.780, test=0.699) total time=  36.6s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.9;, score=(train=0.745, test=0.686) total time=  27.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.9;, score=(train=0.746, test=0.668) total time=  26.7s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=1.0;, score=(train=0.792, test=0.720) total time=  35.9s\n",
      "[CV 1/5] END learning_rate=0.005, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.005, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.005, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.005, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.9;, score=(train=0.743, test=0.674) total time=  26.5s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.9;, score=(train=0.752, test=0.696) total time=  26.8s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.8;, score=(train=0.767, test=0.694) total time=  19.3s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.8;, score=(train=0.762, test=0.698) total time=  19.4s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=0.778, test=0.694) total time=  30.0s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=0.775, test=0.708) total time=  30.3s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=0.772, test=0.702) total time=  30.1s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=0.775, test=0.690) total time=  30.5s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=0.787, test=0.718) total time=  30.5s\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.8;, score=(train=0.763, test=0.690) total time=  19.5s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=deviance, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=deviance, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=deviance, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=deviance, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=deviance, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=deviance, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=deviance, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=deviance, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=deviance, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=deviance, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, loss=deviance, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, loss=deviance, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, loss=deviance, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, loss=deviance, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, loss=deviance, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.863, test=0.743) total time=   5.6s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.875, test=0.769) total time=   5.5s\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.869, test=0.749) total time=   5.6s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=1000, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=1000, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=1000, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=1000, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=1000, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.869, test=0.749) total time=   5.6s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.882, test=0.766) total time=   5.6s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.8;, score=(train=0.761, test=0.680) total time=  20.7s\n",
      "[CV 1/5] END learning_rate=0.01, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.8;, score=(train=0.677, test=0.631) total time=   3.6s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.8;, score=(train=0.772, test=0.709) total time=  21.6s\n",
      "[CV 1/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=0.847, test=0.729) total time=  16.9s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.8;, score=(train=0.675, test=0.645) total time=   3.6s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.8;, score=(train=0.675, test=0.654) total time=   3.6s\n",
      "[CV 5/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=0.854, test=0.763) total time=  17.0s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=0.846, test=0.740) total time=  17.3s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.744, test=0.681) total time=  16.1s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.8;, score=(train=0.675, test=0.622) total time=   2.7s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.740, test=0.690) total time=  16.3s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.741, test=0.677) total time=  15.9s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.8;, score=(train=0.678, test=0.635) total time=   2.4s\n",
      "[CV 2/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=0.855, test=0.748) total time=  13.1s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.005, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.005, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.005, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.005, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=0.851, test=0.744) total time=  12.9s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.750, test=0.692) total time=  11.9s\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.743, test=0.677) total time=  12.1s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.733, test=0.665) total time=  15.7s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.731, test=0.689) total time=  16.2s\n",
      "[CV 1/5] END learning_rate=0.005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.8;, score=(train=0.819, test=0.719) total time=  25.9s\n",
      "[CV 4/5] END learning_rate=0.005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.8;, score=(train=0.817, test=0.726) total time=  26.3s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.726, test=0.662) total time=  15.9s\n",
      "[CV 2/5] END learning_rate=0.005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.8;, score=(train=0.822, test=0.730) total time=  25.1s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.733, test=0.675) total time=  15.3s\n",
      "[CV 5/5] END learning_rate=0.005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.8;, score=(train=0.827, test=0.742) total time=  25.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.738, test=0.679) total time=  14.2s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=0.839, test=0.731) total time=  59.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=0.833, test=0.728) total time=  58.3s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=0.840, test=0.740) total time=  59.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=0.836, test=0.734) total time=  58.9s\n",
      "[CV 3/5] END learning_rate=0.005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.8;, score=(train=0.820, test=0.719) total time=  22.8s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=0.847, test=0.759) total time=  57.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "305 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "38 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of GradientBoostingClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "52 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of GradientBoostingClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "125 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "90 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.67163636        nan        nan 0.71927273        nan        nan\n",
      " 0.75272727 0.64736364        nan        nan 0.741             nan\n",
      " 0.73645455        nan 0.80845455        nan 0.74427273 0.73454545\n",
      " 0.70890909        nan        nan        nan        nan 0.76354545\n",
      "        nan 0.73027273        nan 0.72045455 0.70290909 0.72918182\n",
      " 0.63409091        nan        nan 0.74445455        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.63672727\n",
      " 0.69818182 0.63490909 0.69372727        nan        nan        nan\n",
      " 0.55490909 0.76881818        nan 0.74727273 0.73254545 0.77163636\n",
      "        nan 0.64063636        nan 0.699      0.68454545        nan\n",
      " 0.67872727        nan        nan        nan        nan        nan\n",
      "        nan 0.70245455        nan 0.69436364 0.755             nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.74481818        nan        nan 0.68354545\n",
      "        nan        nan        nan        nan 0.63745455 0.72727273\n",
      "        nan 0.67390909        nan        nan        nan        nan\n",
      "        nan        nan 0.73809091        nan]\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the train scores are non-finite: [0.72795455        nan        nan 0.80870455        nan        nan\n",
      " 0.86609091 0.69465909        nan        nan 0.84011364        nan\n",
      " 0.83734091        nan 0.95077273        nan 0.84904545 0.82897727\n",
      " 0.78663636        nan        nan        nan        nan 0.88079545\n",
      "        nan 0.82834091        nan 0.82545455 0.78043182 0.82840909\n",
      " 0.67070455        nan        nan 0.85031818        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.69206818\n",
      " 0.77477273 0.68952273 0.76636364        nan        nan        nan\n",
      " 0.57227273 0.89806818        nan 0.85022727 0.82738636 0.8895\n",
      "        nan 0.68345455        nan 0.78213636 0.75931818        nan\n",
      " 0.74611364        nan        nan        nan        nan        nan\n",
      "        nan 0.77734091        nan 0.76495455 0.87154545        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.85056818        nan        nan 0.74327273\n",
      "        nan        nan        nan        nan 0.67590909 0.82090909\n",
      "        nan 0.73225           nan        nan        nan        nan\n",
      "        nan        nan 0.839             nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier Accuracy: 0.658\n",
      "Best Parameters: {'subsample': 0.8, 'n_estimators': 750, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 6, 'loss': 'exponential', 'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=101)\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [1e-4, 5e-4, 1e-3, 5e-3, 1e-2],\n",
    "    'n_estimators': [100, 250, 500, 750, 1000],\n",
    "    'max_depth': [3, 4, 5, 6, 7],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'loss': ['deviance', 'exponential']\n",
    "}\n",
    "# Initialize the GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier(random_state=101)\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "best_gbc = RandomizedSearchCV(\n",
    "    estimator=gbc,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=100,  # Number of parameter settings sampled\n",
    "    cv=cv,\n",
    "    scoring='accuracy',\n",
    "    verbose=3,\n",
    "    random_state=101,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True  # To analyze training vs. validation scores\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "best_gbc.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "pred_gbc = best_gbc.best_estimator_.predict(X_test)\n",
    "print(\"Gradient Boosting Classifier Accuracy:\", accuracy_score(y_test, pred_gbc))\n",
    "print(\"Best Parameters:\", best_gbc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=0.841, test=0.753) total time=   4.5s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=0.840, test=0.743) total time=   4.6s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=0.846, test=0.756) total time=   4.6s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=0.841, test=0.731) total time=   4.6s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=0.837, test=0.724) total time=   4.7s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.770, test=0.709) total time=   7.1s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.766, test=0.696) total time=   7.1s\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.767, test=0.691) total time=   6.6s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.767, test=0.696) total time=   6.6s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.775, test=0.710) total time=   6.9s\n",
      "[CV 1/5] END learning_rate=0.001, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.7;, score=(train=0.734, test=0.675) total time=   5.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.7;, score=(train=0.729, test=0.679) total time=   4.8s\n",
      "[CV 3/5] END learning_rate=0.001, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.7;, score=(train=0.734, test=0.660) total time=   4.8s\n",
      "[CV 4/5] END learning_rate=0.001, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.7;, score=(train=0.734, test=0.661) total time=   4.8s\n",
      "[CV 5/5] END learning_rate=0.001, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.7;, score=(train=0.740, test=0.693) total time=   5.1s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.6;, score=(train=0.806, test=0.713) total time=  34.5s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.6;, score=(train=0.805, test=0.725) total time=  34.1s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.6;, score=(train=0.805, test=0.701) total time=  34.7s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.6;, score=(train=0.808, test=0.713) total time=  34.5s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.6;, score=(train=0.820, test=0.745) total time=  34.0s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=None, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.707, test=0.645) total time=  55.9s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=None, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.699, test=0.665) total time=  55.9s\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=None, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.691, test=0.636) total time=  54.9s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=None, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.706, test=0.654) total time=  56.1s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=None, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=0.881, test=0.764) total time= 3.1min\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=None, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=0.884, test=0.766) total time= 3.1min\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=None, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=0.890, test=0.776) total time= 3.1min\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=None, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=0.885, test=0.766) total time= 3.1min\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=None, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=0.889, test=0.775) total time= 3.1min\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=None, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.708, test=0.669) total time=  57.2s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=0.729, test=0.668) total time=   9.4s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=0.725, test=0.673) total time=  10.0s\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=0.725, test=0.674) total time=  10.7s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=0.727, test=0.671) total time=  10.7s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=0.734, test=0.688) total time=  10.9s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=log_loss, max_depth=6, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=0.817, test=0.711) total time= 1.8min\n",
      "[CV 2/5] END learning_rate=0.0001, loss=log_loss, max_depth=6, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=0.816, test=0.731) total time= 1.8min\n",
      "[CV 3/5] END learning_rate=0.0001, loss=log_loss, max_depth=6, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=0.818, test=0.707) total time= 1.8min\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.835, test=0.728) total time= 1.2min\n",
      "[CV 4/5] END learning_rate=0.0001, loss=log_loss, max_depth=6, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=0.814, test=0.720) total time= 2.2min\n",
      "[CV 5/5] END learning_rate=0.0001, loss=log_loss, max_depth=6, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=0.831, test=0.750) total time= 2.1min\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.832, test=0.751) total time=  55.3s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.838, test=0.728) total time=  53.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.840, test=0.736) total time=  52.7s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.855, test=0.762) total time=  52.3s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=None, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=0.755, test=0.668) total time= 7.9min\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=None, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=0.756, test=0.692) total time= 8.7min\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=None, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=0.771, test=0.684) total time= 9.1min\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=None, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=0.741, test=0.659) total time= 9.2min\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=None, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=0.774, test=0.697) total time= 9.2min\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.7;, score=(train=0.940, test=0.799) total time= 1.0min\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.7;, score=(train=0.946, test=0.809) total time= 1.0min\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.7;, score=(train=0.942, test=0.810) total time= 1.0min\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.7;, score=(train=0.943, test=0.793) total time=  55.4s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.7;, score=(train=0.949, test=0.797) total time=  55.2s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=7, max_features=None, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=0.861, test=0.749) total time=10.9min\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=7, max_features=None, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=0.853, test=0.746) total time=10.9min\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=7, max_features=None, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=0.859, test=0.766) total time=11.0min\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=7, max_features=None, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=0.862, test=0.746) total time=10.6min\n",
      "[CV 1/5] END learning_rate=0.0001, loss=log_loss, max_depth=3, max_features=None, min_samples_leaf=1, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=0.607, test=0.583) total time= 7.7min\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=7, max_features=None, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=0.872, test=0.767) total time=10.5min\n",
      "[CV 3/5] END learning_rate=0.0001, loss=log_loss, max_depth=3, max_features=None, min_samples_leaf=1, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=0.603, test=0.558) total time= 7.7min\n",
      "[CV 2/5] END learning_rate=0.0001, loss=log_loss, max_depth=3, max_features=None, min_samples_leaf=1, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=0.594, test=0.576) total time= 7.9min\n",
      "[CV 1/5] END learning_rate=0.0001, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1000, subsample=1.0;, score=(train=0.773, test=0.681) total time= 1.4min\n",
      "[CV 2/5] END learning_rate=0.0001, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1000, subsample=1.0;, score=(train=0.770, test=0.700) total time= 1.4min\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=7, max_features=None, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=0.818, test=0.706) total time= 6.7min\n",
      "[CV 3/5] END learning_rate=0.0001, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1000, subsample=1.0;, score=(train=0.772, test=0.682) total time= 1.4min\n",
      "[CV 4/5] END learning_rate=0.0001, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1000, subsample=1.0;, score=(train=0.770, test=0.691) total time= 1.3min\n",
      "[CV 5/5] END learning_rate=0.0001, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1000, subsample=1.0;, score=(train=0.781, test=0.714) total time= 1.4min\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=7, max_features=None, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=0.824, test=0.737) total time= 6.8min\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=7, max_features=None, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=0.801, test=0.700) total time= 6.8min\n",
      "[CV 4/5] END learning_rate=0.0001, loss=log_loss, max_depth=3, max_features=None, min_samples_leaf=1, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=0.601, test=0.592) total time= 8.9min\n",
      "[CV 5/5] END learning_rate=0.0001, loss=log_loss, max_depth=3, max_features=None, min_samples_leaf=1, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=0.593, test=0.578) total time= 8.9min\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.6;, score=(train=0.945, test=0.804) total time=  58.7s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.6;, score=(train=0.948, test=0.812) total time=  58.8s\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.6;, score=(train=0.946, test=0.807) total time=  58.5s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=7, max_features=None, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=0.833, test=0.732) total time= 6.8min\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=7, max_features=None, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=0.833, test=0.741) total time= 6.7min\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.6;, score=(train=0.947, test=0.800) total time=  58.5s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.6;, score=(train=0.951, test=0.801) total time=  58.6s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=750, subsample=0.7;, score=(train=0.894, test=0.770) total time=  57.4s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=750, subsample=0.7;, score=(train=0.902, test=0.784) total time=  56.8s\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=750, subsample=0.7;, score=(train=0.896, test=0.775) total time=  57.3s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=750, subsample=0.7;, score=(train=0.897, test=0.767) total time=  57.7s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=750, subsample=0.7;, score=(train=0.903, test=0.779) total time=  57.3s\n",
      "[CV 1/5] END learning_rate=0.001, loss=log_loss, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.8;, score=(train=0.881, test=0.764) total time= 2.0min\n",
      "[CV 2/5] END learning_rate=0.001, loss=log_loss, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.8;, score=(train=0.885, test=0.776) total time= 2.0min\n",
      "[CV 3/5] END learning_rate=0.001, loss=log_loss, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.8;, score=(train=0.880, test=0.758) total time= 2.0min\n",
      "[CV 4/5] END learning_rate=0.001, loss=log_loss, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.8;, score=(train=0.883, test=0.765) total time= 2.0min\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=0.829, test=0.720) total time=  17.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=log_loss, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.8;, score=(train=0.896, test=0.789) total time= 2.0min\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=0.828, test=0.730) total time=  16.8s\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=0.827, test=0.721) total time=  16.6s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=0.824, test=0.722) total time=  16.6s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=0.832, test=0.746) total time=  16.7s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=None, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=0.764, test=0.685) total time= 2.4min\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=None, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=0.757, test=0.701) total time= 2.4min\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=None, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=0.756, test=0.677) total time= 2.3min\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=0.789, test=0.696) total time=  29.3s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=0.773, test=0.697) total time=  28.8s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=0.789, test=0.690) total time=  28.8s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=0.786, test=0.697) total time=  28.7s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=0.793, test=0.714) total time=  28.7s\n",
      "[CV 1/5] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=0.865, test=0.746) total time=  29.5s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=None, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=0.764, test=0.688) total time= 2.3min\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=None, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=0.772, test=0.703) total time= 2.3min\n",
      "[CV 2/5] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=0.871, test=0.763) total time=  29.1s\n",
      "[CV 3/5] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=0.861, test=0.749) total time=  29.1s\n",
      "[CV 4/5] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=0.864, test=0.749) total time=  29.5s\n",
      "[CV 5/5] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=0.873, test=0.756) total time=  29.0s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=750, subsample=0.7;, score=(train=0.979, test=0.835) total time= 1.0min\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=750, subsample=0.7;, score=(train=0.981, test=0.838) total time= 1.0min\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=750, subsample=0.7;, score=(train=0.980, test=0.841) total time= 1.0min\n",
      "[CV 1/5] END learning_rate=0.001, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=0.778, test=0.695) total time=  32.3s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=750, subsample=0.7;, score=(train=0.980, test=0.836) total time= 1.0min\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=750, subsample=0.7;, score=(train=0.982, test=0.832) total time= 1.0min\n",
      "[CV 2/5] END learning_rate=0.001, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=0.778, test=0.714) total time=  32.7s\n",
      "[CV 3/5] END learning_rate=0.001, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=0.777, test=0.693) total time=  32.8s\n",
      "[CV 4/5] END learning_rate=0.001, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=0.773, test=0.700) total time=  32.4s\n",
      "[CV 5/5] END learning_rate=0.001, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=0.789, test=0.719) total time=  32.1s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.7;, score=(train=0.793, test=0.709) total time= 1.3min\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.7;, score=(train=0.787, test=0.717) total time= 1.3min\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.7;, score=(train=0.791, test=0.701) total time= 1.3min\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250, subsample=0.9;, score=(train=0.827, test=0.718) total time=  33.3s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.7;, score=(train=0.789, test=0.711) total time= 1.3min\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.7;, score=(train=0.800, test=0.732) total time= 1.3min\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250, subsample=0.9;, score=(train=0.819, test=0.730) total time=  33.6s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250, subsample=0.9;, score=(train=0.828, test=0.722) total time=  33.3s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250, subsample=0.9;, score=(train=0.828, test=0.730) total time=  33.8s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250, subsample=0.9;, score=(train=0.840, test=0.745) total time=  33.6s\n",
      "[CV 1/5] END learning_rate=0.001, loss=log_loss, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.8;, score=(train=0.743, test=0.675) total time=  52.7s\n",
      "[CV 2/5] END learning_rate=0.001, loss=log_loss, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.8;, score=(train=0.736, test=0.685) total time=  53.5s\n",
      "[CV 3/5] END learning_rate=0.001, loss=log_loss, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.8;, score=(train=0.740, test=0.669) total time=  52.6s\n",
      "[CV 4/5] END learning_rate=0.001, loss=log_loss, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.8;, score=(train=0.741, test=0.680) total time=  53.9s\n",
      "[CV 5/5] END learning_rate=0.001, loss=log_loss, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.8;, score=(train=0.746, test=0.696) total time=  54.2s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=0.670, test=0.625) total time= 1.0min\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=None, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.6;, score=(train=0.818, test=0.716) total time=10.0min\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=0.666, test=0.645) total time= 1.0min\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=None, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.6;, score=(train=0.807, test=0.704) total time=10.0min\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=None, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.6;, score=(train=0.813, test=0.732) total time=10.1min\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=0.669, test=0.615) total time= 1.0min\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=None, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.6;, score=(train=0.820, test=0.722) total time=10.0min\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=None, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.6;, score=(train=0.828, test=0.743) total time=10.0min\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=250, subsample=0.6;, score=(train=0.868, test=0.758) total time=  15.4s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=250, subsample=0.6;, score=(train=0.869, test=0.765) total time=  15.5s\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=250, subsample=0.6;, score=(train=0.869, test=0.753) total time=  15.1s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=0.672, test=0.635) total time= 1.0min\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=250, subsample=0.6;, score=(train=0.869, test=0.756) total time=  15.3s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=250, subsample=0.6;, score=(train=0.875, test=0.772) total time=  15.1s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=log_loss, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=250, subsample=0.7;, score=(train=0.832, test=0.720) total time=  20.4s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=log_loss, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=250, subsample=0.7;, score=(train=0.816, test=0.725) total time=  21.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=log_loss, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=250, subsample=0.7;, score=(train=0.838, test=0.732) total time=  20.5s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=log_loss, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=250, subsample=0.7;, score=(train=0.830, test=0.726) total time=  20.7s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=log_loss, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=250, subsample=0.7;, score=(train=0.836, test=0.753) total time=  20.6s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=0.677, test=0.650) total time= 1.0min\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.6;, score=(train=0.762, test=0.693) total time=  30.6s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.6;, score=(train=0.764, test=0.702) total time=  30.3s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=0.852, test=0.735) total time=  51.5s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=0.846, test=0.752) total time=  51.8s\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.6;, score=(train=0.760, test=0.691) total time=  30.5s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=0.849, test=0.733) total time=  51.2s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=0.847, test=0.741) total time=  52.1s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=0.858, test=0.761) total time=  51.4s\n",
      "[CV 1/5] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.8;, score=(train=0.694, test=0.643) total time=   5.4s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=0.667, test=0.624) total time=  23.7s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=0.661, test=0.639) total time=  23.6s\n",
      "[CV 2/5] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.8;, score=(train=0.693, test=0.661) total time=   5.4s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.6;, score=(train=0.763, test=0.694) total time=  31.0s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.6;, score=(train=0.769, test=0.710) total time=  30.6s\n",
      "[CV 3/5] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.8;, score=(train=0.689, test=0.636) total time=   5.4s\n",
      "[CV 4/5] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.8;, score=(train=0.697, test=0.651) total time=   5.3s\n",
      "[CV 5/5] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.8;, score=(train=0.704, test=0.672) total time=   5.4s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=0.663, test=0.617) total time=  23.4s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=0.668, test=0.627) total time=  23.6s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=0.671, test=0.649) total time=  23.7s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=0.610, test=0.581) total time=  36.1s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=0.586, test=0.574) total time=  36.8s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=0.602, test=0.558) total time=  36.2s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=0.603, test=0.585) total time=  36.9s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=0.608, test=0.595) total time=  37.0s\n",
      "[CV 1/5] END learning_rate=0.01, loss=log_loss, max_depth=6, max_features=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=1.0;, score=(train=0.786, test=0.688) total time= 1.7min\n",
      "[CV 2/5] END learning_rate=0.01, loss=log_loss, max_depth=6, max_features=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=1.0;, score=(train=0.800, test=0.718) total time= 1.7min\n",
      "[CV 3/5] END learning_rate=0.01, loss=log_loss, max_depth=6, max_features=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=1.0;, score=(train=0.783, test=0.676) total time= 1.7min\n",
      "[CV 4/5] END learning_rate=0.01, loss=log_loss, max_depth=6, max_features=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=1.0;, score=(train=0.805, test=0.694) total time= 1.7min\n",
      "[CV 5/5] END learning_rate=0.01, loss=log_loss, max_depth=6, max_features=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=1.0;, score=(train=0.806, test=0.717) total time= 1.7min\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.6;, score=(train=0.609, test=0.580) total time=  31.2s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.6;, score=(train=0.590, test=0.571) total time=  31.4s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.6;, score=(train=0.603, test=0.559) total time=  31.3s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.6;, score=(train=0.604, test=0.590) total time=  30.5s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.6;, score=(train=0.608, test=0.599) total time=  30.5s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=None, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.820, test=0.724) total time= 3.2min\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=None, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.822, test=0.742) total time= 3.1min\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=None, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.817, test=0.730) total time= 3.1min\n",
      "[CV 1/5] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=0.756, test=0.675) total time=  43.6s\n",
      "[CV 2/5] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=0.755, test=0.695) total time=  38.6s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=None, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.820, test=0.732) total time= 2.3min\n",
      "[CV 3/5] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=0.747, test=0.665) total time=  33.9s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=None, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.829, test=0.750) total time= 2.2min\n",
      "[CV 4/5] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=0.764, test=0.694) total time=  32.9s\n",
      "[CV 5/5] END learning_rate=0.01, loss=log_loss, max_depth=5, max_features=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=0.772, test=0.696) total time=  33.6s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.9;, score=(train=0.951, test=0.802) total time=  48.1s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.9;, score=(train=0.954, test=0.811) total time=  48.6s\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.9;, score=(train=0.953, test=0.814) total time=  48.4s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.9;, score=(train=0.950, test=0.805) total time=  47.9s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.9;, score=(train=0.955, test=0.810) total time=  47.6s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=6, max_features=None, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=0.731, test=0.642) total time= 9.9min\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=6, max_features=None, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=0.696, test=0.630) total time= 9.7min\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=6, max_features=None, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=0.729, test=0.669) total time= 9.7min\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=6, max_features=None, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=0.742, test=0.665) total time= 9.4min\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.696, test=0.633) total time=   8.3s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=6, max_features=None, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=0.739, test=0.680) total time= 9.5min\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.684, test=0.634) total time=   8.5s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.696, test=0.630) total time=   8.3s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.692, test=0.632) total time=   8.6s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.693, test=0.654) total time=   8.5s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.8;, score=(train=0.784, test=0.698) total time=  35.6s\n",
      "[CV 1/5] END learning_rate=0.01, loss=log_loss, max_depth=6, max_features=None, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=0.948, test=0.805) total time= 2.7min\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.8;, score=(train=0.778, test=0.711) total time=  36.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.8;, score=(train=0.782, test=0.698) total time=  36.1s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.691, test=0.627) total time=  11.1s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.683, test=0.629) total time=  10.9s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.694, test=0.632) total time=  10.7s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.688, test=0.639) total time=  11.0s\n",
      "[CV 2/5] END learning_rate=0.01, loss=log_loss, max_depth=6, max_features=None, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=0.953, test=0.822) total time= 2.7min\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.692, test=0.647) total time=  11.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.8;, score=(train=0.783, test=0.703) total time=  36.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.8;, score=(train=0.795, test=0.726) total time=  36.4s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.767, test=0.694) total time=  14.2s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.759, test=0.698) total time=  14.1s\n",
      "[CV 3/5] END learning_rate=0.01, loss=log_loss, max_depth=6, max_features=None, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=0.950, test=0.826) total time= 2.7min\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.764, test=0.678) total time=  14.1s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.765, test=0.693) total time=  14.1s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.777, test=0.706) total time=  14.1s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.9;, score=(train=0.690, test=0.634) total time=  16.7s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.9;, score=(train=0.691, test=0.657) total time=  16.8s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.9;, score=(train=0.684, test=0.627) total time=  17.6s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.9;, score=(train=0.689, test=0.640) total time=  18.7s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.9;, score=(train=0.693, test=0.661) total time=  18.9s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.861, test=0.750) total time=  20.6s\n",
      "[CV 1/5] END learning_rate=0.001, loss=log_loss, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=0.847, test=0.732) total time=   9.7s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.866, test=0.760) total time=  21.7s\n",
      "[CV 2/5] END learning_rate=0.001, loss=log_loss, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=0.844, test=0.745) total time=   9.4s\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.860, test=0.749) total time=  22.0s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.856, test=0.745) total time=  21.6s\n",
      "[CV 3/5] END learning_rate=0.001, loss=log_loss, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=0.835, test=0.723) total time=   9.2s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.868, test=0.761) total time=  20.9s\n",
      "[CV 4/5] END learning_rate=0.001, loss=log_loss, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=0.845, test=0.737) total time=   9.4s\n",
      "[CV 5/5] END learning_rate=0.001, loss=log_loss, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=0.861, test=0.758) total time=   9.4s\n",
      "[CV 4/5] END learning_rate=0.01, loss=log_loss, max_depth=6, max_features=None, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=0.949, test=0.810) total time= 2.8min\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=0.809, test=0.708) total time=  19.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=0.804, test=0.728) total time=  19.1s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=0.808, test=0.706) total time=  19.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=0.810, test=0.717) total time=  18.8s\n",
      "[CV 1/5] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=0.706, test=0.650) total time=   2.4s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=0.820, test=0.742) total time=  19.1s\n",
      "[CV 2/5] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=0.699, test=0.669) total time=   2.3s\n",
      "[CV 3/5] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=0.699, test=0.643) total time=   2.3s\n",
      "[CV 4/5] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=0.689, test=0.650) total time=   2.3s\n",
      "[CV 5/5] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=0.704, test=0.652) total time=   2.4s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.575, test=0.560) total time=   3.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.574, test=0.555) total time=   2.9s\n",
      "[CV 5/5] END learning_rate=0.01, loss=log_loss, max_depth=6, max_features=None, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=0.952, test=0.814) total time= 2.9min\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.573, test=0.545) total time=   2.6s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.574, test=0.562) total time=   2.6s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.566, test=0.552) total time=   2.6s\n",
      "[CV 1/5] END learning_rate=0.001, loss=log_loss, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10, n_estimators=250, subsample=0.8;, score=(train=0.699, test=0.628) total time= 1.7min\n",
      "[CV 2/5] END learning_rate=0.001, loss=log_loss, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10, n_estimators=250, subsample=0.8;, score=(train=0.694, test=0.652) total time= 1.7min\n",
      "[CV 3/5] END learning_rate=0.001, loss=log_loss, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10, n_estimators=250, subsample=0.8;, score=(train=0.672, test=0.609) total time= 1.7min\n",
      "[CV 4/5] END learning_rate=0.001, loss=log_loss, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10, n_estimators=250, subsample=0.8;, score=(train=0.711, test=0.653) total time= 1.7min\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=None, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.6;, score=(train=0.885, test=0.767) total time= 1.4min\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=None, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.6;, score=(train=0.892, test=0.776) total time= 1.4min\n",
      "[CV 5/5] END learning_rate=0.001, loss=log_loss, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=10, n_estimators=250, subsample=0.8;, score=(train=0.708, test=0.667) total time= 1.7min\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=None, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.6;, score=(train=0.881, test=0.767) total time= 1.5min\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=0.846, test=0.736) total time=  22.4s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=0.849, test=0.752) total time=  22.6s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=0.853, test=0.737) total time=  22.4s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=0.859, test=0.770) total time=  22.2s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=0.845, test=0.740) total time=  22.5s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.833, test=0.728) total time=  21.8s\n",
      "[CV 1/5] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=0.694, test=0.643) total time=   3.0s\n",
      "[CV 2/5] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=0.694, test=0.657) total time=   3.2s\n",
      "[CV 3/5] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=0.690, test=0.637) total time=   3.0s\n",
      "[CV 4/5] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=0.696, test=0.648) total time=   3.1s\n",
      "[CV 5/5] END learning_rate=0.01, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=0.704, test=0.671) total time=   3.1s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.836, test=0.740) total time=  22.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.833, test=0.725) total time=  22.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.833, test=0.733) total time=  22.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.842, test=0.753) total time=  22.1s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.6;, score=(train=0.874, test=0.757) total time=   8.4s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.6;, score=(train=0.874, test=0.758) total time=   8.4s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=None, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.6;, score=(train=0.883, test=0.765) total time= 1.4min\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.6;, score=(train=0.871, test=0.751) total time=   8.6s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=None, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.6;, score=(train=0.892, test=0.775) total time= 1.4min\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.6;, score=(train=0.868, test=0.750) total time=   8.6s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.6;, score=(train=0.882, test=0.755) total time=   8.5s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.9;, score=(train=0.684, test=0.631) total time=  26.2s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.9;, score=(train=0.678, test=0.647) total time=  26.3s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.9;, score=(train=0.683, test=0.627) total time=  26.4s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.9;, score=(train=0.682, test=0.633) total time=  26.2s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=None, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=1.0;, score=(train=0.753, test=0.669) total time= 1.7min\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.9;, score=(train=0.691, test=0.666) total time=  25.9s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=None, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=1.0;, score=(train=0.749, test=0.682) total time= 1.7min\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=None, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=1.0;, score=(train=0.751, test=0.671) total time= 1.7min\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=None, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=1.0;, score=(train=0.765, test=0.699) total time= 1.6min\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=None, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=1.0;, score=(train=0.756, test=0.680) total time= 1.7min\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=750, subsample=0.9;, score=(train=0.702, test=0.645) total time=  19.4s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=750, subsample=0.9;, score=(train=0.702, test=0.653) total time=  19.2s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=750, subsample=0.9;, score=(train=0.699, test=0.636) total time=  19.3s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=750, subsample=0.9;, score=(train=0.702, test=0.649) total time=  19.4s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=750, subsample=0.9;, score=(train=0.709, test=0.670) total time=  19.2s\n",
      "[CV 1/5] END learning_rate=0.001, loss=log_loss, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.872, test=0.759) total time=  19.5s\n",
      "[CV 2/5] END learning_rate=0.001, loss=log_loss, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.875, test=0.764) total time=  22.3s\n",
      "[CV 3/5] END learning_rate=0.001, loss=log_loss, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.873, test=0.762) total time=  23.7s\n",
      "[CV 4/5] END learning_rate=0.001, loss=log_loss, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.876, test=0.759) total time=  25.8s\n",
      "[CV 5/5] END learning_rate=0.001, loss=log_loss, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.884, test=0.772) total time=  43.6s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=1.0;, score=(train=0.793, test=0.700) total time= 1.2min\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=1.0;, score=(train=0.789, test=0.706) total time= 1.2min\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=1.0;, score=(train=0.786, test=0.692) total time= 1.2min\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.765, test=0.687) total time=   4.1s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.763, test=0.695) total time=   4.2s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.769, test=0.685) total time=   4.1s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.769, test=0.687) total time=   4.1s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.777, test=0.710) total time=   4.1s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=1.0;, score=(train=0.787, test=0.702) total time=  59.2s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=1.0;, score=(train=0.800, test=0.730) total time=  58.2s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.893, test=0.767) total time= 4.5min\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.898, test=0.781) total time= 4.7min\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.894, test=0.771) total time= 4.7min\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.893, test=0.768) total time= 4.7min\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.898, test=0.785) total time= 4.7min\n",
      "[CV 1/5] END learning_rate=0.0001, loss=log_loss, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=0.846, test=0.738) total time= 1.7min\n",
      "[CV 2/5] END learning_rate=0.0001, loss=log_loss, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=0.849, test=0.750) total time= 1.7min\n",
      "[CV 3/5] END learning_rate=0.0001, loss=log_loss, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=0.848, test=0.735) total time= 1.7min\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=None, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.776, test=0.681) total time= 3.9min\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=None, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.777, test=0.706) total time= 3.9min\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=None, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.757, test=0.676) total time= 3.9min\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=None, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.790, test=0.705) total time= 3.9min\n",
      "[CV 4/5] END learning_rate=0.0001, loss=log_loss, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=0.849, test=0.736) total time= 1.7min\n",
      "[CV 5/5] END learning_rate=0.0001, loss=log_loss, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=0.861, test=0.758) total time= 1.7min\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=None, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.794, test=0.722) total time= 3.8min\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=0.887, test=0.766) total time=  59.1s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=0.893, test=0.773) total time=  59.2s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=0.886, test=0.758) total time=  58.3s\n",
      "[CV 1/5] END learning_rate=0.001, loss=log_loss, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=0.823, test=0.717) total time=  29.5s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=0.892, test=0.767) total time=  58.4s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=0.895, test=0.785) total time=  58.1s\n",
      "[CV 2/5] END learning_rate=0.001, loss=log_loss, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=0.824, test=0.731) total time=  28.5s\n",
      "[CV 3/5] END learning_rate=0.001, loss=log_loss, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=0.820, test=0.718) total time=  28.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=log_loss, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=0.817, test=0.718) total time=  28.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=log_loss, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=0.834, test=0.743) total time=  28.1s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.9;, score=(train=0.832, test=0.725) total time=  22.1s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.9;, score=(train=0.830, test=0.738) total time=  22.1s\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.9;, score=(train=0.827, test=0.729) total time=  22.3s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.9;, score=(train=0.831, test=0.724) total time=  22.3s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.9;, score=(train=0.833, test=0.736) total time=  22.3s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=log_loss, max_depth=7, max_features=None, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=1.0;, score=(train=0.694, test=0.615) total time= 5.5min\n",
      "[CV 4/5] END learning_rate=0.0001, loss=log_loss, max_depth=7, max_features=None, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=1.0;, score=(train=0.711, test=0.638) total time= 5.1min\n",
      "[CV 2/5] END learning_rate=0.0001, loss=log_loss, max_depth=7, max_features=None, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=1.0;, score=(train=0.719, test=0.658) total time= 5.3min\n",
      "[CV 3/5] END learning_rate=0.0001, loss=log_loss, max_depth=7, max_features=None, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=1.0;, score=(train=0.676, test=0.620) total time= 5.3min\n",
      "[CV 5/5] END learning_rate=0.0001, loss=log_loss, max_depth=7, max_features=None, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=1.0;, score=(train=0.699, test=0.638) total time= 4.9min\n",
      "[CV 1/5] END learning_rate=0.01, loss=log_loss, max_depth=6, max_features=None, min_samples_leaf=4, min_samples_split=10, n_estimators=1000, subsample=0.7;, score=(train=0.991, test=0.847) total time= 5.9min\n",
      "[CV 2/5] END learning_rate=0.01, loss=log_loss, max_depth=6, max_features=None, min_samples_leaf=4, min_samples_split=10, n_estimators=1000, subsample=0.7;, score=(train=0.991, test=0.846) total time= 5.9min\n",
      "[CV 3/5] END learning_rate=0.01, loss=log_loss, max_depth=6, max_features=None, min_samples_leaf=4, min_samples_split=10, n_estimators=1000, subsample=0.7;, score=(train=0.992, test=0.861) total time= 5.9min\n",
      "[CV 1/5] END learning_rate=0.001, loss=log_loss, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.7;, score=(train=0.866, test=0.742) total time=  26.4s\n",
      "[CV 4/5] END learning_rate=0.01, loss=log_loss, max_depth=6, max_features=None, min_samples_leaf=4, min_samples_split=10, n_estimators=1000, subsample=0.7;, score=(train=0.990, test=0.844) total time= 5.8min\n",
      "[CV 2/5] END learning_rate=0.001, loss=log_loss, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.7;, score=(train=0.869, test=0.761) total time=  26.1s\n",
      "[CV 3/5] END learning_rate=0.001, loss=log_loss, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.7;, score=(train=0.866, test=0.744) total time=  26.3s\n",
      "[CV 5/5] END learning_rate=0.01, loss=log_loss, max_depth=6, max_features=None, min_samples_leaf=4, min_samples_split=10, n_estimators=1000, subsample=0.7;, score=(train=0.991, test=0.844) total time= 5.8min\n",
      "[CV 4/5] END learning_rate=0.001, loss=log_loss, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.7;, score=(train=0.868, test=0.755) total time=  26.1s\n",
      "[CV 5/5] END learning_rate=0.001, loss=log_loss, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.7;, score=(train=0.876, test=0.770) total time=  26.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=log_loss, max_depth=7, max_features=None, min_samples_leaf=4, min_samples_split=2, n_estimators=750, subsample=0.9;, score=(train=0.828, test=0.715) total time= 6.6min\n",
      "[CV 2/5] END learning_rate=0.001, loss=log_loss, max_depth=7, max_features=None, min_samples_leaf=4, min_samples_split=2, n_estimators=750, subsample=0.9;, score=(train=0.839, test=0.749) total time= 6.7min\n",
      "[CV 1/5] END learning_rate=0.01, loss=log_loss, max_depth=7, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.9;, score=(train=0.994, test=0.852) total time= 1.1min\n",
      "[CV 2/5] END learning_rate=0.01, loss=log_loss, max_depth=7, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.9;, score=(train=0.995, test=0.848) total time= 1.1min\n",
      "[CV 3/5] END learning_rate=0.001, loss=log_loss, max_depth=7, max_features=None, min_samples_leaf=4, min_samples_split=2, n_estimators=750, subsample=0.9;, score=(train=0.820, test=0.713) total time= 6.7min\n",
      "[CV 3/5] END learning_rate=0.01, loss=log_loss, max_depth=7, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.9;, score=(train=0.996, test=0.862) total time= 1.1min\n",
      "[CV 4/5] END learning_rate=0.01, loss=log_loss, max_depth=7, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.9;, score=(train=0.995, test=0.847) total time= 1.1min\n",
      "[CV 5/5] END learning_rate=0.01, loss=log_loss, max_depth=7, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.9;, score=(train=0.995, test=0.848) total time= 1.1min\n",
      "[CV 1/5] END learning_rate=0.0001, loss=log_loss, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.8;, score=(train=0.690, test=0.632) total time=   8.9s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=log_loss, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.8;, score=(train=0.683, test=0.635) total time=   8.7s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=log_loss, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.8;, score=(train=0.700, test=0.634) total time=   8.8s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=log_loss, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.8;, score=(train=0.691, test=0.635) total time=   9.1s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=log_loss, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.8;, score=(train=0.692, test=0.657) total time=   8.9s\n",
      "[CV 1/5] END learning_rate=0.01, loss=log_loss, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.9;, score=(train=0.879, test=0.760) total time=   5.2s\n",
      "[CV 2/5] END learning_rate=0.01, loss=log_loss, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.9;, score=(train=0.876, test=0.750) total time=   5.2s\n",
      "[CV 3/5] END learning_rate=0.01, loss=log_loss, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.9;, score=(train=0.880, test=0.756) total time=   5.3s\n",
      "[CV 4/5] END learning_rate=0.01, loss=log_loss, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.9;, score=(train=0.888, test=0.757) total time=   5.1s\n",
      "[CV 5/5] END learning_rate=0.01, loss=log_loss, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.9;, score=(train=0.890, test=0.765) total time=   5.2s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.8;, score=(train=0.676, test=0.629) total time=  26.4s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.8;, score=(train=0.667, test=0.646) total time=  27.2s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=None, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=0.774, test=0.675) total time= 3.4min\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.8;, score=(train=0.674, test=0.618) total time=  27.5s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=None, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=0.771, test=0.694) total time= 3.4min\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=None, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=0.745, test=0.664) total time= 3.4min\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=None, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=0.783, test=0.692) total time= 3.4min\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.8;, score=(train=0.680, test=0.640) total time=  27.2s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.8;, score=(train=0.681, test=0.661) total time=  26.9s\n",
      "[CV 4/5] END learning_rate=0.001, loss=log_loss, max_depth=7, max_features=None, min_samples_leaf=4, min_samples_split=2, n_estimators=750, subsample=0.9;, score=(train=0.841, test=0.730) total time= 6.6min\n",
      "[CV 1/5] END learning_rate=0.0001, loss=log_loss, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.8;, score=(train=0.806, test=0.706) total time=  38.1s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=log_loss, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.8;, score=(train=0.801, test=0.722) total time=  38.6s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=None, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=0.783, test=0.706) total time= 3.4min\n",
      "[CV 5/5] END learning_rate=0.001, loss=log_loss, max_depth=7, max_features=None, min_samples_leaf=4, min_samples_split=2, n_estimators=750, subsample=0.9;, score=(train=0.841, test=0.741) total time= 6.6min\n",
      "[CV 3/5] END learning_rate=0.0001, loss=log_loss, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.8;, score=(train=0.808, test=0.707) total time=  38.8s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=0.600, test=0.573) total time=   2.7s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=0.601, test=0.571) total time=   2.7s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=log_loss, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.8;, score=(train=0.799, test=0.711) total time=  38.5s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=0.625, test=0.584) total time=   2.8s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=0.610, test=0.578) total time=   2.8s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=log_loss, max_depth=4, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=0.603, test=0.571) total time=   2.8s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=log_loss, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.8;, score=(train=0.815, test=0.736) total time=  38.2s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=0.788, test=0.702) total time=  25.4s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=0.781, test=0.710) total time=  25.4s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=0.784, test=0.695) total time=  25.4s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=0.649, test=0.614) total time=   5.3s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=0.640, test=0.607) total time=   5.3s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=0.650, test=0.601) total time=   5.3s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=0.650, test=0.614) total time=   5.6s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=0.781, test=0.708) total time=  25.3s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=0.797, test=0.729) total time=  25.3s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=log_loss, max_depth=3, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=0.639, test=0.614) total time=   5.2s\n",
      "[CV 1/5] END learning_rate=0.001, loss=log_loss, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=1.0;, score=(train=0.823, test=0.714) total time=  31.7s\n",
      "[CV 2/5] END learning_rate=0.001, loss=log_loss, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=1.0;, score=(train=0.819, test=0.732) total time=  32.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=log_loss, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=1.0;, score=(train=0.818, test=0.715) total time=  32.1s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.7;, score=(train=0.824, test=0.715) total time=  13.1s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.7;, score=(train=0.818, test=0.730) total time=  14.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=log_loss, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=1.0;, score=(train=0.821, test=0.725) total time=  32.4s\n",
      "[CV 5/5] END learning_rate=0.001, loss=log_loss, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=1.0;, score=(train=0.832, test=0.751) total time=  32.2s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.7;, score=(train=0.831, test=0.722) total time=  13.5s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.7;, score=(train=0.823, test=0.723) total time=  13.5s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.7;, score=(train=0.836, test=0.751) total time=  13.2s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=None, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.658, test=0.603) total time= 1.0min\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=None, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.640, test=0.614) total time= 1.0min\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=None, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.623, test=0.570) total time= 1.0min\n",
      "[CV 1/5] END learning_rate=0.01, loss=log_loss, max_depth=7, max_features=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=1.0;, score=(train=0.843, test=0.720) total time=  59.5s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=None, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.659, test=0.619) total time= 1.0min\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=None, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.638, test=0.620) total time= 1.0min\n",
      "[CV 2/5] END learning_rate=0.01, loss=log_loss, max_depth=7, max_features=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=1.0;, score=(train=0.853, test=0.752) total time=  59.2s\n",
      "[CV 4/5] END learning_rate=0.01, loss=log_loss, max_depth=7, max_features=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=1.0;, score=(train=0.852, test=0.730) total time=  58.6s\n",
      "[CV 3/5] END learning_rate=0.01, loss=log_loss, max_depth=7, max_features=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=1.0;, score=(train=0.835, test=0.714) total time=  59.1s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=None, min_samples_leaf=1, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=0.629, test=0.589) total time= 5.9min\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=None, min_samples_leaf=1, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=0.641, test=0.609) total time= 5.9min\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=None, min_samples_leaf=1, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=0.619, test=0.588) total time= 6.0min\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=None, min_samples_leaf=1, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=0.610, test=0.564) total time= 6.0min\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=None, min_samples_leaf=1, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=0.617, test=0.599) total time= 6.0min\n",
      "[CV 5/5] END learning_rate=0.01, loss=log_loss, max_depth=7, max_features=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=1.0;, score=(train=0.854, test=0.740) total time= 1.0min\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=0.846, test=0.740) total time= 1.1min\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=0.849, test=0.751) total time= 1.1min\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=0.847, test=0.735) total time= 1.1min\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=0.860, test=0.759) total time= 1.1min\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=0.848, test=0.737) total time= 1.1min\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=None, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.7;, score=(train=0.630, test=0.593) total time= 1.6min\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=None, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.7;, score=(train=0.633, test=0.613) total time= 1.6min\n",
      "[CV 1/5] END learning_rate=0.001, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000, subsample=1.0;, score=(train=0.788, test=0.696) total time=  54.5s\n",
      "[CV 3/5] END learning_rate=0.001, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000, subsample=1.0;, score=(train=0.787, test=0.703) total time=  54.7s\n",
      "[CV 2/5] END learning_rate=0.001, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000, subsample=1.0;, score=(train=0.785, test=0.712) total time=  55.2s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=None, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.7;, score=(train=0.624, test=0.571) total time= 1.6min\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=None, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.7;, score=(train=0.632, test=0.612) total time= 1.5min\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=None, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.7;, score=(train=0.630, test=0.613) total time= 1.6min\n",
      "[CV 4/5] END learning_rate=0.001, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000, subsample=1.0;, score=(train=0.785, test=0.700) total time=  54.1s\n",
      "[CV 5/5] END learning_rate=0.001, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000, subsample=1.0;, score=(train=0.798, test=0.727) total time=  53.4s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.9;, score=(train=0.716, test=0.629) total time=  46.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.9;, score=(train=0.720, test=0.656) total time=  46.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.9;, score=(train=0.675, test=0.616) total time=  46.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.9;, score=(train=0.730, test=0.654) total time=  46.1s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.9;, score=(train=0.721, test=0.676) total time=  45.7s\n",
      "[CV 1/5] END learning_rate=0.01, loss=log_loss, max_depth=7, max_features=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=0.844, test=0.720) total time=  59.6s\n",
      "[CV 2/5] END learning_rate=0.01, loss=log_loss, max_depth=7, max_features=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=0.853, test=0.747) total time=  59.4s\n",
      "[CV 3/5] END learning_rate=0.01, loss=log_loss, max_depth=7, max_features=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=0.838, test=0.711) total time=  59.5s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=log_loss, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=1.0;, score=(train=0.768, test=0.679) total time=   5.8s\n",
      "[CV 4/5] END learning_rate=0.01, loss=log_loss, max_depth=7, max_features=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=0.855, test=0.728) total time=  59.8s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=0.763, test=0.679) total time=  54.1s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=log_loss, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=1.0;, score=(train=0.742, test=0.657) total time=   5.7s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=0.757, test=0.694) total time=  54.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=log_loss, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=1.0;, score=(train=0.779, test=0.683) total time=   5.8s\n",
      "[CV 5/5] END learning_rate=0.01, loss=log_loss, max_depth=7, max_features=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=0.852, test=0.742) total time=  59.8s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=log_loss, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=1.0;, score=(train=0.762, test=0.670) total time=   5.8s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=log_loss, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=1.0;, score=(train=0.770, test=0.679) total time=   5.7s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=0.763, test=0.674) total time=  54.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=0.758, test=0.688) total time=  53.7s\n",
      "[CV 1/5] END learning_rate=0.001, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.9;, score=(train=0.795, test=0.705) total time=  28.2s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=log_loss, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=0.773, test=0.707) total time=  54.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.9;, score=(train=0.794, test=0.715) total time=  28.6s\n",
      "[CV 3/5] END learning_rate=0.001, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.9;, score=(train=0.793, test=0.697) total time=  28.6s\n",
      "[CV 4/5] END learning_rate=0.001, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.9;, score=(train=0.791, test=0.702) total time=  28.7s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=log_loss, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=0.811, test=0.707) total time= 1.1min\n",
      "[CV 2/5] END learning_rate=0.0001, loss=log_loss, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=0.806, test=0.725) total time= 1.1min\n",
      "[CV 3/5] END learning_rate=0.0001, loss=log_loss, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=0.809, test=0.698) total time= 1.1min\n",
      "[CV 4/5] END learning_rate=0.0001, loss=log_loss, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=0.804, test=0.710) total time= 1.1min\n",
      "[CV 5/5] END learning_rate=0.0001, loss=log_loss, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=0.823, test=0.744) total time= 1.1min\n",
      "[CV 1/5] END learning_rate=0.001, loss=log_loss, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.8;, score=(train=0.840, test=0.721) total time=   6.6s\n",
      "[CV 2/5] END learning_rate=0.001, loss=log_loss, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.8;, score=(train=0.840, test=0.742) total time=   6.4s\n",
      "[CV 5/5] END learning_rate=0.001, loss=log_loss, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.9;, score=(train=0.802, test=0.730) total time=  30.1s\n",
      "[CV 3/5] END learning_rate=0.001, loss=log_loss, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.8;, score=(train=0.842, test=0.730) total time=   6.2s\n",
      "[CV 4/5] END learning_rate=0.001, loss=log_loss, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.8;, score=(train=0.845, test=0.735) total time=   6.2s\n",
      "[CV 5/5] END learning_rate=0.001, loss=log_loss, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.8;, score=(train=0.855, test=0.759) total time=   5.8s\n",
      "[CV 1/5] END learning_rate=0.001, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=0.703, test=0.648) total time=  27.3s\n",
      "[CV 2/5] END learning_rate=0.001, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=0.699, test=0.664) total time=  27.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=0.699, test=0.640) total time=  26.6s\n",
      "[CV 4/5] END learning_rate=0.001, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=0.704, test=0.655) total time=  26.2s\n",
      "[CV 5/5] END learning_rate=0.001, loss=log_loss, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=0.708, test=0.675) total time=  26.1s\n",
      "Gradient Boosting Classifier Accuracy: 0.657\n",
      "Best Parameters: {'subsample': 0.8, 'n_estimators': 750, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 6, 'loss': 'exponential', 'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=101)\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [1e-4, 1e-3, 1e-2],\n",
    "    'n_estimators': [100, 250, 500, 750, 1000],\n",
    "    'max_depth': [3, 4, 5, 6, 7],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': [None, 'sqrt', 'log2'],\n",
    "    'loss': ['log_loss', 'exponential']\n",
    "}\n",
    "\n",
    "# Initialize the GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier(random_state=101)\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "best_gbc2 = RandomizedSearchCV(\n",
    "    estimator=gbc,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=100,  # Number of parameter settings sampled\n",
    "    cv=cv,\n",
    "    scoring='accuracy',\n",
    "    verbose=5,\n",
    "    random_state=101,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True  # To analyze training vs. validation scores\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "best_gbc2.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "pred_gbc = best_gbc2.best_estimator_.predict(X_test)\n",
    "print(\"Gradient Boosting Classifier Accuracy:\", accuracy_score(y_test, pred_gbc))\n",
    "print(\"Best Parameters:\", best_gbc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 18 is smaller than n_iter=100. Running 18 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END learning_rate=0.0001, max_depth=6, n_estimators=500;, score=(train=0.661, test=0.625) total time= 5.0min\n",
      "[CV 2/5] END learning_rate=0.0001, max_depth=6, n_estimators=500;, score=(train=0.660, test=0.623) total time= 5.0min\n",
      "[CV 5/5] END learning_rate=0.0001, max_depth=6, n_estimators=500;, score=(train=0.675, test=0.619) total time= 5.1min\n",
      "[CV 3/5] END learning_rate=0.0001, max_depth=6, n_estimators=500;, score=(train=0.685, test=0.622) total time= 5.1min\n",
      "[CV 4/5] END learning_rate=0.0001, max_depth=6, n_estimators=500;, score=(train=0.667, test=0.634) total time= 5.1min\n",
      "[CV 1/5] END learning_rate=0.0001, max_depth=6, n_estimators=750;, score=(train=0.669, test=0.642) total time= 7.6min\n",
      "[CV 2/5] END learning_rate=0.0001, max_depth=6, n_estimators=750;, score=(train=0.664, test=0.626) total time= 7.7min\n",
      "[CV 3/5] END learning_rate=0.0001, max_depth=6, n_estimators=750;, score=(train=0.691, test=0.630) total time= 7.7min\n",
      "[CV 5/5] END learning_rate=0.0001, max_depth=6, n_estimators=750;, score=(train=0.677, test=0.619) total time= 7.6min\n",
      "[CV 4/5] END learning_rate=0.0001, max_depth=6, n_estimators=750;, score=(train=0.674, test=0.632) total time= 7.7min\n",
      "[CV 1/5] END learning_rate=0.0001, max_depth=7, n_estimators=500;, score=(train=0.678, test=0.630) total time= 5.9min\n",
      "[CV 1/5] END learning_rate=0.0001, max_depth=6, n_estimators=1000;, score=(train=0.671, test=0.644) total time=10.3min\n",
      "[CV 2/5] END learning_rate=0.0001, max_depth=6, n_estimators=1000;, score=(train=0.667, test=0.628) total time=10.3min\n",
      "[CV 3/5] END learning_rate=0.0001, max_depth=6, n_estimators=1000;, score=(train=0.686, test=0.628) total time=10.4min\n",
      "[CV 5/5] END learning_rate=0.0001, max_depth=6, n_estimators=1000;, score=(train=0.680, test=0.623) total time=10.1min\n",
      "[CV 4/5] END learning_rate=0.0001, max_depth=6, n_estimators=1000;, score=(train=0.678, test=0.639) total time=10.2min\n",
      "[CV 2/5] END learning_rate=0.0001, max_depth=7, n_estimators=500;, score=(train=0.691, test=0.641) total time= 5.8min\n",
      "[CV 3/5] END learning_rate=0.0001, max_depth=7, n_estimators=500;, score=(train=0.714, test=0.638) total time= 5.8min\n",
      "[CV 4/5] END learning_rate=0.0001, max_depth=7, n_estimators=500;, score=(train=0.697, test=0.650) total time= 5.7min\n",
      "[CV 5/5] END learning_rate=0.0001, max_depth=7, n_estimators=500;, score=(train=0.691, test=0.627) total time= 5.7min\n",
      "[CV 1/5] END learning_rate=0.0001, max_depth=7, n_estimators=750;, score=(train=0.697, test=0.654) total time= 8.7min\n",
      "[CV 2/5] END learning_rate=0.0001, max_depth=7, n_estimators=750;, score=(train=0.692, test=0.640) total time= 8.8min\n",
      "[CV 4/5] END learning_rate=0.0001, max_depth=7, n_estimators=750;, score=(train=0.702, test=0.652) total time=13.6min\n",
      "[CV 3/5] END learning_rate=0.0001, max_depth=7, n_estimators=750;, score=(train=0.721, test=0.643) total time=14.4min\n",
      "[CV 5/5] END learning_rate=0.0001, max_depth=7, n_estimators=750;, score=(train=0.694, test=0.628) total time=17.2min\n",
      "[CV 1/5] END learning_rate=0.0001, max_depth=7, n_estimators=1000;, score=(train=0.691, test=0.653) total time=35.4min\n",
      "[CV 2/5] END learning_rate=0.0001, max_depth=7, n_estimators=1000;, score=(train=0.698, test=0.643) total time=40.1min\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=6, n_estimators=500;, score=(train=0.742, test=0.694) total time=31.9min\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=6, n_estimators=500;, score=(train=0.739, test=0.684) total time=32.1min\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=6, n_estimators=500;, score=(train=0.739, test=0.658) total time=32.5min\n",
      "[CV 3/5] END learning_rate=0.0001, max_depth=7, n_estimators=1000;, score=(train=0.722, test=0.639) total time=49.8min\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=6, n_estimators=500;, score=(train=0.730, test=0.673) total time=32.9min\n",
      "[CV 4/5] END learning_rate=0.0001, max_depth=7, n_estimators=1000;, score=(train=0.707, test=0.658) total time=66.1min\n",
      "[CV 5/5] END learning_rate=0.0001, max_depth=7, n_estimators=1000;, score=(train=0.701, test=0.628) total time=66.6min\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=6, n_estimators=500;, score=(train=0.745, test=0.675) total time=33.2min\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=6, n_estimators=750;, score=(train=0.759, test=0.708) total time=50.3min\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=6, n_estimators=750;, score=(train=0.760, test=0.697) total time=49.7min\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=6, n_estimators=750;, score=(train=0.770, test=0.679) total time=46.7min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[116], line 25\u001b[0m\n\u001b[1;32m     12\u001b[0m best_gbc \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[1;32m     13\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mgbc,\n\u001b[1;32m     14\u001b[0m     param_distributions\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     return_train_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# To analyze training vs. validation scores\u001b[39;00m\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[43mbest_gbc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Predict and evaluate\u001b[39;00m\n\u001b[1;32m     28\u001b[0m pred_gbc \u001b[38;5;241m=\u001b[39m best_gbc\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1015\u001b[0m     )\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1960\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1958\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1959\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1960\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1961\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1962\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1963\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/model_selection/_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    962\u001b[0m         )\n\u001b[1;32m    963\u001b[0m     )\n\u001b[0;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    988\u001b[0m     )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=101)\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [1e-4, 1e-3, 1e-2],\n",
    "    'n_estimators': [500, 750, 1000],\n",
    "    'max_depth': [5, 6, 7],\n",
    "}\n",
    "# Initialize the GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier(random_state=101)\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "best_gbc = RandomizedSearchCV(\n",
    "    estimator=gbc,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=100,  # Number of parameter settings sampled\n",
    "    cv=cv,\n",
    "    scoring='accuracy',\n",
    "    verbose=3,\n",
    "    random_state=101,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True  # To analyze training vs. validation scores\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "best_gbc.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "pred_gbc = best_gbc.best_estimator_.predict(X_test)\n",
    "print(\"Gradient Boosting Classifier Accuracy:\", accuracy_score(y_test, pred_gbc))\n",
    "print(\"Best Parameters:\", best_gbc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.622 1\n"
     ]
    }
   ],
   "source": [
    "best = 0\n",
    "n_n = 0\n",
    "for i in range(1, 100):    \n",
    "    param_grid = {\n",
    "        'n_neighbors': [63],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'algorithm': ['auto'],\n",
    "        'leaf_size': [1],\n",
    "        'p': [1, 2],}\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=101)\n",
    "\n",
    "    best_knn = GridSearchCV(\n",
    "        KNeighborsClassifier(),\n",
    "        param_grid,\n",
    "        cv=cv,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    best_knn.fit(X_train, y_train)\n",
    "    pred = best_knn.best_estimator_.predict(X_test)\n",
    "    # print(accuracy_score(y_test, pred))\n",
    "    # print(best_knn.best_params_)\n",
    "    score = accuracy_score(y_test, pred)\n",
    "    if score > best:\n",
    "        best = score\n",
    "        n_n = i\n",
    "\n",
    "print(best, n_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.597 100\n"
     ]
    }
   ],
   "source": [
    "best = 0\n",
    "n_n = 0\n",
    "for i in range(100, 1100, 33):    \n",
    "    param_grid = {\n",
    "        'n_neighbors': [i],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'algorithm': ['auto'],\n",
    "        'leaf_size': [1],\n",
    "        'p': [1, 2],}\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=101)\n",
    "\n",
    "    best_knn = GridSearchCV(\n",
    "        KNeighborsClassifier(),\n",
    "        param_grid,\n",
    "        cv=cv,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    best_knn.fit(X_train, y_train)\n",
    "    pred = best_knn.best_estimator_.predict(X_test)\n",
    "    # print(accuracy_score(y_test, pred))\n",
    "    # print(best_knn.best_params_)\n",
    "    score = accuracy_score(y_test, pred)\n",
    "    if score > best:\n",
    "        best = score\n",
    "        n_n = i\n",
    "\n",
    "print(best, n_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.47697167, -2.39488025,  3.01299261, ...,  0.07993488,\n",
       "        -0.09280763, -0.21674284],\n",
       "       [ 2.6470763 , -7.10882141, -0.48137408, ...,  0.20361502,\n",
       "         0.09274828, -0.03457125],\n",
       "       [-2.85586012,  4.30927577, -0.03534365, ...,  0.30233175,\n",
       "         0.07264612,  0.04994187],\n",
       "       ...,\n",
       "       [30.55843418,  0.91438656,  4.77390641, ...,  0.31755162,\n",
       "        -0.76115822, -0.17223901],\n",
       "       [31.30817513,  0.1605108 ,  4.50606648, ..., -0.24897733,\n",
       "        -0.58856532,  0.24257708],\n",
       "       [32.82541546,  0.98442496,  5.99846122, ...,  0.24917282,\n",
       "         0.31128077,  0.54682842]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "[CV 2/5] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=20, max_features=sqrt, max_samples=0.9, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=20, max_features=sqrt, max_samples=0.9, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=20, max_features=sqrt, max_samples=0.9, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=20, max_features=sqrt, max_samples=0.9, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=nan total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=20, max_features=sqrt, max_samples=0.9, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=nan total time=   0.1s\n",
      "[CV 1/5] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=30, max_features=log2, max_samples=0.9, min_samples_leaf=2, min_samples_split=15, n_estimators=400;, score=0.860 total time= 1.6min\n",
      "[CV 3/5] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=30, max_features=log2, max_samples=0.9, min_samples_leaf=2, min_samples_split=15, n_estimators=400;, score=0.859 total time= 1.6min\n",
      "[CV 2/5] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=30, max_features=log2, max_samples=0.9, min_samples_leaf=2, min_samples_split=15, n_estimators=400;, score=0.862 total time= 1.6min\n",
      "[CV 1/5] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=10, max_features=None, max_samples=0.7, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=10, max_features=None, max_samples=0.7, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=10, max_features=None, max_samples=0.7, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=10, max_features=None, max_samples=0.7, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=10, max_features=None, max_samples=0.7, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=50, max_features=log2, max_samples=1.0, min_samples_leaf=1, min_samples_split=15, n_estimators=200;, score=0.862 total time=  40.0s\n",
      "[CV 4/5] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=30, max_features=log2, max_samples=0.9, min_samples_leaf=2, min_samples_split=15, n_estimators=400;, score=0.870 total time= 1.2min\n",
      "[CV 5/5] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=30, max_features=log2, max_samples=0.9, min_samples_leaf=2, min_samples_split=15, n_estimators=400;, score=0.874 total time= 1.2min\n",
      "[CV 2/5] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=50, max_features=log2, max_samples=1.0, min_samples_leaf=1, min_samples_split=15, n_estimators=200;, score=0.867 total time=  38.8s\n",
      "[CV 3/5] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=50, max_features=log2, max_samples=1.0, min_samples_leaf=1, min_samples_split=15, n_estimators=200;, score=0.866 total time=  37.9s\n",
      "[CV 4/5] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=50, max_features=log2, max_samples=1.0, min_samples_leaf=1, min_samples_split=15, n_estimators=200;, score=0.870 total time=  37.2s\n",
      "[CV 5/5] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=50, max_features=log2, max_samples=1.0, min_samples_leaf=1, min_samples_split=15, n_estimators=200;, score=0.871 total time=  38.1s\n",
      "[CV 1/5] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=None, max_features=log2, max_samples=0.7, min_samples_leaf=2, min_samples_split=20, n_estimators=400;, score=0.852 total time= 1.3min\n",
      "[CV 2/5] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=None, max_features=log2, max_samples=0.7, min_samples_leaf=2, min_samples_split=20, n_estimators=400;, score=0.854 total time= 1.3min\n",
      "[CV 3/5] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=None, max_features=log2, max_samples=0.7, min_samples_leaf=2, min_samples_split=20, n_estimators=400;, score=0.853 total time= 1.4min\n",
      "[CV 1/5] END bootstrap=False, class_weight=None, criterion=gini, max_depth=30, max_features=sqrt, max_samples=0.5, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, class_weight=None, criterion=gini, max_depth=30, max_features=sqrt, max_samples=0.5, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, class_weight=None, criterion=gini, max_depth=30, max_features=sqrt, max_samples=0.5, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, class_weight=None, criterion=gini, max_depth=30, max_features=sqrt, max_samples=0.5, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, class_weight=None, criterion=gini, max_depth=30, max_features=sqrt, max_samples=0.5, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=None, max_features=None, max_samples=0.9, min_samples_leaf=8, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=None, max_features=None, max_samples=0.9, min_samples_leaf=8, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=None, max_features=None, max_samples=0.9, min_samples_leaf=8, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=None, max_features=None, max_samples=0.9, min_samples_leaf=8, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=None, max_features=None, max_samples=0.9, min_samples_leaf=8, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=10, max_features=auto, max_samples=1.0, min_samples_leaf=8, min_samples_split=15, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=10, max_features=auto, max_samples=1.0, min_samples_leaf=8, min_samples_split=15, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=10, max_features=auto, max_samples=1.0, min_samples_leaf=8, min_samples_split=15, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=10, max_features=auto, max_samples=1.0, min_samples_leaf=8, min_samples_split=15, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=10, max_features=auto, max_samples=1.0, min_samples_leaf=8, min_samples_split=15, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=40, max_features=log2, max_samples=0.5, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=40, max_features=log2, max_samples=0.5, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=40, max_features=log2, max_samples=0.5, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=40, max_features=log2, max_samples=0.5, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=40, max_features=log2, max_samples=0.5, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=40, max_features=sqrt, max_samples=0.9, min_samples_leaf=4, min_samples_split=15, n_estimators=300;, score=0.859 total time= 1.1min\n",
      "[CV 4/5] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=None, max_features=log2, max_samples=0.7, min_samples_leaf=2, min_samples_split=20, n_estimators=400;, score=0.855 total time= 1.4min\n",
      "[CV 5/5] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=None, max_features=log2, max_samples=0.7, min_samples_leaf=2, min_samples_split=20, n_estimators=400;, score=0.860 total time= 1.4min\n",
      "[CV 2/5] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=40, max_features=sqrt, max_samples=0.9, min_samples_leaf=4, min_samples_split=15, n_estimators=300;, score=0.857 total time= 1.4min\n",
      "[CV 1/5] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=None, max_features=None, max_samples=0.9, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.859 total time= 7.5min\n",
      "[CV 1/5] END bootstrap=False, class_weight=None, criterion=gini, max_depth=30, max_features=auto, max_samples=1.0, min_samples_leaf=4, min_samples_split=20, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, class_weight=None, criterion=gini, max_depth=30, max_features=auto, max_samples=1.0, min_samples_leaf=4, min_samples_split=20, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, class_weight=None, criterion=gini, max_depth=30, max_features=auto, max_samples=1.0, min_samples_leaf=4, min_samples_split=20, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, class_weight=None, criterion=gini, max_depth=30, max_features=auto, max_samples=1.0, min_samples_leaf=4, min_samples_split=20, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, class_weight=None, criterion=gini, max_depth=30, max_features=auto, max_samples=1.0, min_samples_leaf=4, min_samples_split=20, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=30, max_features=None, max_samples=0.7, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=30, max_features=None, max_samples=0.7, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=30, max_features=None, max_samples=0.7, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=30, max_features=None, max_samples=0.7, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=30, max_features=None, max_samples=0.7, min_samples_leaf=1, min_samples_split=15, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=20, max_features=log2, max_samples=0.5, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=20, max_features=log2, max_samples=0.5, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=20, max_features=log2, max_samples=0.5, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=20, max_features=log2, max_samples=0.5, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=20, max_features=log2, max_samples=0.5, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=40, max_features=sqrt, max_samples=0.9, min_samples_leaf=4, min_samples_split=15, n_estimators=300;, score=0.861 total time= 1.4min\n",
      "[CV 4/5] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=40, max_features=sqrt, max_samples=0.9, min_samples_leaf=4, min_samples_split=15, n_estimators=300;, score=0.863 total time= 1.4min\n",
      "[CV 4/5] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=None, max_features=None, max_samples=0.9, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.852 total time= 7.6min\n",
      "[CV 3/5] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=None, max_features=None, max_samples=0.9, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.860 total time= 7.8min\n",
      "[CV 2/5] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=None, max_features=None, max_samples=0.9, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.864 total time= 7.9min\n",
      "[CV 1/5] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=None, max_features=sqrt, max_samples=0.9, min_samples_leaf=8, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=None, max_features=sqrt, max_samples=0.9, min_samples_leaf=8, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=None, max_features=sqrt, max_samples=0.9, min_samples_leaf=8, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=None, max_features=sqrt, max_samples=0.9, min_samples_leaf=8, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=None, max_features=sqrt, max_samples=0.9, min_samples_leaf=8, min_samples_split=2, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=30, max_features=auto, max_samples=1.0, min_samples_leaf=8, min_samples_split=15, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=30, max_features=auto, max_samples=1.0, min_samples_leaf=8, min_samples_split=15, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=30, max_features=auto, max_samples=1.0, min_samples_leaf=8, min_samples_split=15, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=30, max_features=auto, max_samples=1.0, min_samples_leaf=8, min_samples_split=15, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=30, max_features=auto, max_samples=1.0, min_samples_leaf=8, min_samples_split=15, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=40, max_features=sqrt, max_samples=0.9, min_samples_leaf=6, min_samples_split=15, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=40, max_features=sqrt, max_samples=0.9, min_samples_leaf=6, min_samples_split=15, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=40, max_features=sqrt, max_samples=0.9, min_samples_leaf=6, min_samples_split=15, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=40, max_features=sqrt, max_samples=0.9, min_samples_leaf=6, min_samples_split=15, n_estimators=500;, score=nan total time=   0.1s\n",
      "[CV 5/5] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=40, max_features=sqrt, max_samples=0.9, min_samples_leaf=6, min_samples_split=15, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=20, max_features=auto, max_samples=1.0, min_samples_leaf=8, min_samples_split=10, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=20, max_features=auto, max_samples=1.0, min_samples_leaf=8, min_samples_split=10, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=20, max_features=auto, max_samples=1.0, min_samples_leaf=8, min_samples_split=10, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=20, max_features=auto, max_samples=1.0, min_samples_leaf=8, min_samples_split=10, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=20, max_features=auto, max_samples=1.0, min_samples_leaf=8, min_samples_split=10, n_estimators=400;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=40, max_features=log2, max_samples=0.5, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=40, max_features=log2, max_samples=0.5, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=40, max_features=log2, max_samples=0.5, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=40, max_features=log2, max_samples=0.5, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=40, max_features=log2, max_samples=0.5, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=None, max_features=None, max_samples=0.9, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.868 total time= 7.9min\n",
      "[CV 1/5] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=10, max_features=log2, max_samples=1.0, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.818 total time=  44.0s\n",
      "[CV 2/5] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=10, max_features=log2, max_samples=1.0, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.800 total time=  43.6s\n",
      "[CV 5/5] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=40, max_features=sqrt, max_samples=0.9, min_samples_leaf=4, min_samples_split=15, n_estimators=300;, score=0.872 total time= 1.4min\n",
      "[CV 3/5] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=10, max_features=log2, max_samples=1.0, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.803 total time=  45.6s\n",
      "[CV 1/5] END bootstrap=False, class_weight=None, criterion=gini, max_depth=10, max_features=auto, max_samples=0.5, min_samples_leaf=4, min_samples_split=20, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, class_weight=None, criterion=gini, max_depth=10, max_features=auto, max_samples=0.5, min_samples_leaf=4, min_samples_split=20, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, class_weight=None, criterion=gini, max_depth=10, max_features=auto, max_samples=0.5, min_samples_leaf=4, min_samples_split=20, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, class_weight=None, criterion=gini, max_depth=10, max_features=auto, max_samples=0.5, min_samples_leaf=4, min_samples_split=20, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, class_weight=None, criterion=gini, max_depth=10, max_features=auto, max_samples=0.5, min_samples_leaf=4, min_samples_split=20, n_estimators=200;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=None, max_features=log2, max_samples=0.7, min_samples_leaf=2, min_samples_split=2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=None, max_features=log2, max_samples=0.7, min_samples_leaf=2, min_samples_split=2, n_estimators=300;, score=nan total time=   0.1s\n",
      "[CV 3/5] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=None, max_features=log2, max_samples=0.7, min_samples_leaf=2, min_samples_split=2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=None, max_features=log2, max_samples=0.7, min_samples_leaf=2, min_samples_split=2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=None, max_features=log2, max_samples=0.7, min_samples_leaf=2, min_samples_split=2, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=20, max_features=auto, max_samples=0.7, min_samples_leaf=2, min_samples_split=15, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=20, max_features=auto, max_samples=0.7, min_samples_leaf=2, min_samples_split=15, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=20, max_features=auto, max_samples=0.7, min_samples_leaf=2, min_samples_split=15, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=20, max_features=auto, max_samples=0.7, min_samples_leaf=2, min_samples_split=15, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=20, max_features=auto, max_samples=0.7, min_samples_leaf=2, min_samples_split=15, n_estimators=500;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, class_weight=None, criterion=gini, max_depth=20, max_features=log2, max_samples=0.9, min_samples_leaf=1, min_samples_split=5, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, class_weight=None, criterion=gini, max_depth=20, max_features=log2, max_samples=0.9, min_samples_leaf=1, min_samples_split=5, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, class_weight=None, criterion=gini, max_depth=20, max_features=log2, max_samples=0.9, min_samples_leaf=1, min_samples_split=5, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, class_weight=None, criterion=gini, max_depth=20, max_features=log2, max_samples=0.9, min_samples_leaf=1, min_samples_split=5, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, class_weight=None, criterion=gini, max_depth=20, max_features=log2, max_samples=0.9, min_samples_leaf=1, min_samples_split=5, n_estimators=300;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=10, max_features=log2, max_samples=1.0, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.811 total time=  45.7s\n",
      "[CV 5/5] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=10, max_features=log2, max_samples=1.0, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.798 total time=  48.1s\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10, 15, 20],\n",
    "    'min_samples_leaf': [1, 2, 4, 6, 8],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "    'bootstrap': [True, False],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'class_weight': [None, 'balanced', 'balanced_subsample'],\n",
    "    'max_samples': [0.5, 0.7, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=101)\n",
    "\n",
    "best_rf = RandomizedSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=101),\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=50,  # Number of parameter settings sampled\n",
    "    cv=cv,\n",
    "    scoring='accuracy',\n",
    "    verbose=5,\n",
    "    random_state=101,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "best_rf.fit(X_train, y_train)\n",
    "pred = best_rf.best_estimator_.predict(X_test)\n",
    "print(accuracy_score(y_test, pred))\n",
    "print(best_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=0.01, max_depth=3, random_state=101)\n",
    "pred = gbc.fit(X_train,y_train).predict(X_test)\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf_soft = VotingClassifier(estimators = [('knn',knn),('rf',rf),('svc',svc)], voting = 'soft') \n",
    "pred = voting_clf_soft.fit(X_train,y_train).predict(X_test)\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp\n",
      "0.679\n",
      "svc\n",
      "0.67\n",
      "rf\n",
      "0.666\n",
      "lr\n",
      "0.68\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'mlp': best_mlp.best_estimator_,\n",
    "    'svc': svc,\n",
    "    'rf': best_rf.best_estimator_,\n",
    "    'lr': LogisticRegression()\n",
    "}\n",
    "for model_name, model in models.items():\n",
    "    print(model_name)\n",
    "    estimators = [('mlp', best_mlp.best_estimator_), ('svc',svc), ('rf', best_rf.best_estimator_)]\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=101)\n",
    "\n",
    "    stacking_clf = StackingClassifier(\n",
    "        estimators=estimators,\n",
    "        final_estimator=model,\n",
    "        cv=cv,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    pred = stacking_clf.fit(X_train,y_train).predict(X_test)\n",
    "    print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   12.2s remaining:   18.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   14.6s finished\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  1.2min remaining:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  1.2min remaining:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  2.0min remaining:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.681\n"
     ]
    }
   ],
   "source": [
    "estimators = [('mlp', best_mlp.best_estimator_), ('svc',svc), ('rf', best_rf.best_estimator_), ('gbc', best_gbc.best_estimator_)]\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=101)\n",
    "\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression(),\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=5\n",
    ")\n",
    "\n",
    "pred = stacking_clf.fit(X_train,y_train).predict(X_test)\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   10.1s remaining:   15.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   11.5s finished\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   59.2s remaining:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   59.5s finished\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  1.0min remaining:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.687\n"
     ]
    }
   ],
   "source": [
    "estimators = [('mlp', best_mlp.best_estimator_), ('gbc', best_gbc.best_estimator_), ('svc', best_svc.best_estimator_)]\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=101)\n",
    "\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression(),\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=5\n",
    ")\n",
    "\n",
    "pred = stacking_clf.fit(X_train,y_train).predict(X_test)\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    9.5s remaining:   14.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   11.2s finished\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   58.0s remaining:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   58.5s finished\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  1.0min remaining:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.697\n"
     ]
    }
   ],
   "source": [
    "estimators = [('mlp', best_mlp.best_estimator_), ('gbc', best_gbc.best_estimator_), ('svc', best_svc.best_estimator_)]\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=101)\n",
    "\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression(C=1, penalty='l2', solver='saga', class_weight='balanced'),\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=5\n",
    ")\n",
    "\n",
    "pred = stacking_clf.fit(X_train,y_train).predict(X_test)\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   11.4s remaining:   17.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   13.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   51.7s remaining:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   52.9s remaining:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   52.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   53.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.698\n"
     ]
    }
   ],
   "source": [
    "estimators = [('mlp', best_mlp.best_estimator_), ('gbc', best_gbc.best_estimator_), ('svc', best_svc.best_estimator_)]\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=101)\n",
    "\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression(C=1, penalty='l2', solver='saga', class_weight='balanced'),\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=5\n",
    ")\n",
    "\n",
    "pred = stacking_clf.fit(X_train,y_train).predict(X_test)\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   22.8s remaining:   34.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   29.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  1.8min remaining:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.8min finished\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  1.9min remaining:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69\n"
     ]
    }
   ],
   "source": [
    "estimators = [('mlp', best_mlp.best_estimator_), ('gbc', best_gbc.best_estimator_), ('svc', best_svc.best_estimator_)]\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=101)\n",
    "\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression(C=1, penalty='l2', solver='saga', class_weight='balanced'),\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=5\n",
    ")\n",
    "\n",
    "pred = stacking_clf.fit(X_train,y_train).predict(X_test)\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[137], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m cv \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m101\u001b[39m)\n\u001b[1;32m      3\u001b[0m voting_clf_soft \u001b[38;5;241m=\u001b[39m VotingClassifier(estimators \u001b[38;5;241m=\u001b[39m estimators, voting \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mvoting_clf_soft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(accuracy_score(y_test, pred))\n",
      "File \u001b[0;32m/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/utils/validation.py:66\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     69\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[38;5;241m-\u001b[39mextra_args:])\n\u001b[1;32m     72\u001b[0m ]\n",
      "File \u001b[0;32m/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/ensemble/_voting.py:423\u001b[0m, in \u001b[0;36mVotingClassifier.fit\u001b[0;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    421\u001b[0m     fit_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_weight\n\u001b[0;32m--> 423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformed_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/ensemble/_voting.py:104\u001b[0m, in \u001b[0;36m_BaseVoting.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m fit_params:\n\u001b[1;32m    100\u001b[0m             routed_params[name]\u001b[38;5;241m.\u001b[39mfit[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m fit_params[\n\u001b[1;32m    101\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    102\u001b[0m             ]\n\u001b[0;32m--> 104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_single_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mVoting\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclfs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclfs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdrop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    115\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnamed_estimators_ \u001b[38;5;241m=\u001b[39m Bunch()\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# Uses 'drop' as placeholder for dropped estimators\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/utils/parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/ensemble/_base.py:40\u001b[0m, in \u001b[0;36m_fit_single_estimator\u001b[0;34m(estimator, X, y, fit_params, message_clsname, message)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m---> 40\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[0;32m/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:783\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[1;32m    782\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[0;32m--> 783\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_at_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:879\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    872\u001b[0m         initial_loss \u001b[38;5;241m=\u001b[39m factor \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss(\n\u001b[1;32m    873\u001b[0m             y_true\u001b[38;5;241m=\u001b[39my_oob_masked,\n\u001b[1;32m    874\u001b[0m             raw_prediction\u001b[38;5;241m=\u001b[39mraw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[1;32m    875\u001b[0m             sample_weight\u001b[38;5;241m=\u001b[39msample_weight_oob_masked,\n\u001b[1;32m    876\u001b[0m         )\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[0;32m--> 879\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_csc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_csr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[38;5;66;03m# track loss\u001b[39;00m\n\u001b[1;32m    892\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:490\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    487\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;241m*\u001b[39m sample_mask\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m    489\u001b[0m X \u001b[38;5;241m=\u001b[39m X_csc \u001b[38;5;28;01mif\u001b[39;00m X_csc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[0;32m--> 490\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg_g_view\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    492\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[1;32m    495\u001b[0m X_for_tree_update \u001b[38;5;241m=\u001b[39m X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n",
      "File \u001b[0;32m/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/tree/_classes.py:1377\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1349\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1350\u001b[0m \n\u001b[1;32m   1351\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1377\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1378\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1379\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1380\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1382\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/tree/_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    463\u001b[0m         splitter,\n\u001b[1;32m    464\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    470\u001b[0m     )\n\u001b[0;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=101)\n",
    "\n",
    "voting_clf_soft = VotingClassifier(estimators = estimators, voting = 'soft')\n",
    "pred = voting_clf_soft.fit(X_train, y_train).predict(X_test)\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('mlp', best_mlp.best_estimator_), ('gbc', best_gbc.best_estimator_), ('svc', best_svc.best_estimator_)]\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=101)\n",
    "\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression(C=1, penalty='l2', solver='saga', class_weight='balanced'),\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=5\n",
    ")\n",
    "\n",
    "pred = stacking_clf.fit(X_train,y_train).predict(X_test)\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   13.4s remaining:   20.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   15.5s finished\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   54.1s remaining:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   54.6s finished\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   55.1s remaining:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   55.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.697\n"
     ]
    }
   ],
   "source": [
    "estimators = [('mlp', best_mlp2.best_estimator_), ('gbc', best_gbc.best_estimator_), ('svc', best_svc.best_estimator_)]\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=101)\n",
    "\n",
    "stacking_clf2 = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression(C=1, penalty='l2', solver='saga', class_weight='balanced'),\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=5\n",
    ")\n",
    "\n",
    "pred = stacking_clf2.fit(X_train,y_train).predict(X_test)\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 5/5] END final_estimator__C=10, final_estimator__class_weight=None, final_estimator__max_iter=100, final_estimator__penalty=l2, final_estimator__solver=lbfgs;, score=0.865 total time=92.5min\n",
      "[CV 4/5] END final_estimator__C=10, final_estimator__class_weight=None, final_estimator__max_iter=100, final_estimator__penalty=l2, final_estimator__solver=lbfgs;, score=0.890 total time=92.6min\n",
      "[CV 1/5] END final_estimator__C=100, final_estimator__class_weight=None, final_estimator__max_iter=200, final_estimator__penalty=l2, final_estimator__solver=liblinear;, score=0.879 total time=92.7min\n",
      "[CV 2/5] END final_estimator__C=10, final_estimator__class_weight=None, final_estimator__max_iter=100, final_estimator__penalty=l2, final_estimator__solver=lbfgs;, score=0.876 total time=92.8min\n",
      "[CV 3/5] END final_estimator__C=100, final_estimator__class_weight=None, final_estimator__max_iter=200, final_estimator__penalty=l2, final_estimator__solver=liblinear;, score=0.875 total time=93.0min\n",
      "[CV 3/5] END final_estimator__C=10, final_estimator__class_weight=None, final_estimator__max_iter=100, final_estimator__penalty=l2, final_estimator__solver=lbfgs;, score=0.875 total time=93.0min\n",
      "[CV 2/5] END final_estimator__C=100, final_estimator__class_weight=None, final_estimator__max_iter=200, final_estimator__penalty=l2, final_estimator__solver=liblinear;, score=0.876 total time=93.3min\n",
      "[CV 1/5] END final_estimator__C=10, final_estimator__class_weight=None, final_estimator__max_iter=100, final_estimator__penalty=l2, final_estimator__solver=lbfgs;, score=0.879 total time=93.6min\n",
      "[CV 1/5] END final_estimator__C=0.01, final_estimator__class_weight=balanced, final_estimator__max_iter=300, final_estimator__penalty=l1, final_estimator__solver=lbfgs;, score=nan total time=79.5min\n",
      "[CV 4/5] END final_estimator__C=100, final_estimator__class_weight=None, final_estimator__max_iter=200, final_estimator__penalty=l2, final_estimator__solver=liblinear;, score=0.890 total time=79.7min\n",
      "[CV 5/5] END final_estimator__C=100, final_estimator__class_weight=None, final_estimator__max_iter=200, final_estimator__penalty=l2, final_estimator__solver=liblinear;, score=0.866 total time=79.7min\n",
      "[CV 2/5] END final_estimator__C=0.01, final_estimator__class_weight=balanced, final_estimator__max_iter=300, final_estimator__penalty=l1, final_estimator__solver=lbfgs;, score=nan total time=79.8min\n",
      "[CV 3/5] END final_estimator__C=0.01, final_estimator__class_weight=balanced, final_estimator__max_iter=300, final_estimator__penalty=l1, final_estimator__solver=lbfgs;, score=nan total time=79.6min\n",
      "[CV 4/5] END final_estimator__C=0.01, final_estimator__class_weight=balanced, final_estimator__max_iter=300, final_estimator__penalty=l1, final_estimator__solver=lbfgs;, score=nan total time=79.6min\n",
      "[CV 5/5] END final_estimator__C=0.01, final_estimator__class_weight=balanced, final_estimator__max_iter=300, final_estimator__penalty=l1, final_estimator__solver=lbfgs;, score=nan total time=79.4min\n",
      "[CV 1/5] END final_estimator__C=10, final_estimator__class_weight=balanced, final_estimator__max_iter=100, final_estimator__penalty=l2, final_estimator__solver=lbfgs;, score=0.879 total time=79.9min\n",
      "[CV 4/5] END final_estimator__C=10, final_estimator__class_weight=balanced, final_estimator__max_iter=100, final_estimator__penalty=l2, final_estimator__solver=lbfgs;, score=0.891 total time=52.1min\n",
      "[CV 3/5] END final_estimator__C=10, final_estimator__class_weight=balanced, final_estimator__max_iter=100, final_estimator__penalty=l2, final_estimator__solver=lbfgs;, score=0.875 total time=52.3min\n",
      "[CV 5/5] END final_estimator__C=10, final_estimator__class_weight=balanced, final_estimator__max_iter=100, final_estimator__penalty=l2, final_estimator__solver=lbfgs;, score=0.867 total time=52.0min\n",
      "[CV 3/5] END final_estimator__C=100, final_estimator__class_weight=balanced, final_estimator__max_iter=200, final_estimator__penalty=l2, final_estimator__solver=liblinear;, score=0.875 total time=51.9min\n",
      "[CV 2/5] END final_estimator__C=10, final_estimator__class_weight=balanced, final_estimator__max_iter=100, final_estimator__penalty=l2, final_estimator__solver=lbfgs;, score=0.876 total time=52.5min\n",
      "[CV 2/5] END final_estimator__C=100, final_estimator__class_weight=balanced, final_estimator__max_iter=200, final_estimator__penalty=l2, final_estimator__solver=liblinear;, score=0.877 total time=52.2min\n",
      "[CV 1/5] END final_estimator__C=100, final_estimator__class_weight=balanced, final_estimator__max_iter=200, final_estimator__penalty=l2, final_estimator__solver=liblinear;, score=0.879 total time=52.3min\n",
      "[CV 4/5] END final_estimator__C=100, final_estimator__class_weight=balanced, final_estimator__max_iter=200, final_estimator__penalty=l2, final_estimator__solver=liblinear;, score=0.890 total time=52.2min\n",
      "[CV 5/5] END final_estimator__C=100, final_estimator__class_weight=balanced, final_estimator__max_iter=200, final_estimator__penalty=l2, final_estimator__solver=liblinear;, score=0.866 total time=40.7min\n",
      "[CV 2/5] END final_estimator__C=0.1, final_estimator__class_weight=balanced, final_estimator__max_iter=200, final_estimator__penalty=l2, final_estimator__solver=lbfgs;, score=0.876 total time=40.8min\n",
      "[CV 1/5] END final_estimator__C=0.1, final_estimator__class_weight=balanced, final_estimator__max_iter=200, final_estimator__penalty=l2, final_estimator__solver=lbfgs;, score=0.882 total time=40.9min\n",
      "[CV 3/5] END final_estimator__C=0.1, final_estimator__class_weight=balanced, final_estimator__max_iter=200, final_estimator__penalty=l2, final_estimator__solver=lbfgs;, score=0.875 total time=40.8min\n",
      "[CV 4/5] END final_estimator__C=0.1, final_estimator__class_weight=balanced, final_estimator__max_iter=200, final_estimator__penalty=l2, final_estimator__solver=lbfgs;, score=0.889 total time=40.9min\n",
      "[CV 1/5] END final_estimator__C=1, final_estimator__class_weight=balanced, final_estimator__max_iter=100, final_estimator__penalty=l1, final_estimator__solver=lbfgs;, score=nan total time=40.9min\n",
      "[CV 5/5] END final_estimator__C=0.1, final_estimator__class_weight=balanced, final_estimator__max_iter=200, final_estimator__penalty=l2, final_estimator__solver=lbfgs;, score=0.867 total time=41.0min\n",
      "[CV 2/5] END final_estimator__C=1, final_estimator__class_weight=balanced, final_estimator__max_iter=100, final_estimator__penalty=l1, final_estimator__solver=lbfgs;, score=nan total time=41.0min\n",
      "[CV 3/5] END final_estimator__C=1, final_estimator__class_weight=balanced, final_estimator__max_iter=100, final_estimator__penalty=l1, final_estimator__solver=lbfgs;, score=nan total time=30.1min\n",
      "[CV 4/5] END final_estimator__C=1, final_estimator__class_weight=balanced, final_estimator__max_iter=100, final_estimator__penalty=l1, final_estimator__solver=lbfgs;, score=nan total time=30.0min\n",
      "[CV 5/5] END final_estimator__C=1, final_estimator__class_weight=balanced, final_estimator__max_iter=100, final_estimator__penalty=l1, final_estimator__solver=lbfgs;, score=nan total time=30.0min\n",
      "[CV 1/5] END final_estimator__C=1, final_estimator__class_weight=None, final_estimator__max_iter=200, final_estimator__penalty=l1, final_estimator__solver=lbfgs;, score=nan total time=30.0min\n",
      "[CV 2/5] END final_estimator__C=1, final_estimator__class_weight=None, final_estimator__max_iter=200, final_estimator__penalty=l1, final_estimator__solver=lbfgs;, score=nan total time=30.0min\n",
      "[CV 3/5] END final_estimator__C=1, final_estimator__class_weight=None, final_estimator__max_iter=200, final_estimator__penalty=l1, final_estimator__solver=lbfgs;, score=nan total time=30.1min\n",
      "[CV 4/5] END final_estimator__C=1, final_estimator__class_weight=None, final_estimator__max_iter=200, final_estimator__penalty=l1, final_estimator__solver=lbfgs;, score=nan total time=30.1min\n",
      "[CV 5/5] END final_estimator__C=1, final_estimator__class_weight=None, final_estimator__max_iter=200, final_estimator__penalty=l1, final_estimator__solver=lbfgs;, score=nan total time=29.8min\n",
      "[CV 1/5] END final_estimator__C=0.01, final_estimator__class_weight=balanced, final_estimator__max_iter=200, final_estimator__penalty=l2, final_estimator__solver=liblinear;, score=0.885 total time=28.7min\n",
      "[CV 2/5] END final_estimator__C=0.01, final_estimator__class_weight=balanced, final_estimator__max_iter=200, final_estimator__penalty=l2, final_estimator__solver=liblinear;, score=0.873 total time=28.8min\n",
      "[CV 5/5] END final_estimator__C=0.01, final_estimator__class_weight=balanced, final_estimator__max_iter=200, final_estimator__penalty=l2, final_estimator__solver=liblinear;, score=0.869 total time=28.7min\n",
      "[CV 4/5] END final_estimator__C=0.01, final_estimator__class_weight=balanced, final_estimator__max_iter=200, final_estimator__penalty=l2, final_estimator__solver=liblinear;, score=0.889 total time=28.8min\n",
      "[CV 3/5] END final_estimator__C=0.01, final_estimator__class_weight=balanced, final_estimator__max_iter=200, final_estimator__penalty=l2, final_estimator__solver=liblinear;, score=0.869 total time=28.9min\n",
      "[CV 1/5] END final_estimator__C=100, final_estimator__class_weight=None, final_estimator__max_iter=200, final_estimator__penalty=l1, final_estimator__solver=lbfgs;, score=nan total time=28.5min\n",
      "[CV 3/5] END final_estimator__C=100, final_estimator__class_weight=None, final_estimator__max_iter=200, final_estimator__penalty=l1, final_estimator__solver=lbfgs;, score=nan total time=28.4min\n",
      "[CV 2/5] END final_estimator__C=100, final_estimator__class_weight=None, final_estimator__max_iter=200, final_estimator__penalty=l1, final_estimator__solver=lbfgs;, score=nan total time=28.8min\n",
      "[CV 4/5] END final_estimator__C=100, final_estimator__class_weight=None, final_estimator__max_iter=200, final_estimator__penalty=l1, final_estimator__solver=lbfgs;, score=nan total time=17.3min\n",
      "[CV 5/5] END final_estimator__C=100, final_estimator__class_weight=None, final_estimator__max_iter=200, final_estimator__penalty=l1, final_estimator__solver=lbfgs;, score=nan total time=17.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "20 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/ensemble/_stacking.py\", line 672, in fit\n",
      "    return super().fit(X, y_encoded, sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/ensemble/_stacking.py\", line 288, in fit\n",
      "    _fit_single_estimator(self.final_estimator_, X_meta, y, fit_params=fit_params)\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/ensemble/_base.py\", line 40, in _fit_single_estimator\n",
      "    estimator.fit(X, y, **fit_params)\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.87727273 0.87736364        nan 0.87772727 0.87763636 0.87754545\n",
      "        nan        nan 0.877             nan]\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   11.5s remaining:   17.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   13.6s finished\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   49.0s remaining:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   50.2s finished\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  4.6min remaining:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  4.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier Accuracy: 0.677\n",
      "Best Hyperparameters: {'final_estimator__solver': 'lbfgs', 'final_estimator__penalty': 'l2', 'final_estimator__max_iter': 100, 'final_estimator__class_weight': 'balanced', 'final_estimator__C': 10}\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameter grid for the final estimator\n",
    "param_grid = {\n",
    "    'final_estimator__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'final_estimator__penalty': ['l2', 'l1'],\n",
    "    'final_estimator__solver': ['lbfgs', 'liblinear'],\n",
    "    'final_estimator__max_iter': [100, 200, 300],\n",
    "    'final_estimator__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "best_stacking = RandomizedSearchCV(\n",
    "    estimator=stacking_clf,\n",
    "    param_distributions=param_grid,\n",
    "    cv=cv,\n",
    "    scoring='accuracy',\n",
    "    verbose=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "best_stacking.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "pred = best_stacking.best_estimator_.predict(X_test)\n",
    "\n",
    "# Evaluate the performance\n",
    "print(\"Stacking Classifier Accuracy:\", accuracy_score(y_test, pred))\n",
    "print(\"Best Hyperparameters:\", best_stacking.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline5 = Pipeline([\n",
    "    ('preprocessing', FunctionTransformer(transform_test)),\n",
    "    ('scaler', scaler),\n",
    "    ('pca', pca),\n",
    "    ('stacking', stacking_clf2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_model3.joblib']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pipeline5, 'best_model3.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, joblib.load('model.joblib').predict(test_data['data'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('model.joblib')\n",
    "model.score(test_data['data'], y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "com6018",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
