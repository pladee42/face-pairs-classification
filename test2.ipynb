{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image, ImageEnhance, ImageOps, ImageFilter\n",
    "from IPython.display import display\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [1, 2, 3]\n",
    "int(sum(t) / len(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_test(X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Transform the testing data into the format expected by the model.\n",
    "    (No augmentation)\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): The images data.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Flattened transformed data.\n",
    "    \"\"\"\n",
    "    X = X.reshape(-1, 2, 62, 47)\n",
    "    X = np.concatenate((X[:, 0], X[:, 1]), axis=2)\n",
    "    X = X.reshape(X.shape[0], -1)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (2200, 5828), Test data shape: (1000, 5828)\n"
     ]
    }
   ],
   "source": [
    "data = joblib.load(\"train.joblib\")\n",
    "test_data = joblib.load(open(\"data/eval1.joblib\", \"rb\"))\n",
    "print(f\"Training data shape: {data['data'].shape}, Test data shape: {test_data['data'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.698\n",
      "[[357 143]\n",
      " [159 341]]\n"
     ]
    }
   ],
   "source": [
    "model = joblib.load(\"best_model2.joblib\")\n",
    "pred = model.predict(test_data['data'])\n",
    "print(accuracy_score(test_data['target'], pred))\n",
    "print(confusion_matrix(test_data['target'], pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   4,  14,  23,  24,  25,  33,  41,  44,  45,  48,\n",
       "        50,  52,  54,  58,  59,  60,  63,  71,  72,  73,  77,  79,  80,\n",
       "        81,  88,  90,  95,  96, 101, 102, 105, 109, 110, 113, 119, 121,\n",
       "       122, 126, 127, 132, 133, 134, 135, 136, 140, 144, 147, 153, 154,\n",
       "       155, 157, 162, 164, 168, 169, 174, 177, 181, 182, 183, 184, 188,\n",
       "       190, 204, 206, 207, 208, 213, 214, 217, 219, 221, 222, 224, 231,\n",
       "       232, 233, 253, 254, 255, 261, 262, 263, 269, 271, 272, 276, 277,\n",
       "       278, 280, 285, 292, 301, 305, 306, 307, 308, 309, 312, 316, 318,\n",
       "       330, 334, 335, 339, 340, 356, 359, 362, 363, 366, 371, 372, 375,\n",
       "       377, 378, 396, 397, 399, 402, 405, 408, 410, 412, 417, 418, 420,\n",
       "       421, 425, 428, 429, 431, 433, 434, 437, 438, 441, 443, 444, 446,\n",
       "       450, 455, 456, 458, 459, 460, 464, 465, 469, 470, 472, 473, 478,\n",
       "       480, 488, 499, 511, 514, 516, 518, 525, 526, 528, 529, 533, 538,\n",
       "       539, 540, 541, 542, 547, 556, 559, 561, 570, 575, 577, 579, 582,\n",
       "       613, 615, 616, 622, 629, 631, 633, 646, 651, 653, 660, 665, 666,\n",
       "       670, 675, 680, 681, 682, 689, 698, 702, 704, 707, 709, 712, 714,\n",
       "       715, 724, 727, 728, 733, 745, 754, 756, 757, 758, 760, 764, 769,\n",
       "       776, 779, 781, 782, 786, 787, 789, 792, 794, 799, 800, 808, 809,\n",
       "       810, 815, 817, 820, 823, 827, 829, 830, 833, 835, 836, 837, 840,\n",
       "       842, 849, 850, 851, 856, 857, 861, 862, 870, 872, 873, 878, 879,\n",
       "       883, 884, 886, 889, 895, 898, 912, 914, 915, 922, 924, 925, 927,\n",
       "       930, 934, 935, 936, 938, 940, 941, 942, 943, 950, 952, 953, 954,\n",
       "       955, 959, 963, 965, 967, 969, 971, 972, 977, 978, 979, 986, 988,\n",
       "       993, 995, 996])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_indices = np.where(test_data['target'] != pred)[0]\n",
    "incorrect_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def false_predict(i):\n",
    "    X = test_data['data'][i]\n",
    "    X = X.reshape(2, 62, 47)\n",
    "    X = np.concatenate((X[0, :], X[1, :]), axis=1)\n",
    "    X = X * 255\n",
    "    plt.title(f'Predict: {pred[i]} / True: {test_data['target'][i]}')\n",
    "    plt.imshow(X)\n",
    "    plt.show()\n",
    "\n",
    "false_predict(986)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2200, 50)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = data['data']\n",
    "pca = PCA(n_components=50)\n",
    "train = pca.fit_transform(train)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 50)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test_data['data']\n",
    "test = pca.transform(test)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "    ('pca', pca),\n",
    "    ('model', model)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = data['data'][:, :2914]\n",
    "image2 = data['data'][:, 2914:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2200, 2914)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = np.abs(image1 - image2)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_augmentation4(X, y, augmentation_ratio=0.5):\n",
    "    augmented_images = list(X)  # Start with original images\n",
    "    augmented_labels = list(y)  # Start with original labels\n",
    "\n",
    "    # Determine the number of images to augment based on augmentation_ratio\n",
    "    total_images = len(X)\n",
    "    num_augment = int(augmentation_ratio * total_images)\n",
    "\n",
    "    for i in range(8):  # 6 augmentation types\n",
    "        augment_indices = np.random.choice(total_images, size=num_augment, replace=False)\n",
    "        \n",
    "        for image_idx in augment_indices:\n",
    "            original_image = X[image_idx]\n",
    "            label = y[image_idx]\n",
    "            \n",
    "            # Apply specific augmentation logic\n",
    "            if i == 0:  # Horizontal flip\n",
    "                augmented_image = original_image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            elif i == 1:  # Brightness adjustment\n",
    "                augmented_image = ImageEnhance.Brightness(original_image.convert('L')).enhance(np.random.uniform(0.7, 1.5))\n",
    "            elif i == 2:  # Contrast adjustment\n",
    "                augmented_image = ImageEnhance.Contrast(original_image.convert('L')).enhance(np.random.uniform(0.5, 2))\n",
    "            elif i == 3:  # Sharpness adjustment\n",
    "                augmented_image = ImageEnhance.Sharpness(original_image.convert('L')).enhance(np.random.uniform(0.5, 2))\n",
    "            elif i == 4:  # Edge detection\n",
    "                augmented_image = original_image.convert('L').filter(ImageFilter.FIND_EDGES)\n",
    "            elif i == 5:  # Gaussian blur\n",
    "                augmented_image = original_image.convert('L').filter(ImageFilter.GaussianBlur(np.random.uniform(0.7, 1)))\n",
    "            elif i == 6:\n",
    "                augmented_image = original_image.convert('L').filter(ImageFilter.EDGE_ENHANCE_MORE)\n",
    "            elif i == 7:\n",
    "                augmented_image = original_image.convert('L').filter(ImageFilter.CONTOUR)\n",
    "                \n",
    "            \n",
    "\n",
    "            # Add augmented image and label to the dataset\n",
    "            augmented_images.append(augmented_image)\n",
    "            augmented_labels.append(label)\n",
    "    \n",
    "    # Normalize the images and convert labels to numpy arrays\n",
    "    X = np.array([np.array(img) / 255 for img in augmented_images])  # Normalize images\n",
    "    y = np.array(augmented_labels)\n",
    "    \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8800, 150) (8800,)\n",
      "(1000, 150) (1000,)\n"
     ]
    }
   ],
   "source": [
    "def numpy_to_pil(images_array):\n",
    "    pil_images = []\n",
    "    for i in range(images_array.shape[0]):\n",
    "        img = Image.fromarray(images_array[i] * 255, mode='F')\n",
    "        pil_images.append(img)\n",
    "    return pil_images\n",
    "\n",
    "def preprocessing(X_train, y_train, augmentation_ratio=0.5):\n",
    "    X1, X2 = X_train[:, :X_train.shape[1]//2], X_train[:, X_train.shape[1]//2:]\n",
    "    X1, X2 = numpy_to_pil(X1), numpy_to_pil(X2)\n",
    "    X1, y = image_augmentation4(X1, y_train, augmentation_ratio)\n",
    "    X2, _ = image_augmentation4(X2, y_train, augmentation_ratio)\n",
    "    X1, X2 = X1.reshape(X1.shape[0], -1), X2.reshape(X2.shape[0], -1)\n",
    "    X = np.abs(X1 - X2)\n",
    "    return X, y\n",
    "\n",
    "def preprocessing_test(X):\n",
    "    X1, X2 = X[:, :X.shape[1]//2], X[:, X.shape[1]//2:]\n",
    "    X = np.abs(X1 - X2)\n",
    "    return X\n",
    "\n",
    "\n",
    "X_train, y_train = preprocessing(data['data'], data['target'])\n",
    "X_test = preprocessing_test(test_data['data'])\n",
    "y_test = test_data['target']\n",
    "\n",
    "pca = PCA(n_components=150, random_state=101)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3300, 150) (3300,)\n",
      "(1000, 150) (1000,)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import numpy as np\n",
    "\n",
    "def horizontal_flip(img):\n",
    "    return img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "def random_brightness(img, brightness_range=(0.7, 1.5)):\n",
    "    img = img.convert('L')\n",
    "    factor = np.random.uniform(*brightness_range)\n",
    "    return ImageEnhance.Brightness(img).enhance(factor)\n",
    "\n",
    "def random_contrast(img, contrast_range=(0.5, 2.0)):\n",
    "    img = img.convert('L')\n",
    "    factor = np.random.uniform(*contrast_range)\n",
    "    return ImageEnhance.Contrast(img).enhance(factor)\n",
    "\n",
    "def random_sharpness(img, sharpness_range=(0.5, 2.0)):\n",
    "    img = img.convert('L')\n",
    "    factor = np.random.uniform(*sharpness_range)\n",
    "    return ImageEnhance.Sharpness(img).enhance(factor)\n",
    "\n",
    "def gaussian_blur(img, blur_range=(0.7, 1.0)):\n",
    "    img = img.convert('L')\n",
    "    radius = np.random.uniform(*blur_range)\n",
    "    return img.filter(ImageFilter.GaussianBlur(radius))\n",
    "\n",
    "def edge_detection(img):\n",
    "    img = img.convert('L')\n",
    "    return img.filter(ImageFilter.FIND_EDGES)\n",
    "\n",
    "def edge_enhance_more(img):\n",
    "    img = img.convert('L')\n",
    "    return img.filter(ImageFilter.EDGE_ENHANCE_MORE)\n",
    "\n",
    "def contour_filter(img):\n",
    "    img = img.convert('L')\n",
    "    return img.filter(ImageFilter.CONTOUR)\n",
    "\n",
    "# Define a list or dictionary of augmentations and their probabilities.\n",
    "AUGMENTATIONS = [\n",
    "    (horizontal_flip, 0.3),       # 30% chance to flip\n",
    "    (random_brightness, 0.2),     # 20% chance to adjust brightness\n",
    "    (random_contrast, 0.2),       # and so on...\n",
    "    (random_sharpness, 0.2),\n",
    "    (gaussian_blur, 0.1),\n",
    "    (edge_detection, 0.05),\n",
    "    (edge_enhance_more, 0.05),\n",
    "    (contour_filter, 0.05),\n",
    "]\n",
    "\n",
    "def augment_image(img):\n",
    "    # Decide which augmentations to apply randomly\n",
    "    for aug_func, aug_prob in AUGMENTATIONS:\n",
    "        if np.random.rand() < aug_prob:\n",
    "            img = aug_func(img)\n",
    "    return img\n",
    "\n",
    "def image_augmentation(X, y, augmentation_ratio=0.5, max_aug_per_image=1):\n",
    "    \"\"\"\n",
    "    A more flexible augmentation:\n",
    "    - augmentation_ratio: fraction of images for which we generate augmented versions.\n",
    "    - max_aug_per_image: how many augmented variants you want per original image (can be > 1).\n",
    "    \"\"\"\n",
    "    augmented_images = []\n",
    "    augmented_labels = []\n",
    "    \n",
    "    total_images = len(X)\n",
    "    num_to_augment = int(augmentation_ratio * total_images)\n",
    "\n",
    "    # Randomly pick images to augment\n",
    "    indices_to_augment = np.random.choice(total_images, size=num_to_augment, replace=False)\n",
    "    \n",
    "    # Add original images\n",
    "    augmented_images.extend(X)\n",
    "    augmented_labels.extend(y)\n",
    "\n",
    "    for idx in indices_to_augment:\n",
    "        for _ in range(max_aug_per_image):\n",
    "            aug_img = augment_image(X[idx])\n",
    "            augmented_images.append(aug_img)\n",
    "            augmented_labels.append(y[idx])\n",
    "            \n",
    "    # Convert to arrays and normalize\n",
    "    X_out = np.array([np.array(img, dtype=np.float32) / 255.0 for img in augmented_images])\n",
    "    y_out = np.array(augmented_labels)\n",
    "    return X_out, y_out\n",
    "\n",
    "def numpy_to_pil(images_array):\n",
    "    pil_images = []\n",
    "    for i in range(images_array.shape[0]):\n",
    "        img = Image.fromarray((images_array[i] * 255).astype('float32'), mode='F')\n",
    "        pil_images.append(img)\n",
    "    return pil_images\n",
    "\n",
    "def preprocessing(X_train, y_train, augmentation_ratio=0.5):\n",
    "    half = X_train.shape[1] // 2\n",
    "    X1, X2 = X_train[:, :half], X_train[:, half:]\n",
    "    X1, X2 = numpy_to_pil(X1), numpy_to_pil(X2)\n",
    "\n",
    "    # Apply augmentation\n",
    "    X1_aug, y = image_augmentation(X1, y_train, augmentation_ratio=augmentation_ratio, max_aug_per_image=1)\n",
    "    X2_aug, _ = image_augmentation(X2, y_train, augmentation_ratio=augmentation_ratio, max_aug_per_image=1)\n",
    "\n",
    "    # Reshape to vectors and compute difference\n",
    "    X1_aug = X1_aug.reshape(X1_aug.shape[0], -1)\n",
    "    X2_aug = X2_aug.reshape(X2_aug.shape[0], -1)\n",
    "\n",
    "    X = np.abs(X1_aug - X2_aug)\n",
    "    return X, y\n",
    "\n",
    "def preprocessing_test(X):\n",
    "    half = X.shape[1] // 2\n",
    "    X1, X2 = X[:, :half], X[:, half:]\n",
    "    X = np.abs(X1 - X2)\n",
    "    return X\n",
    "\n",
    "X_train, y_train = preprocessing(data['data'], data['target'])\n",
    "X_test = preprocessing_test(test_data['data'])\n",
    "y_test = test_data['target']\n",
    "\n",
    "pca = PCA(n_components=150, random_state=101)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.583\n",
      "0.641\n",
      "0.662\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "pred = knn.fit(X_train,y_train).predict(X_test)\n",
    "print(accuracy_score(y_test, pred))\n",
    "\n",
    "rf = RandomForestClassifier(random_state = 101)\n",
    "pred = rf.fit(X_train,y_train).predict(X_test)\n",
    "print(accuracy_score(y_test, pred))\n",
    "\n",
    "svc = SVC(probability = True, kernel='rbf', random_state=101)\n",
    "pred = svc.fit(X_train,y_train).predict(X_test)\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.639\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(150, 100, 50), solver='adam', max_iter=1000, activation='relu', early_stopping=True, random_state=101)\n",
    "pred = mlp.fit(X_train,y_train).predict(X_test)\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.588\n",
      "{'solver': 'adam', 'max_iter': 1000, 'learning_rate_init': 0.01, 'hidden_layer_sizes': (150, 100, 50), 'early_stopping': False, 'alpha': 1e-05, 'activation': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(150, 100, 50)],\n",
    "    'activation': ['relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [1e-5, 1e-4, 1e-3, 1e-2],  # Regularization parameter\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],\n",
    "    'max_iter': [200, 500, 1000],\n",
    "    'early_stopping': [True, False]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=101)\n",
    "\n",
    "best_mlp = RandomizedSearchCV(\n",
    "    MLPClassifier(random_state=101),\n",
    "    param_distributions=param_grid,\n",
    "    refit=True,\n",
    "    cv=cv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "best_mlp.fit(X_train, y_train)\n",
    "pred = best_mlp.best_estimator_.predict(X_test)\n",
    "print(f\"{accuracy_score(y_test, pred)}\")\n",
    "print(f\"{best_mlp.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.826, test=0.625) total time=   4.3s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.824, test=0.666) total time=   4.3s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.808, test=0.602) total time=   4.3s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.819, test=0.634) total time=   4.4s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.005, loss=deviance, max_depth=3, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.005, loss=deviance, max_depth=3, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.005, loss=deviance, max_depth=3, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=deviance, max_depth=3, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.005, loss=deviance, max_depth=3, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.823, test=0.634) total time=   4.4s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.970, test=0.630) total time=  12.2s\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.974, test=0.611) total time=  12.2s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.969, test=0.648) total time=  12.4s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=0.788, test=0.659) total time=   2.5s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=0.786, test=0.591) total time=   2.5s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.6;, score=(train=0.924, test=0.611) total time=  22.1s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.6;, score=(train=0.939, test=0.623) total time=  22.4s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.6;, score=(train=0.936, test=0.675) total time=  22.6s\n",
      "[CV 1/5] END learning_rate=0.005, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.005, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.005, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.005, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.005, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.005, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.005, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.005, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=0.795, test=0.602) total time=   2.4s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=0.770, test=0.618) total time=   2.5s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=0.789, test=0.625) total time=   2.4s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.6;, score=(train=0.931, test=0.650) total time=  22.3s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.6;, score=(train=0.936, test=0.614) total time=  22.3s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.970, test=0.623) total time=  11.8s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.974, test=0.650) total time=  12.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.956, test=0.673) total time=  12.6s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.945, test=0.625) total time=  12.8s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.960, test=0.623) total time=  12.5s\n",
      "[CV 1/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.949, test=0.639) total time=  13.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.7;, score=(train=0.951, test=0.675) total time=  12.4s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.959, test=0.632) total time=  12.7s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.7;, score=(train=0.942, test=0.639) total time=  12.6s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.7;, score=(train=0.953, test=0.611) total time=  12.5s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.963, test=0.661) total time=   4.5s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.7;, score=(train=0.945, test=0.641) total time=  12.6s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.7;, score=(train=0.952, test=0.643) total time=  12.6s\n",
      "[CV 2/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.953, test=0.630) total time=   4.6s\n",
      "[CV 3/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.963, test=0.614) total time=   4.7s\n",
      "[CV 4/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.956, test=0.636) total time=   4.6s\n",
      "[CV 5/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.963, test=0.632) total time=   4.6s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.8;, score=(train=1.000, test=0.659) total time=  22.3s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.8;, score=(train=1.000, test=0.614) total time=  22.3s\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.8;, score=(train=0.999, test=0.630) total time=  22.4s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.8;, score=(train=1.000, test=0.650) total time=  22.3s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.8;, score=(train=0.999, test=0.627) total time=  22.5s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.6;, score=(train=0.936, test=0.680) total time=  17.1s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.6;, score=(train=0.934, test=0.623) total time=  17.3s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.6;, score=(train=0.947, test=0.625) total time=  17.2s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1000, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, loss=deviance, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.6;, score=(train=0.940, test=0.648) total time=  16.5s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.6;, score=(train=0.941, test=0.632) total time=  16.5s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=750, subsample=0.7;, score=(train=0.913, test=0.670) total time=  16.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=750, subsample=0.7;, score=(train=0.905, test=0.618) total time=  16.3s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=750, subsample=0.7;, score=(train=0.918, test=0.632) total time=  16.1s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=deviance, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=deviance, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=deviance, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=deviance, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=deviance, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=750, subsample=0.7;, score=(train=0.914, test=0.634) total time=  15.7s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=750, subsample=0.7;, score=(train=0.970, test=0.668) total time=  14.6s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=750, subsample=0.7;, score=(train=0.913, test=0.623) total time=  15.9s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=750, subsample=0.7;, score=(train=0.951, test=0.661) total time=   8.3s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=750, subsample=0.7;, score=(train=0.961, test=0.630) total time=  14.6s\n",
      "[CV 1/5] END learning_rate=0.005, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.005, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.005, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.005, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=750, subsample=0.7;, score=(train=0.969, test=0.625) total time=  14.7s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=750, subsample=0.7;, score=(train=0.965, test=0.634) total time=  14.7s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=750, subsample=0.7;, score=(train=0.971, test=0.639) total time=  14.8s\n",
      "[CV 1/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.9;, score=(train=0.942, test=0.625) total time=   2.3s\n",
      "[CV 2/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.9;, score=(train=0.939, test=0.630) total time=   2.2s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=750, subsample=0.7;, score=(train=0.952, test=0.627) total time=   8.5s\n",
      "[CV 3/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.9;, score=(train=0.945, test=0.627) total time=   2.2s\n",
      "[CV 4/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.9;, score=(train=0.947, test=0.618) total time=   2.2s\n",
      "[CV 5/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.9;, score=(train=0.946, test=0.636) total time=   2.2s\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=750, subsample=0.7;, score=(train=0.953, test=0.614) total time=   8.7s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=750, subsample=0.7;, score=(train=0.950, test=0.625) total time=   8.5s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=750, subsample=0.7;, score=(train=0.957, test=0.641) total time=   8.6s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250, subsample=0.9;, score=(train=0.966, test=0.664) total time=   9.9s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250, subsample=0.9;, score=(train=0.952, test=0.618) total time=   9.8s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250, subsample=0.9;, score=(train=0.966, test=0.632) total time=   9.6s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250, subsample=0.9;, score=(train=0.956, test=0.618) total time=   9.6s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=250, subsample=0.9;, score=(train=0.963, test=0.614) total time=   9.9s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.7;, score=(train=0.907, test=0.677) total time=  22.0s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.7;, score=(train=0.902, test=0.614) total time=  21.9s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.7;, score=(train=0.911, test=0.636) total time=  21.4s\n",
      "[CV 1/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=250, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=250, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=250, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=250, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=250, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.7;, score=(train=0.918, test=0.623) total time=  22.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.7;, score=(train=0.912, test=0.639) total time=  22.1s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=0.774, test=0.677) total time=  17.3s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=0.960, test=0.670) total time=  12.6s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=0.951, test=0.614) total time=  12.7s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=500, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=0.961, test=0.630) total time=  12.4s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=0.765, test=0.593) total time=  17.3s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.864, test=0.666) total time=   3.5s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.832, test=0.607) total time=   3.4s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=0.767, test=0.627) total time=  17.2s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=0.765, test=0.600) total time=  17.1s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=0.774, test=0.620) total time=  17.4s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=0.954, test=0.641) total time=  12.1s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.859, test=0.623) total time=   3.5s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.856, test=0.632) total time=   3.5s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.814, test=0.605) total time=   5.2s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.855, test=0.614) total time=   3.5s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.826, test=0.634) total time=   5.4s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=0.9;, score=(train=0.960, test=0.618) total time=  12.1s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.909, test=0.659) total time=   6.2s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.826, test=0.630) total time=   5.4s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=deviance, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=deviance, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=deviance, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=deviance, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=deviance, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.749, test=0.650) total time=   1.2s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.757, test=0.605) total time=   1.2s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.910, test=0.602) total time=   6.3s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.822, test=0.634) total time=   5.5s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.766, test=0.641) total time=   1.2s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.745, test=0.630) total time=   1.2s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.903, test=0.627) total time=   6.5s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.900, test=0.627) total time=   6.6s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.769, test=0.627) total time=   1.3s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.8;, score=(train=0.905, test=0.627) total time=  18.2s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.8;, score=(train=0.903, test=0.632) total time=  18.3s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.8;, score=(train=0.903, test=0.684) total time=  18.5s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.6;, score=(train=0.901, test=0.639) total time=   6.6s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.9;, score=(train=0.839, test=0.668) total time=   5.8s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=0.962, test=0.680) total time=  10.3s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.8;, score=(train=0.895, test=0.614) total time=  18.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=0.8;, score=(train=0.905, test=0.623) total time=  18.6s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=750, subsample=1.0;, score=(train=0.991, test=0.652) total time=  22.4s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=750, subsample=1.0;, score=(train=0.989, test=0.616) total time=  22.5s\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=750, subsample=1.0;, score=(train=0.993, test=0.620) total time=  22.6s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=750, subsample=1.0;, score=(train=0.988, test=0.618) total time=  22.5s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=750, subsample=1.0;, score=(train=0.993, test=0.657) total time=  22.8s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=0.953, test=0.616) total time=  10.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=0.961, test=0.618) total time=  10.0s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.943, test=0.668) total time=   9.5s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=0.952, test=0.636) total time=   9.7s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500, subsample=0.7;, score=(train=0.962, test=0.630) total time=   9.8s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.935, test=0.611) total time=   9.2s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.942, test=0.611) total time=   9.6s\n",
      "[CV 1/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=deviance, max_depth=3, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.939, test=0.645) total time=   9.5s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=0.947, test=0.634) total time=   9.3s\n",
      "[CV 1/5] END learning_rate=0.005, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.977, test=0.664) total time=   7.8s\n",
      "[CV 2/5] END learning_rate=0.005, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.974, test=0.611) total time=   7.9s\n",
      "[CV 3/5] END learning_rate=0.005, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.977, test=0.645) total time=   8.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.975, test=0.616) total time=   7.9s\n",
      "[CV 5/5] END learning_rate=0.005, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=0.979, test=0.614) total time=   8.1s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.9;, score=(train=0.803, test=0.668) total time=  10.4s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.9;, score=(train=0.775, test=0.600) total time=  10.8s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.9;, score=(train=0.790, test=0.627) total time=  10.3s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.9;, score=(train=0.785, test=0.614) total time=  10.7s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.9;, score=(train=0.785, test=0.636) total time=  10.8s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.903, test=0.641) total time=   1.3s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.888, test=0.602) total time=   1.2s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.883, test=0.620) total time=   1.3s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.895, test=0.634) total time=   1.2s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.896, test=0.602) total time=   1.3s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=1.0;, score=(train=0.912, test=0.670) total time=  14.1s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=1.0;, score=(train=0.904, test=0.609) total time=  14.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=1.0;, score=(train=0.923, test=0.620) total time=  13.9s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=deviance, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=deviance, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=deviance, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=deviance, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=deviance, max_depth=7, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=deviance, max_depth=4, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=1.0;, score=(train=0.917, test=0.645) total time=  13.8s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=750, subsample=1.0;, score=(train=0.920, test=0.607) total time=  14.2s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.9;, score=(train=0.874, test=0.664) total time=  10.8s\n",
      "[CV 1/5] END learning_rate=0.005, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.005, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.005, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.005, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.9;, score=(train=0.855, test=0.605) total time=  10.7s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.9;, score=(train=0.876, test=0.605) total time=  10.9s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.9;, score=(train=0.878, test=0.630) total time=  10.9s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=4, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.9;, score=(train=0.868, test=0.607) total time=  11.0s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.970, test=0.655) total time=   2.7s\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.965, test=0.623) total time=   2.7s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=0.894, test=0.673) total time=  14.5s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.8;, score=(train=0.891, test=0.668) total time=   7.3s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=250, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=exponential, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=deviance, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=deviance, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=deviance, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=deviance, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=deviance, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=deviance, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=deviance, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=deviance, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=deviance, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=deviance, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, loss=deviance, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, loss=deviance, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, loss=deviance, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, loss=deviance, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, loss=deviance, max_depth=7, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.8;, score=(train=0.874, test=0.620) total time=   7.4s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.952, test=0.627) total time=   2.7s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.960, test=0.627) total time=   2.7s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.8;, score=(train=0.879, test=0.620) total time=   7.4s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=0.889, test=0.616) total time=  14.3s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=7, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=0.965, test=0.650) total time=   2.6s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=1000, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=1000, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=1000, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=1000, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=deviance, max_depth=5, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=1000, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=0.964, test=0.655) total time=   5.2s\n",
      "[CV 3/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=0.963, test=0.625) total time=   5.2s\n",
      "[CV 5/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=0.960, test=0.641) total time=   5.1s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=4, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.9;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=0.900, test=0.652) total time=  14.3s\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.8;, score=(train=0.883, test=0.609) total time=   7.5s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.853, test=0.652) total time=   5.8s\n",
      "[CV 1/5] END learning_rate=0.01, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=750, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=7, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.005, loss=deviance, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=1000, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.8;, score=(train=0.784, test=0.657) total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.8;, score=(train=0.884, test=0.632) total time=   7.4s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.8;, score=(train=0.777, test=0.602) total time=   1.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.8;, score=(train=0.782, test=0.609) total time=   1.0s\n",
      "[CV 2/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=0.950, test=0.614) total time=   5.3s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.8;, score=(train=0.772, test=0.618) total time=   0.9s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=3, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100, subsample=0.8;, score=(train=0.777, test=0.625) total time=   1.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=exponential, max_depth=6, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=250, subsample=0.9;, score=(train=0.955, test=0.623) total time=   5.3s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.837, test=0.630) total time=   6.0s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.845, test=0.632) total time=   6.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=0.903, test=0.641) total time=  14.7s\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.841, test=0.602) total time=   6.3s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, max_depth=3, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.843, test=0.636) total time=   6.3s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=0.6;, score=(train=0.898, test=0.630) total time=  15.0s\n",
      "[CV 1/5] END learning_rate=0.005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.8;, score=(train=0.947, test=0.666) total time=  13.2s\n",
      "[CV 2/5] END learning_rate=0.005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.8;, score=(train=0.940, test=0.623) total time=  13.1s\n",
      "[CV 3/5] END learning_rate=0.005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.8;, score=(train=0.948, test=0.620) total time=  13.1s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100, subsample=0.6;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=3, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=750, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.005, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.005, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.005, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.005, loss=deviance, max_depth=6, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0001, loss=exponential, max_depth=5, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=1000, subsample=1.0;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.8;, score=(train=0.949, test=0.620) total time=  13.2s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.837, test=0.668) total time=   8.2s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.821, test=0.609) total time=   8.2s\n",
      "[CV 5/5] END learning_rate=0.005, loss=exponential, max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500, subsample=0.8;, score=(train=0.949, test=0.645) total time=  13.2s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.832, test=0.623) total time=   8.2s\n",
      "[CV 1/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=deviance, max_depth=7, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=100, subsample=0.7;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.0005, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.832, test=0.636) total time=   7.9s\n",
      "[CV 5/5] END learning_rate=0.0005, loss=exponential, max_depth=4, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500, subsample=0.6;, score=(train=0.835, test=0.625) total time=   8.0s\n",
      "[CV 1/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=0.955, test=0.677) total time=  26.2s\n",
      "[CV 2/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=0.944, test=0.623) total time=  26.0s\n",
      "[CV 3/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=0.960, test=0.625) total time=  25.0s\n",
      "[CV 4/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=0.953, test=0.643) total time=  24.5s\n",
      "[CV 5/5] END learning_rate=0.001, loss=exponential, max_depth=6, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1000, subsample=0.8;, score=(train=0.959, test=0.620) total time=  24.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "305 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "67 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of GradientBoostingClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "23 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of GradientBoostingClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "65 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'log_loss', 'exponential'}. Got 'deviance' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "150 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingClassifier must be a str among {'exponential', 'log_loss'}. Got 'deviance' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.63227273        nan        nan 0.63454545        nan        nan\n",
      " 0.63227273 0.61909091        nan        nan 0.63818182        nan\n",
      " 0.64181818        nan 0.63590909        nan 0.63454545 0.64136364\n",
      " 0.63545455        nan        nan        nan        nan 0.63909091\n",
      "        nan 0.63363636        nan 0.62727273 0.63772727 0.62909091\n",
      " 0.62363636        nan        nan 0.63454545        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.62818182\n",
      " 0.63590909 0.63409091 0.63090909        nan        nan        nan\n",
      " 0.63045455 0.63272727        nan 0.63590909 0.63409091 0.63\n",
      "        nan 0.62909091        nan 0.63045455 0.62              nan\n",
      " 0.62181818        nan        nan        nan        nan        nan\n",
      "        nan 0.64227273        nan 0.63       0.63636364        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.63136364        nan        nan 0.63045455\n",
      "        nan        nan        nan        nan 0.62227273 0.635\n",
      "        nan 0.63227273        nan        nan        nan        nan\n",
      "        nan        nan 0.63772727        nan]\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the train scores are non-finite: [0.82              nan        nan 0.93329545        nan        nan\n",
      " 0.97159091 0.78556818        nan        nan 0.95375           nan\n",
      " 0.94840909        nan 0.99965909        nan 0.95943182 0.93954545\n",
      " 0.91261364        nan        nan        nan        nan 0.96727273\n",
      "        nan 0.95272727        nan 0.94363636 0.91022727 0.96045455\n",
      " 0.76897727        nan        nan 0.95715909        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.85318182\n",
      " 0.90215909 0.82545455 0.90443182        nan        nan        nan\n",
      " 0.75715909 0.99068182        nan 0.95795455 0.94090909 0.97659091\n",
      "        nan 0.78738636        nan 0.91545455 0.89306818        nan\n",
      " 0.87022727        nan        nan        nan        nan        nan\n",
      "        nan 0.89681818        nan 0.88227273 0.96238636        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.95829545        nan        nan 0.84363636\n",
      "        nan        nan        nan        nan 0.77852273 0.94670455\n",
      "        nan 0.83136364        nan        nan        nan        nan\n",
      "        nan        nan 0.95409091        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier Accuracy: 0.655\n",
      "Best Parameters: {'subsample': 0.6, 'n_estimators': 750, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 5, 'loss': 'exponential', 'learning_rate': 0.0005}\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=101)\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [1e-4, 5e-4, 1e-3, 5e-3, 1e-2],\n",
    "    'n_estimators': [100, 250, 500, 750, 1000],\n",
    "    'max_depth': [3, 4, 5, 6, 7],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'loss': ['deviance', 'exponential']  # 'deviance' is equivalent to logistic regression\n",
    "}\n",
    "# Initialize the GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier(random_state=101)\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "best_gbc = RandomizedSearchCV(\n",
    "    estimator=gbc,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=100,  # Number of parameter settings sampled\n",
    "    cv=cv,\n",
    "    scoring='accuracy',\n",
    "    verbose=3,\n",
    "    random_state=101,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True  # To analyze training vs. validation scores\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "best_gbc.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "pred_gbc = best_gbc.best_estimator_.predict(X_test)\n",
    "print(\"Gradient Boosting Classifier Accuracy:\", accuracy_score(y_test, pred_gbc))\n",
    "print(\"Best Parameters:\", best_gbc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/com6018/lib/python3.12/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 20 is smaller than n_iter=50. Running 20 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END C=0.1, gamma=0.1, kernel=rbf;, score=(train=0.759, test=0.639) total time=   4.3s\n",
      "[CV 2/5] END C=0.1, gamma=0.1, kernel=rbf;, score=(train=0.553, test=0.527) total time=   4.3s\n",
      "[CV 1/5] END C=0.1, gamma=1, kernel=rbf;, score=(train=0.503, test=0.486) total time=   4.3s\n",
      "[CV 4/5] END C=0.1, gamma=1, kernel=rbf;, score=(train=0.503, test=0.489) total time=   4.4s\n",
      "[CV 5/5] END C=0.1, gamma=1, kernel=rbf;, score=(train=0.501, test=0.495) total time=   4.4s\n",
      "[CV 3/5] END C=0.1, gamma=1, kernel=rbf;, score=(train=0.503, test=0.489) total time=   4.3s\n",
      "[CV 2/5] END C=0.1, gamma=1, kernel=rbf;, score=(train=0.502, test=0.491) total time=   4.5s\n",
      "[CV 3/5] END C=0.1, gamma=0.1, kernel=rbf;, score=(train=0.641, test=0.607) total time=   4.6s\n",
      "[CV 3/5] END C=0.1, gamma=0.01, kernel=rbf;, score=(train=0.661, test=0.618) total time=   4.2s\n",
      "[CV 2/5] END C=0.1, gamma=0.01, kernel=rbf;, score=(train=0.670, test=0.630) total time=   4.2s\n",
      "[CV 4/5] END C=0.1, gamma=0.01, kernel=rbf;, score=(train=0.663, test=0.639) total time=   4.1s\n",
      "[CV 1/5] END C=0.1, gamma=0.01, kernel=rbf;, score=(train=0.664, test=0.648) total time=   4.2s\n",
      "[CV 5/5] END C=0.1, gamma=0.01, kernel=rbf;, score=(train=0.659, test=0.643) total time=   4.3s\n",
      "[CV 5/5] END C=0.1, gamma=0.1, kernel=rbf;, score=(train=0.546, test=0.536) total time=   4.7s\n",
      "[CV 4/5] END C=0.1, gamma=0.1, kernel=rbf;, score=(train=0.555, test=0.520) total time=   4.8s\n",
      "[CV 1/5] END C=0.1, gamma=0.001, kernel=rbf;, score=(train=0.597, test=0.577) total time=   4.6s\n",
      "[CV 2/5] END C=0.1, gamma=0.001, kernel=rbf;, score=(train=0.604, test=0.605) total time=   4.5s\n",
      "[CV 3/5] END C=0.1, gamma=0.001, kernel=rbf;, score=(train=0.601, test=0.598) total time=   4.7s\n",
      "[CV 4/5] END C=0.1, gamma=0.001, kernel=rbf;, score=(train=0.603, test=0.611) total time=   4.8s\n",
      "[CV 5/5] END C=0.1, gamma=0.001, kernel=rbf;, score=(train=0.607, test=0.584) total time=   4.8s\n",
      "[CV 1/5] END C=0.1, gamma=0.0001, kernel=rbf;, score=(train=0.503, test=0.486) total time=   4.8s\n",
      "[CV 2/5] END C=0.1, gamma=0.0001, kernel=rbf;, score=(train=0.502, test=0.491) total time=   4.7s\n",
      "[CV 3/5] END C=0.1, gamma=0.0001, kernel=rbf;, score=(train=0.503, test=0.489) total time=   4.8s\n",
      "[CV 4/5] END C=0.1, gamma=0.0001, kernel=rbf;, score=(train=0.503, test=0.489) total time=   4.9s\n",
      "[CV 5/5] END C=0.1, gamma=0.0001, kernel=rbf;, score=(train=0.501, test=0.495) total time=   4.5s\n",
      "[CV 1/5] END C=1, gamma=1, kernel=rbf;, score=(train=1.000, test=0.486) total time=   4.8s\n",
      "[CV 3/5] END C=1, gamma=1, kernel=rbf;, score=(train=1.000, test=0.489) total time=   4.8s\n",
      "[CV 2/5] END C=1, gamma=1, kernel=rbf;, score=(train=1.000, test=0.491) total time=   4.9s\n",
      "[CV 4/5] END C=1, gamma=1, kernel=rbf;, score=(train=1.000, test=0.489) total time=   4.8s\n",
      "[CV 5/5] END C=1, gamma=1, kernel=rbf;, score=(train=1.000, test=0.495) total time=   4.9s\n",
      "[CV 1/5] END C=1, gamma=0.1, kernel=rbf;, score=(train=0.995, test=0.648) total time=   5.0s\n",
      "[CV 2/5] END C=1, gamma=0.1, kernel=rbf;, score=(train=0.995, test=0.600) total time=   4.9s\n",
      "[CV 1/5] END C=1, gamma=0.01, kernel=rbf;, score=(train=0.782, test=0.632) total time=   4.3s\n",
      "[CV 2/5] END C=1, gamma=0.01, kernel=rbf;, score=(train=0.768, test=0.650) total time=   4.5s\n",
      "[CV 3/5] END C=1, gamma=0.1, kernel=rbf;, score=(train=0.997, test=0.636) total time=   5.4s\n",
      "[CV 3/5] END C=1, gamma=0.01, kernel=rbf;, score=(train=0.771, test=0.652) total time=   4.5s\n",
      "[CV 4/5] END C=1, gamma=0.01, kernel=rbf;, score=(train=0.774, test=0.650) total time=   4.5s\n",
      "[CV 4/5] END C=1, gamma=0.1, kernel=rbf;, score=(train=0.997, test=0.611) total time=   5.3s\n",
      "[CV 5/5] END C=1, gamma=0.01, kernel=rbf;, score=(train=0.760, test=0.652) total time=   4.6s\n",
      "[CV 5/5] END C=1, gamma=0.1, kernel=rbf;, score=(train=0.995, test=0.611) total time=   5.4s\n",
      "[CV 1/5] END C=1, gamma=0.001, kernel=rbf;, score=(train=0.666, test=0.636) total time=   3.9s\n",
      "[CV 2/5] END C=1, gamma=0.001, kernel=rbf;, score=(train=0.668, test=0.625) total time=   3.9s\n",
      "[CV 3/5] END C=1, gamma=0.001, kernel=rbf;, score=(train=0.657, test=0.639) total time=   4.0s\n",
      "[CV 5/5] END C=1, gamma=0.001, kernel=rbf;, score=(train=0.664, test=0.655) total time=   3.8s\n",
      "[CV 4/5] END C=1, gamma=0.001, kernel=rbf;, score=(train=0.665, test=0.645) total time=   4.0s\n",
      "[CV 1/5] END C=1, gamma=0.0001, kernel=rbf;, score=(train=0.596, test=0.577) total time=   4.2s\n",
      "[CV 2/5] END C=1, gamma=0.0001, kernel=rbf;, score=(train=0.603, test=0.598) total time=   4.4s\n",
      "[CV 3/5] END C=1, gamma=0.0001, kernel=rbf;, score=(train=0.596, test=0.595) total time=   4.3s\n",
      "[CV 4/5] END C=1, gamma=0.0001, kernel=rbf;, score=(train=0.598, test=0.609) total time=   4.2s\n",
      "[CV 5/5] END C=1, gamma=0.0001, kernel=rbf;, score=(train=0.610, test=0.577) total time=   4.2s\n",
      "[CV 1/5] END C=10, gamma=1, kernel=rbf;, score=(train=1.000, test=0.486) total time=   4.6s\n",
      "[CV 2/5] END C=10, gamma=1, kernel=rbf;, score=(train=1.000, test=0.491) total time=   4.6s\n",
      "[CV 3/5] END C=10, gamma=1, kernel=rbf;, score=(train=1.000, test=0.489) total time=   4.6s\n",
      "[CV 4/5] END C=10, gamma=1, kernel=rbf;, score=(train=1.000, test=0.489) total time=   4.8s\n",
      "[CV 5/5] END C=10, gamma=1, kernel=rbf;, score=(train=1.000, test=0.495) total time=   4.7s\n",
      "[CV 1/5] END C=10, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.650) total time=   4.6s\n",
      "[CV 2/5] END C=10, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.614) total time=   4.8s\n",
      "[CV 3/5] END C=10, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.639) total time=   4.7s\n",
      "[CV 5/5] END C=10, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.609) total time=   4.6s\n",
      "[CV 4/5] END C=10, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.609) total time=   4.8s\n",
      "[CV 1/5] END C=10, gamma=0.01, kernel=rbf;, score=(train=0.965, test=0.623) total time=   4.8s\n",
      "[CV 3/5] END C=10, gamma=0.01, kernel=rbf;, score=(train=0.973, test=0.632) total time=   4.7s\n",
      "[CV 2/5] END C=10, gamma=0.01, kernel=rbf;, score=(train=0.965, test=0.639) total time=   4.9s\n",
      "[CV 4/5] END C=10, gamma=0.01, kernel=rbf;, score=(train=0.966, test=0.627) total time=   4.9s\n",
      "[CV 1/5] END C=10, gamma=0.001, kernel=rbf;, score=(train=0.717, test=0.632) total time=   3.7s\n",
      "[CV 2/5] END C=10, gamma=0.001, kernel=rbf;, score=(train=0.713, test=0.639) total time=   3.7s\n",
      "[CV 3/5] END C=10, gamma=0.001, kernel=rbf;, score=(train=0.714, test=0.655) total time=   3.7s\n",
      "[CV 4/5] END C=10, gamma=0.001, kernel=rbf;, score=(train=0.718, test=0.639) total time=   3.8s\n",
      "[CV 5/5] END C=10, gamma=0.01, kernel=rbf;, score=(train=0.963, test=0.639) total time=   4.6s\n",
      "[CV 5/5] END C=10, gamma=0.001, kernel=rbf;, score=(train=0.705, test=0.659) total time=   3.7s\n",
      "[CV 1/5] END C=10, gamma=0.0001, kernel=rbf;, score=(train=0.662, test=0.634) total time=   4.0s\n",
      "[CV 2/5] END C=10, gamma=0.0001, kernel=rbf;, score=(train=0.664, test=0.625) total time=   3.8s\n",
      "[CV 3/5] END C=10, gamma=0.0001, kernel=rbf;, score=(train=0.661, test=0.636) total time=   3.9s\n",
      "[CV 5/5] END C=10, gamma=0.0001, kernel=rbf;, score=(train=0.658, test=0.639) total time=   3.9s\n",
      "[CV 4/5] END C=10, gamma=0.0001, kernel=rbf;, score=(train=0.662, test=0.648) total time=   4.1s\n",
      "[CV 2/5] END C=100, gamma=1, kernel=rbf;, score=(train=1.000, test=0.491) total time=   4.7s\n",
      "[CV 1/5] END C=100, gamma=1, kernel=rbf;, score=(train=1.000, test=0.486) total time=   4.7s\n",
      "[CV 4/5] END C=100, gamma=1, kernel=rbf;, score=(train=1.000, test=0.489) total time=   4.4s\n",
      "[CV 3/5] END C=100, gamma=1, kernel=rbf;, score=(train=1.000, test=0.489) total time=   4.8s\n",
      "[CV 5/5] END C=100, gamma=1, kernel=rbf;, score=(train=1.000, test=0.495) total time=   4.8s\n",
      "[CV 1/5] END C=100, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.650) total time=   4.7s\n",
      "[CV 3/5] END C=100, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.639) total time=   4.6s\n",
      "[CV 2/5] END C=100, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.614) total time=   4.7s\n",
      "[CV 5/5] END C=100, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.609) total time=   4.7s\n",
      "[CV 4/5] END C=100, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.609) total time=   4.8s\n",
      "[CV 2/5] END C=100, gamma=0.01, kernel=rbf;, score=(train=1.000, test=0.620) total time=   5.2s\n",
      "[CV 1/5] END C=100, gamma=0.01, kernel=rbf;, score=(train=1.000, test=0.589) total time=   5.3s\n",
      "[CV 3/5] END C=100, gamma=0.01, kernel=rbf;, score=(train=1.000, test=0.618) total time=   5.2s\n",
      "[CV 1/5] END C=100, gamma=0.001, kernel=rbf;, score=(train=0.803, test=0.630) total time=   4.1s\n",
      "[CV 4/5] END C=100, gamma=0.01, kernel=rbf;, score=(train=1.000, test=0.618) total time=   5.3s\n",
      "[CV 3/5] END C=100, gamma=0.001, kernel=rbf;, score=(train=0.805, test=0.659) total time=   4.2s\n",
      "[CV 5/5] END C=100, gamma=0.01, kernel=rbf;, score=(train=1.000, test=0.593) total time=   5.4s\n",
      "[CV 2/5] END C=100, gamma=0.001, kernel=rbf;, score=(train=0.794, test=0.639) total time=   4.3s\n",
      "[CV 4/5] END C=100, gamma=0.001, kernel=rbf;, score=(train=0.798, test=0.623) total time=   4.3s\n",
      "[CV 1/5] END C=100, gamma=0.0001, kernel=rbf;, score=(train=0.702, test=0.627) total time=   3.7s\n",
      "[CV 5/5] END C=100, gamma=0.001, kernel=rbf;, score=(train=0.794, test=0.648) total time=   4.3s\n",
      "[CV 2/5] END C=100, gamma=0.0001, kernel=rbf;, score=(train=0.699, test=0.643) total time=   3.3s\n",
      "[CV 3/5] END C=100, gamma=0.0001, kernel=rbf;, score=(train=0.693, test=0.643) total time=   3.1s\n",
      "[CV 4/5] END C=100, gamma=0.0001, kernel=rbf;, score=(train=0.705, test=0.634) total time=   2.8s\n",
      "[CV 5/5] END C=100, gamma=0.0001, kernel=rbf;, score=(train=0.693, test=0.652) total time=   2.9s\n",
      "0.672\n",
      "{'kernel': 'rbf', 'gamma': 0.01, 'C': 1}\n"
     ]
    }
   ],
   "source": [
    "param_distributions = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=101)\n",
    "\n",
    "best_svc = RandomizedSearchCV(\n",
    "    estimator=SVC(random_state=101, probability=True),\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50,\n",
    "    cv=cv,\n",
    "    verbose=3,\n",
    "    scoring='accuracy',\n",
    "    random_state=101,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "best_svc.fit(X_train, y_train)\n",
    "pred = best_svc.best_estimator_.predict(X_test)\n",
    "print(accuracy_score(y_test, pred))\n",
    "print(best_svc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    1.1s remaining:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    3.1s remaining:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67\n"
     ]
    }
   ],
   "source": [
    "estimators = [('mlp', best_mlp.best_estimator_), ('svc',best_svc.best_estimator_)]\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=101)\n",
    "\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression(),\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=5\n",
    ")\n",
    "\n",
    "pred = stacking_clf.fit(X_train,y_train).predict(X_test)\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At Ratio 0.2: [0.651, 0.652, 0.672]\n",
      "At Ratio 0.3: [0.651, 0.625, 0.647]\n",
      "At Ratio 0.4: [0.647, 0.618, 0.65]\n",
      "At Ratio 0.5: [0.652, 0.599, 0.629]\n",
      "At Ratio 0.6: [0.644, 0.635, 0.647]\n",
      "At Ratio 0.7: [0.661, 0.629, 0.642]\n"
     ]
    }
   ],
   "source": [
    "result = {}\n",
    "for i in range(2,8):\n",
    "    predictions = []\n",
    "    i = i / 10\n",
    "    X_train, y_train = preprocessing(data['data'], data['target'], i)\n",
    "    X_test = preprocessing_test(test_data['data'])\n",
    "    y_test = test_data['target']\n",
    "\n",
    "    pca = PCA(n_components=150, random_state=101)\n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    X_test = pca.transform(X_test)\n",
    "    \n",
    "    svc = SVC(probability = True)\n",
    "    pred = svc.fit(X_train,y_train).predict(X_test)\n",
    "    predictions.append(accuracy_score(y_test, pred))\n",
    "    \n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(128, 64), solver='adam', max_iter=1000, activation='relu', early_stopping=True, random_state=101)\n",
    "    pred = mlp.fit(X_train,y_train).predict(X_test)\n",
    "    predictions.append(accuracy_score(y_test, pred))\n",
    "    \n",
    "    gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=0.01, max_depth=3, random_state=101)\n",
    "    pred = gbc.fit(X_train,y_train).predict(X_test)\n",
    "    predictions.append(accuracy_score(y_test, pred))\n",
    "    \n",
    "    # cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=101)\n",
    "\n",
    "    # estimators = [('mlp', mlp), ('svc',svc), ('gbc', gbc)]#, ('voting_soft', voting_clf_soft)]\n",
    "\n",
    "    # stacking_clf = StackingClassifier(\n",
    "    #     estimators=estimators,\n",
    "    #     final_estimator=LogisticRegression(),\n",
    "    #     cv=cv,\n",
    "    #     n_jobs=-1\n",
    "    # )\n",
    "    # pred = stacking_clf.fit(X_train,y_train).predict(X_test)\n",
    "    # predictions.append(accuracy_score(y_test, pred))\n",
    "    \n",
    "    print(f'At Ratio {i}: {predictions}')\n",
    "    \n",
    "    result[i] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 - 4\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "com6018",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
